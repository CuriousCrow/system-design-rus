# System Design

Привет, добро пожаловать на курс System Design. Надеюсь, что изучив его, вы узнаете много нового.

_Этот курс также доступен на моем [сайте](https://karanpratapsingh.com/courses/system-design) , а электронная версия книги на [leanpub](https://leanpub.com/systemdesign). Пожалуйста, ставьте ⭐ если курс оказался для Вас полезен!_

# Содержание

- **Вступление**

  - [Что такое system design?](#what-is-system-design)

- **Глава I**

  - [IP](#ip)
  - [OSI Model](#osi-model)
  - [TCP and UDP](#tcp-and-udp)
  - [Domain Name System (DNS)](#domain-name-system-dns)
  - [Load Balancing](#load-balancing)
  - [Clustering](#clustering)
  - [Caching](#caching)
  - [Content Delivery Network (CDN)](#content-delivery-network-cdn)
  - [Proxy](#proxy)
  - [Availability](#availability)
  - [Scalability](#scalability)
  - [Storage](#storage)

- **Глава II**

  - [Databases and DBMS](#databases-and-dbms)
  - [SQL databases](#sql-databases)
  - [NoSQL databases](#nosql-databases)
  - [SQL vs NoSQL databases](#sql-vs-nosql-databases)
  - [Database Replication](#database-replication)
  - [Indexes](#indexes)
  - [Normalization and Denormalization](#normalization-and-denormalization)
  - [ACID and BASE consistency models](#acid-and-base-consistency-models)
  - [CAP theorem](#cap-theorem)
  - [PACELC Theorem](#pacelc-theorem)
  - [Transactions](#transactions)
  - [Distributed Transactions](#distributed-transactions)
  - [Sharding](#sharding)
  - [Consistent Hashing](#consistent-hashing)
  - [Database Federation](#database-federation)

- **Глава III**

  - [N-tier architecture](#n-tier-architecture)
  - [Message Brokers](#message-brokers)
  - [Message Queues](#message-queues)
  - [Publish-Subscribe](#publish-subscribe)
  - [Enterprise Service Bus (ESB)](#enterprise-service-bus-esb)
  - [Monoliths and Microservices](#monoliths-and-microservices)
  - [Event-Driven Architecture (EDA)](#event-driven-architecture-eda)
  - [Event Sourcing](#event-sourcing)
  - [Command and Query Responsibility Segregation (CQRS)](#command-and-query-responsibility-segregation-cqrs)
  - [API Gateway](#api-gateway)
  - [REST, GraphQL, gRPC](#rest-graphql-grpc)
  - [Long polling, WebSockets, Server-Sent Events (SSE)](#long-polling-websockets-server-sent-events-sse)

- **Глава IV**

  - [Geohashing and Quadtrees](#geohashing-and-quadtrees)
  - [Circuit breaker](#circuit-breaker)
  - [Rate Limiting](#rate-limiting)
  - [Service Discovery](#service-discovery)
  - [SLA, SLO, SLI](#sla-slo-sli)
  - [Disaster recovery](#disaster-recovery)
  - [Virtual Machines (VMs) and Containers](#virtual-machines-vms-and-containers)
  - [OAuth 2.0 and OpenID Connect (OIDC)](#oauth-20-and-openid-connect-oidc)
  - [Single Sign-On (SSO)](#single-sign-on-sso)
  - [SSL, TLS, mTLS](#ssl-tls-mtls)

- **Глава V**

  - [Собеседование по System Design](#system-design-interviews)
  - [URL Shortener](#url-shortener)
  - [WhatsApp](#whatsapp)
  - [Twitter](#twitter)
  - [Netflix](#netflix)
  - [Uber](#uber)

- **Приложение**

  - [Что дальше?](#next-steps)
  - [Полезные ссылки](#references)

# Что такое системное проектирование?

Прежде чем мы начнем этот курс, давайте поговорим о том, что такое системное проектирование.

Системное проектирование - это процесс определения архитектуры, интерфейсов и данных для системы, которая удовлетворяет определенным требованиям. Системное проектирование соответствует потребностям вашего бизнеса или организации через последовательные и эффективные системы. Для этого требуется системный подход к созданию и инжинирингу систем. Хорошее системное проектирование требует от нас думать обо всем, начиная от инфраструктуры и заканчивая данными и их хранением.

## Почему системное проектирование так важно?

Системное проектирование помогает нам определить решение, которое удовлетворяет бизнес-требованиям. Это одно из первых решений, которые мы можем принять при построении системы. Часто это крайне важно думать на высоком уровне, поскольку эти решения очень сложно исправить позднее. Это также облегчает обоснование и управление архитектурными изменениями по мере развития системы.

# IP

IP-адрес - это уникальный адрес, который идентифицирует устройство в Интернете или локальной сети. IP означает _"Протокол интернета"_, который представляет собой набор правил, регулирующих формат данных, отправляемых через Интернет или локальную сеть.

По сути, IP-адреса являются идентификатором, который позволяет отправлять информацию между устройствами в сети. Они содержат информацию о местоположении и обеспечивают доступность устройств для обмена данными. Интернету необходим способ различать разные компьютеры, маршрутизаторы и веб-сайты. IP-адреса предоставляют такой способ и являются важной частью работы Интернета.

## Версии

Существуют различные версии IP-адресов:

### IPv4

Оригинальный Интернет-протокол - это IPv4, который использует 32-битную числовую точечно-десятичную нотацию, которая позволяет использовать около 4 миллиардов IP-адресов. Изначально этого было более чем достаточно, но по мере роста использования интернета нам понадобилось что-то лучшее.

_Пример: `102.22.192.181`_

### IPv6

IPv6 - это новый протокол, который был представлен в 1998 году. Развёртывание началось в середине 2000-х годов, и поскольку число пользователей интернета выросло в геометрической прогрессии, оно продолжается до сих пор.

Этот новый протокол использует 128-битную алфавитно-цифровую шестнадцатеричную нотацию. Это означает, что IPv6 может обеспечить около ~340e+36 IP-адресов. Этого более чем достаточно для удовлетворения растущего спроса на многие годы вперёд.

_Пример: `2001:0db8:85a3:0000:0000:8a2e:0370:7334`_

## Типы

Давайте обсудим типы IP-адресов:

### Публичный

Публичный IP-адрес - это адрес, где один основной адрес связан со всей вашей сетью. В этом типе IP-адреса каждое подключенное устройство имеет один и тот же IP-адрес.

_Пример: IP-адрес, предоставленный вашему маршрутизатору поставщиком услуг интернета._

### Приватный

Приватный IP-адрес - это уникальный IP-номер, назначаемый каждому устройству, подключающемуся к вашей сети интернет, включая устройства, такие как компьютеры, планшеты и смартфоны, используемые в вашем доме.

_Пример: IP-адреса, создаваемые вашим домашним маршрутизатором для ваших устройств._

### Статический

Статический IP-адрес не меняется и создаётся вручную, в отличие от автоматического назначения. Эти адреса обычно более дорогие, но более надёжные.

_Пример: Они обычно используются для важных вещей, таких как надёжные геолокационные службы, удалённый доступ, хостинг серверов и т. д._

### Динамический

Динамический IP-адрес меняется с течением времени и не всегда остаётся таким же. Он назначается сервером динамической конфигурации хоста (DHCP). Динамические IP-адреса являются наиболее распространённым типом IP-адресов. Они дешевле в развёртывании и позволяют повторно использовать IP-адреса в сети по мере необходимости.

_Пример: Они более часто используются для оборудования потребителей и личного использования._

# Модель OSI

Модель OSI - это логическая и концептуальная модель, которая определяет сетевое взаимодействие, используемое системами, открытыми для взаимодействия и связи с другими системами. Модель открытой системной интеркоммуникации (OSI) также определяет логическую сеть и эффективно описывает передачу компьютерных пакетов с использованием различных уровней протоколов.

Модель OSI можно рассматривать как универсальный язык компьютерных сетей. Она основана на концепции разделения системы связи на семь абстрактных уровней, каждый из которых стекается на предыдущий.

## Почему модель OSI важна?

Модель открытой системной интеркоммуникации (OSI) определила общие термины, используемые в обсуждениях и документировании сетевых технологий. Это позволяет нам разбирать очень сложные процессы связи и оценивать их компоненты.

Хотя данная модель не непосредственно реализуется в сетях TCP/IP, которые наиболее распространены сегодня, она по-прежнему может помочь нам во многом:

- Упростить процесс поиска и угрозы по всему стеку протоколов.
- Поощрять производителей аппаратного обеспечения создавать сетевые продукты, способные взаимодействовать друг с другом по сети.
- Быть неотъемлемой частью формирования мышления о безопасности.
- Разделять сложные функции на более простые компоненты.

## Слои

Можно выделить следующие семь абстрактных слоев OSI-модели, от верхнего уровня к нижнему:

![osi-model](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/osi-model/osi-model.png)

### Прикладной уровень (Application)

Этот уровень единственный прямо взаимодействует с данными от пользователя. Программные приложения, такие как веб-браузеры и почтовые клиенты, полагаются на прикладной уровень для инициирования коммуникации. Однако следует четко понимать, что клиентские программные приложения не являются частью прикладного уровня; скорее, прикладной уровень отвечает за протоколы и манипуляции данными, на которых программное обеспечение основывается для представления значимых данных пользователю. Протоколы прикладного уровня включают HTTP и SMTP.

### Уровень представления (Presentation)

Уровень представления также называется уровнем трансляции. Здесь данные от прикладного уровня извлекаются и манипулируются в соответствии с необходимым форматом для передачи по сети. Функции уровня представления включают трансляцию, шифрование/дешифрование и сжатие.

### Сеансовый уровень (Session)

Этот уровень отвечает за открытие и закрытие коммуникации между двумя устройствами. Время между открытием и закрытием коммуникации известно как сеанс. Сеансовый уровень обеспечивает, чтобы сеанс оставался открытым достаточно долго для передачи всех обмениваемых данных, а затем быстро закрывает сеанс, чтобы избежать расточительного расходования ресурсов. Сеансовый уровень также синхронизирует передачу данных с контрольными точками.

### Транспортный уровень (Transport)

Транспортный уровень (также известный как уровень 4) отвечает за конечно-конечное взаимодействие между двумя устройствами. Это включает в себя взятие данных с сеансового уровня и разбиение их на части, называемые сегментами, перед отправкой на сетевой уровень (уровень 3). Он также отвечает за сборку сегментов на принимающем устройстве в данные, которые может использовать сеансовый уровень.

### Сетевой уровень (Network)

Сетевой уровень отвечает за облегчение передачи данных между двумя различными сетями. Сетевой уровень разбивает сегменты с транспортного уровня на более мелкие единицы, называемые пакетами, на устройстве отправителя, а затем собирает эти пакеты на устройстве получателя. Сетевой уровень также находит оптимальный физический путь для достижения данных до их назначения, это известно как маршрутизация. Если два устройства, обменивающихся данными, находятся в одной сети, то сетевой уровень не требуется.

### Канальный уровень (Data Link)

Канальный уровень очень похож на сетевой уровень, за исключением того, что он облегчает передачу данных между двумя устройствами в одной сети. Канальный уровень берет пакеты с сетевого уровня и разбивает их на более мелкие части, называемые кадрами.

### Физический уровень (Physical)

На этом уровне находится физическое оборудование, участвующее в передаче данных, такое как кабели и коммутаторы. Это также уровень, на котором данные преобразуются в поток битов, который представляет собой последовательность единиц и нулей. Физический уровень обоих устройств также должен договориться о соглашении по сигналу, чтобы единицы можно было различить от нулей на обоих устройствах.

# TCP and UDP

## TCP

Протокол управления передачей (TCP) ориентирован на установление соединения, что означает, что после установки соединения данные могут передаваться в обе стороны. У TCP встроены системы проверки ошибок и гарантии доставки данных в том порядке, в котором они были отправлены, что делает его идеальным протоколом для передачи информации, такой как статические изображения, файлы данных и веб-страницы.

![tcp](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/tcp-and-udp/tcp.png)

Но хотя TCP инстинктивно надежен, его механизмы обратной связи также приводят к бóльшему накладному расходу, что влечет за собой более интенсивное использование доступной пропускной способности в сети.

## UDP

Протокол пользовательских дейтаграмм (UDP) - это более простой, безсоединительный интернет-протокол, в котором проверка ошибок и восстановление не требуются. С UDP нет накладных расходов на открытие соединения, поддержание соединения или завершение соединения. Данные непрерывно отправляются получателю, вне зависимости от того, получает ли он их или нет.

![udp](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/tcp-and-udp/udp.png)

Он широко предпочтителен для реального времени связи, такой как трансляция или многопрограммная передача сети. Мы должны использовать UDP вместо TCP, когда нам нужна минимальная задержка, и потеря данных хуже, чем задержка данных.

## TCP против UDP

TCP - это протокол, ориентированный на установление соединения, в то время как UDP - это протокол без установления соединения. Одно из ключевых различий между TCP и UDP - это скорость, поскольку TCP сравнительно медленнее, чем UDP. В целом, UDP является более быстрым, простым и эффективным протоколом, однако повторная передача потерянных пакетов данных возможна только с TCP.

TCP обеспечивает упорядоченную доставку данных от пользователя к серверу (и наоборот), в то время как UDP не предназначен для точечного обмена данными, и не проверяет готовность получателя.

| Функция             | TCP                                         | UDP                                |
| ------------------- | ------------------------------------------- | ---------------------------------- |
| Подключение          | Требует установленного соединения           | Протокол без установления соединения |
| Гарантированная доставка | Может гарантировать доставку данных       | Не может гарантировать доставку данных |
| Переотправка     | Возможна повторная отправка потерянных пакетов | Нет повторной отправки потерянных пакетов |
| Скорость               | Медленнее, чем UDP                             | Быстрее, чем TCP                    |
| Рассылка        | Не поддерживает рассылку               | Поддерживает рассылку              |
| Сферы применения           | HTTPS, HTTP, SMTP, POP, FTP, и т. д.            | Видеопотоки, DNS, VoIP, и т. д.    |

# Domain Name System (DNS)

Ранее мы узнали о IP-адресах, которые позволяют каждой машине подключаться к другим машинам. Но, как мы знаем, людям удобнее работать с именами, чем с числами. Легче запомнить имя, например, `google.com`, чем что-то вроде `122.250.192.232`.

Это приводит нас к системе доменных имен (DNS), которая является иерархической и децентрализованной системой именования, используемой для преобразования человеко-читаемых доменных имен в IP-адреса.

## Как работает DNS

![how-dns-works](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/domain-name-system/how-dns-works.png)

DNS-запрос включает в себя следующие восемь шагов:

1. Клиент вводит [example.com](http://example.com) в веб-браузер, запрос отправляется в интернет и получается DNS-резольвером.
2. Резольвер рекурсивно запрашивает DNS корневой сервер.
3. Корневой сервер отвечает резольверу адресом доменного имени верхнего уровня (TLD).
4. Резольвер затем делает запрос к TLD-серверу `.com`.
5. Сервер TLD затем отвечает IP-адресом сервера имен домена, [example.com](http://example.com).
6. Наконец, рекурсивный резольвер отправляет запрос на сервер имен домена.
7. IP-адрес для [example.com](http://example.com) затем возвращается резольверу с сервера имен.
8. DNS-резольвер затем отвечает веб-браузеру IP-адресом исходного запрошенного домена.

После того как IP-адрес был разрешен, клиент должен иметь возможность запросить контент по разрешенному IP-адресу. Например, разрешенный IP может возвращать веб-страницу для отображения в браузере.

## Типы серверов

Теперь давайте рассмотрим четыре основные группы серверов, составляющих инфраструктуру DNS.

### DNS-резольвер

DNS-резольвер (также известный как рекурсивный DNS-резольвер) - это первый этап в DNS-запросе. Рекурсивный резольвер действует как посредник между клиентом и DNS-сервером имен. После получения DNS-запроса от веб-клиента рекурсивный резольвер либо отвечает кэшированными данными, либо отправляет запрос корневому DNS-серверу, за которым следует запрос к DNS-серверу TLD, а затем последний запрос к авторитетному DNS-серверу. После получения ответа от авторитетного DNS-сервера, содержащего запрошенный IP-адрес, рекурсивный резольвер отправляет ответ клиенту.

### Корневой DNS-сервер

Корневой DNS-сервер принимает запрос рекурсивного резольвера, включающий доменное имя, и отвечает, направляя рекурсивный резольвер к DNS-серверу TLD на основе расширения этого домена (`.com`, `.net`, `.org` и т. д.). Корневые DNS-серверы находятся под надзором некоммерческой организации под названием [Интернет-корпорация по присвоению имен и номеров (ICANN)](https://www.icann.org).

Существует 13 корневых DNS-серверов, известных каждому рекурсивному резольверу. Следует отметить, что хотя существует 13 корневых DNS-серверов, это не означает, что в системе корневых DNS-серверов есть только 13 машин. Существует 13 типов корневых DNS-серверов, но у каждого из них есть несколько копий по всему миру, которые используют [маршрутизацию Anycast](https://en.wikipedia.org/wiki/Anycast) для обеспечения быстрых ответов.

### TLD nameserver

Top Level Domain (TLD) nameserver поддерживает информацию для всех доменных имен, которые имеют общее доменное расширение, такое как `.com`, `.net` или что-то ещё после последней точки в URL-адресе.

Управление серверами имен верхнего уровня доменного имени осуществляется [Управлением назначения интернет-ресурсов (IANA)](https://www.iana.org), которое является подразделением [ICANN](https://www.icann.org). IANA разделяет сервера имен верхнего уровня доменного имени на две основные группы:

- **Общие домены верхнего уровня**: Это домены, такие как `.com`, `.org`, `.net`, `.edu` и `.gov`.
- **Домены верхнего уровня по странам**: Это включает любые домены, которые специфичны для страны или региона. Примеры включают `.uk`, `.us`, `.ru` и `.jp`.

### Авторитетный DNS-сервер

Авторитетный сервер имен обычно является последним шагом резольвера в пути к IP-адресу. Авторитетный сервер имен содержит информацию, специфичную для обслуживаемого имени домена (например, [google.com](http://google.com)), и может предоставить рекурсивному резольверу IP-адрес этого сервера, найденного в DNS-записи типа A, или, если домен имеет запись CNAME (псевдоним), он предоставит рекурсивному резольверу псевдоним домена, после чего рекурсивный резольвер должен будет выполнить новый DNS-запрос, чтобы получить запись от авторитетного сервера имен (чаще всего запись типа A, содержащую IP-адрес). Если не удается найти домен, возвращается сообщение NXDOMAIN.

## Типы запросов

Существует три типа запросов в DNS-системе:

### Рекурсивный

В рекурсивном запросе DNS-клиент требует, чтобы DNS-сервер (обычно рекурсивный DNS-резольвер) отвечал клиенту либо запрошенной ресурсной записью, либо сообщением об ошибке, если резольвер не может найти запись.

### Итеративный

В итеративном запросе DNS-клиент предоставляет имя хоста, а DNS-резольвер возвращает наилучший ответ, который может. Если DNS-резольвер имеет соответствующие DNS-записи в своем кэше, он возвращает их. Если нет, он направляет DNS-клиента к корневому серверу или другому авторитетному серверу имен, который находится ближе всего к требуемой DNS-зоне. Затем DNS-клиент должен повторить запрос напрямую к DNS-серверу, на который он был направлен.

### Не рекурсивный

Не рекурсивный запрос - это запрос, в котором DNS-резольвер уже знает ответ. Он либо немедленно возвращает DNS-запись, потому что уже хранит ее в локальном кэше, либо запрашивает DNS-сервер имен, который является авторитетным для этой записи, что означает, что он определенно содержит правильный IP-адрес для этого имени хоста. В обоих случаях нет необходимости в дополнительных раундах запросов (как в рекурсивных или итеративных запросах). Вместо этого ответ немедленно возвращается клиенту.

## Типы записей

DNS-записи (также известные как файлы зон) - это инструкции, которые находятся на авторитетных DNS-серверах и содержат информацию о домене, включая IP-адрес, связанный с этим доменом, и способ обработки запросов для этого домена.

Эти записи представляют собой серию текстовых файлов, написанных в так называемом _синтаксисе DNS_. Синтаксис DNS - это просто строка символов, используемая в качестве команд, которые указывают DNS-серверу, что делать. У всех DNS-записей также есть _"TTL"_, что означает время жизни, и указывает, как часто DNS-сервер будет обновлять эту запись.

Существует больше типов записей, но на данный момент давайте рассмотрим некоторые из наиболее часто используемых:

- **A (Address record)**: Это запись, которая содержит IP-адрес домена.
- **AAAA (IPv6 Address record)**: Запись, которая содержит IPv6-адрес домена (в отличие от записей A, которые хранят IPv4-адрес).
- **CNAME (Canonical Name record)**: Перенаправляет один домен или поддомен на другой домен, НЕ предоставляет IP-адрес.
- **MX (Mail exchanger record)**: Направляет почту на почтовый сервер.
- **TXT (Text Record)**: Эта запись позволяет администратору сохранять текстовые заметки в записи. Эти записи часто используются для защиты электронной почты.
- **NS (Name Server records)**: Хранит сервер имен для записи DNS.
- **SOA (Start of Authority)**: Хранит административную информацию о домене.
- **SRV (Service Location record)**: Указывает порт для конкретных служб.
- **PTR (Reverse-lookup Pointer record)**: Предоставляет обратное преобразование имени домена.
- **CERT (Certificate record)**: Хранит открытые ключевые сертификаты.

## Поддомены

Поддомен - это дополнительная часть основного имени нашего домена. Он обычно используется для логического разделения веб-сайта на разделы. Мы можем создать несколько поддоменов или дочерних доменов на основном домене.

Например, `blog.example.com`, где `blog` - это поддомен, `example` - это основной домен, а `.com` - это домен верхнего уровня (TLD). Аналогичные примеры могут быть `support.example.com` или `careers.example.com`.

## DNS-зоны

DNS-зона - это отдельная часть пространства доменов, которая делегируется юридическому лицу, такому как человек, организация или компания, ответственному за поддержку DNS-зоны. DNS-зона также представляет собой административную функцию, позволяющую осуществлять детализированный контроль над компонентами DNS, такими как авторитетные серверы имен.

## Кэширование DNS

Кэш DNS (иногда называемый кэшем резольвера DNS) - это временная база данных, поддерживаемая операционной системой компьютера, которая содержит записи всех недавних посещений и попыток посещений веб-сайтов и других интернет-доменов. Другими словами, кэш DNS - это просто память о недавних DNS-запросах, к которой наш компьютер может быстро обратиться, когда он пытается определить, как загрузить веб-сайт.

Система доменных имен реализует время жизни (TTL) на каждой DNS-записи. TTL указывает количество секунд, в течение которого запись может быть кэширована DNS-клиентом или сервером. Когда запись хранится в кэше, сохраняется значение TTL, которое сопровождало ее. Сервер продолжает обновлять TTL записи, хранящейся в кэше, отсчитывая каждую секунду. Когда оно достигает нуля, запись удаляется или удаляется из кэша. В этот момент, если получен запрос на эту запись, DNS-сервер должен начать процесс разрешения.

## Обратное DNS

Обратное DNS-разрешение — это DNS-запрос для определения доменного имени, связанного с заданным IP-адресом. Это осуществляет противоположное действие по сравнению с более распространенным прямым DNS-запросом, при котором система DNS запрашивается для возврата IP-адреса. Процесс обратного разрешения IP-адреса использует записи PTR. Если на сервере нет записи PTR, он не может выполнить обратный поиск.

Обратные поиски часто используются почтовыми серверами. Почтовые серверы проверяют и определяют, пришло ли сообщение электронной почты с действительного сервера, прежде чем принять его на свою сеть. Многие почтовые серверы отклоняют сообщения от любого сервера, который не поддерживает обратные поиски или считается весьма маловероятным для подлинного.

_Примечание: Обратные DNS-запросы не всегда приняты к использованию, поскольку они не являются критическими для нормального функционирования интернета._

## Примеры

Примеры наиболее широко используемых DNS-решений:

- [Route53](https://aws.amazon.com/route53)
- [Cloudflare DNS](https://www.cloudflare.com/dns)
- [Google Cloud DNS](https://cloud.google.com/dns)
- [Azure DNS](https://azure.microsoft.com/en-in/services/dns)
- [NS1](https://ns1.com/products/managed-dns)

# Load Balancing

Load balancing lets us distribute incoming network traffic across multiple resources ensuring high availability and reliability by sending requests only to resources that are online. This provides the flexibility to add or subtract resources as demand dictates.

![load-balancing](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/load-balancing/load-balancer.png)

Для дополнительной масштабируемости и резервирования можно использовать балансировщик на каждом слое нашей системы:

![load-balancing-layers](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/load-balancing/load-balancer-layers.png)

## А зачем?

Современные сайты с высоким трафиком должны обслуживать сотни тысяч, если не миллионы, одновременных запросов от пользователей или клиентов. Для эффективного масштабирования и удовлетворения этого высокого объема запросов современные лучшие практики в области вычислений обычно требуют добавления большего количества серверов.

Балансировщик нагрузки может находиться перед серверами и направлять запросы клиентов по всем серверам, способным выполнить эти запросы таким образом, чтобы максимизировать скорость и использование мощности. Это гарантирует, что ни один сервер не перегружен, что может привести к снижению производительности. Если один сервер выходит из строя, балансировщик нагрузки перенаправляет трафик на оставшиеся онлайн-серверы. Когда к группе серверов добавляется новый сервер, балансировщик нагрузки автоматически начинает отправлять запросы на него.

## Распределение нагрузки

Это является ключевой функцией балансировщиков. Есть несколько принятых вариантов распределения нагрузки:

- **Host-based**: Распределяет запросы на основе запрашиваемого имени хоста.
- **Path-based**: Использует я распределения запросов URL целиком, а не только хост.
- **Content-based**: Исследует весь запрос целиком. Например в таком случае запрос может распределяться в зависимости от значение какого-либо параметра.

## Уровни

Обычно балансировщики нагрузки работают на одном из двух уровней:

### Сетевой уровень

Это балансировщик нагрузки, который работает на транспортном уровне сети, также известном как уровень 4. Он выполняет маршрутизацию на основе сетевой информации, такой как IP-адреса, и не способен выполнять маршрутизацию на основе содержимого. Это часто выделенные аппаратные устройства, способные работать с высокой скоростью.

### Прикладной уровень

Это балансировщик нагрузки, который работает на уровне приложения, также известном как уровень 7. Балансировщики нагрузки могут прочитывать запросы полностью и выполнять маршрутизацию на основе содержимого. Это позволяет управлять нагрузкой на основе полного понимания трафика.

## Типы

Давайте рассмотрим разные типы балансировщиков нагрузки:

### Программное обеспечение

Программные балансировщики нагрузки обычно легче внедрить, чем аппаратные версии. Они также часто более экономичны и гибки, и используются в сочетании с средами разработки программного обеспечения. Программный подход дает нам гибкость настройки балансировщика нагрузки под конкретные потребности нашей среды. Увеличение гибкости может потребовать больше работы по настройке балансировщика нагрузки. По сравнению с аппаратными версиями, которые предлагают более закрытый подход, программные балансировщики дают нам больше свободы для внесения изменений и обновлений.

Программные балансировщики нагрузки широко используются и доступны как установочные решения, требующие конфигурации и управления, так и как управляемые облачные сервисы.

### Аппаратное обеспечение

Как следует из названия, аппаратный балансировщик нагрузки зависит от физического оборудования, установленного на месте, для распределения трафика приложений и сети. Эти устройства могут обрабатывать большой объем трафика, но часто имеют значительную цену и относительно ограничены в гибкости.

Аппаратные балансировщики нагрузки включают в себя проприетарное программное обеспечение, которое требует обслуживания и обновлений с выпуском новых версий и патчей безопасности.

### DNS

Балансировка нагрузки DNS - это практика настройки домена в системе доменных имен (DNS) таким образом, чтобы запросы клиентов к домену распределялись по группе серверных машин.

К сожалению, у балансировки нагрузки DNS есть врожденные проблемы, ограничивающие ее надежность и эффективность. Самым значимым из них является то, что DNS не проверяет отказы серверов и сетей или ошибки. Он всегда возвращает один и тот же набор IP-адресов для домена, даже если серверы выключены или недоступны.

## Routing Algorithms

Теперь давайте обсудим наиболее распространенные алгоритмы маршрутизации:

- **Round-robin**: Запросы распределяются по приложениям в циклическом порядке.
- **Weighted Round-robin**: Основан на простом методе Round-robin и учитывает различные характеристики серверов, такие как вычислительная мощность и обработка трафика, с использованием весов, которые могут быть назначены администратором через записи DNS.
- **Least Connections**: Новый запрос отправляется на сервер с наименьшим текущим количеством соединений с клиентами. Относительная вычислительная мощность каждого сервера учитывается при определении того, у кого меньше всего соединений.
- **Least Response Time**: Отправляет запросы на сервер, выбранный формулой, которая объединяет самое быстрое время ответа и наименьшее количество активных соединений.
- **Least Bandwidth**: Этот метод измеряет трафик в мегабитах в секунду (Mbps) и отправляет запросы клиентов на сервер с наименьшим количеством Mbps трафика.
- **Hashing**: Распределяет запросы на основе ключа, который мы определяем, такого как IP-адрес клиента или URL запроса.

## Преимущества

Балансировка нагрузки также играет ключевую роль в предотвращении простоев, другие преимущества балансировки нагрузки включают в себя следующее:

- Масштабируемость
- Отказоустойчивость
- Гибкость
- Эффективность

## Резервные балансировщики нагрузки

Как вы, возможно, уже догадались, сам балансировщик нагрузки может быть единственной точкой отказа. Для преодоления этого может использоваться второй или `N` количество балансировщиков нагрузки в режиме кластера.

И, если обнаруживается сбой и _активный_ балансировщик нагрузки выходит из строя, другой _пассивный_ балансировщик нагрузки может взять на себя его функции, что сделает нашу систему более устойчивой к отказам.

![redundant-load-balancing](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/load-balancing/redundant-load-balancer.png)

## Features

Вот некоторые распространенные желаемые функции балансировщиков нагрузки:

- **Автомасштабирование**: Запуск и выключение ресурсов в зависимости от условий спроса.
- **Клейкие сессии**: Возможность назначить тот же пользовательский или устройственный ресурс тому же ресурсу для поддержания состояния сеанса на ресурсе.
- **Проверка состояния**: Возможность определить, отключен ли ресурс или работает плохо, чтобы удалить ресурс из пула балансировки нагрузки.
- **Устойчивые соединения**: Разрешение серверу открывать постоянное соединение с клиентом, такое как WebSocket.
- **Шифрование**: Обработка зашифрованных соединений, таких как TLS и SSL.
- **Сертификаты**: Предоставление клиенту сертификатов и аутентификация клиентских сертификатов.
- **Сжатие**: Сжатие ответов.
- **Кэширование**: Балансировщик нагрузки на уровне приложения может предлагать возможность кэшировать ответы.
- **Логирование**: Логирование метаданных запроса и ответа может служить важным следом для аудита или источником данных аналитики.
- **Трассировка запросов**: Присвоение каждому запросу уникального идентификатора для целей логирования, мониторинга и устранения неполадок.
- **Перенаправления**: Возможность перенаправления входящего запроса на основе таких факторов, как запрошенный путь.
- **Фиксированный ответ**: Возврат статического ответа на запрос, такого как сообщение об ошибке.

## Примеры

Ниже приведены некоторые часто используемые в IT-индустрии балансировщики:

- [Amazon Elastic Load Balancing](https://aws.amazon.com/elasticloadbalancing)
- [Azure Load Balancing](https://azure.microsoft.com/en-in/services/load-balancer)
- [GCP Load Balancing](https://cloud.google.com/load-balancing)
- [DigitalOcean Load Balancer](https://www.digitalocean.com/products/load-balancer)
- [Nginx](https://www.nginx.com)
- [HAProxy](http://www.haproxy.org)

# Clustering

На более высоком уровне компьютерный кластер представляет собой группу из двух или более компьютеров, или узлов, которые работают параллельно для достижения общей цели. Это позволяет распределить рабочие нагрузки, состоящие из большого количества индивидуальных, параллелизуемых задач, между узлами в кластере. В результате эти задачи могут использовать объединенную память и вычислительную мощность каждого компьютера для повышения общей производительности.

Для создания компьютерного кластера каждый отдельный узел должен быть подключен к сети для обеспечения межузлового взаимодействия. Затем программное обеспечение может быть использовано для объединения узлов и формирования кластера. Возможно, на каждом узле может быть общее устройство хранения и/или локальное хранилище.

![cluster](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/clustering/cluster.png)

Обычно, как минимум один узел назначается ведущим и действует как точка входа в кластер. Ведущий узел может быть ответственен за делегирование входящей работы другим узлам и, при необходимости, агрегирование результатов и возврат ответа пользователю.

Идеально, кластер функционирует так, как если бы он был единым системным блоком. Пользователь, получающий доступ к кластеру, не должен знать, является ли система кластером или отдельным компьютером. Более того, кластер должен быть спроектирован для минимизации задержек и предотвращения узких мест в межузловом общении.

## Типы

Компьютерные кластеры обычно можно классифицировать по трем типам:

- Высокодоступные или с отказоустойчивостью
- Балансировка нагрузки
- Высокопроизводительные вычисления

## Конфигурации

Два наиболее распространенных варианта конфигурации кластеров с высокой доступностью (HA) - это активный-активный и активный-пассивный.

### Активный-активный

![Активный-активный](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/clustering/active-active.png)

Активно-активный кластер обычно состоит по крайней мере из двух узлов, которые одновременно активно выполняют одинаковый тип сервиса. Основная цель активно-активного кластера - достижение балансировки нагрузки. Балансировщик нагрузки распределяет рабочие нагрузки по всем узлам, чтобы предотвратить перегрузку любого отдельного узла. Поскольку доступно больше узлов для обслуживания, также будет улучшение пропускной способности и времени отклика.

### Active-Passive

![active-passive](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/clustering/active-passive.png)

Как и конфигурация кластера активный-активный, кластер активный-пассивный также состоит по крайней мере из двух узлов. Однако, как подразумевает название _активный-пассивный_, не все узлы будут активными. Например, в случае двух узлов, если первый узел уже активен, то второй узел должен быть пассивным или в режиме ожидания.

## Преимущества

Четыре основных преимущества кластерных вычислений следующие:

- Высокая доступность
- Масштабируемость
- Производительность
- Экономическая эффективность

## Load balancing vs Clustering

Балансировка нагрузки имеет некоторые общие черты с кластеризацией, но это разные процессы. Кластеризация обеспечивает избыточность, увеличивает мощность и доступность. Серверы в кластере осведомлены друг о друге и работают сообща в рамках общей цели. Но с балансировкой нагрузки серверы не осведомлены друг о друге. Вместо этого они реагируют на запросы, получаемые от балансировщика нагрузки.

Мы можем применять балансировку нагрузки в сочетании с кластеризацией, но она также применима в случаях, когда независимые серверы разделяют общую цель, такую как запуск веб-сайта, бизнес-приложения, веб-сервиса или другого IT-ресурса.

## Challenges

Самая очевидная проблема, с которой сталкивается кластеризация, - это увеличение сложности установки и обслуживания. Операционная система, приложение и его зависимости должны быть установлены и обновлены на каждом узле.

Это становится еще более сложным, если узлы в кластере неоднородны. Использование ресурсов для каждого узла также должно быть тщательно отслежено, а журналы должны быть агрегированы, чтобы убедиться, что программное обеспечение работает правильно.

Кроме того, управление хранилищем становится более сложным, общее устройство хранения должно предотвращать перезапись узлов друг другом, и распределенные хранилища данных должны быть синхронизированы.

## Примеры

Кластеризация широко распространена в IT-индустрии и часто многие технологии и сервисы поддерживают того или иного рода clustering-режим. Например:

- Контейнеры (e.g. [Kubernetes](https://kubernetes.io), [Amazon ECS](https://aws.amazon.com/ecs))
- СУБД (e.g. [Cassandra](https://cassandra.apache.org/_/index.html), [MongoDB](https://www.mongodb.com))
- Кэш (e.g. [Redis](https://redis.io/docs/manual/scaling))

# Caching

_"В IT есть только две сложные вещи: инвалидация кэша и вопросы именования." - Phil Karlton_

![caching](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/caching/caching.png)

Кэш в первую очередь предназначен для увеличения производительности извлечения данных, сокращая необходимость доступа к более медленному основному уровню хранения. Жертвуя емкостью ради скорости, кэш обычно хранит подмножество данных временно, в отличие от баз данных, данные в которых обычно полные и долговечные.

Кэши используют принцип локальности ссылок _"недавно запрошенные данные вероятно будут запрошены снова"._

## Caching and Memory

Как память компьютера, кэш представляет собой компактную, быстродействующую память, которая хранит данные в иерархии уровней, начиная с уровня один и последовательно продвигаясь оттуда. Они обозначаются как L1, L2, L3 и так далее. Кэш также записывается по запросу, например, когда произошло обновление и новые данные нужно сохранить в кэше, заменяя старые данные, которые были сохранены.

Независимо от того, читается ли или записывается кэш, это происходит блок за блоком. Каждый блок также имеет тег, который содержит местоположение, где данные были сохранены в кэше. Когда данные запрашиваются из кэша, происходит поиск по тегам, чтобы найти конкретный контент, который необходим на уровне один (L1) памяти. Если правильные данные не найдены, производятся дополнительные поиски в L2.

Если данные не найдены там, поиски продолжаются в L3, затем в L4 и так далее, пока они не будут найдены, затем они считываются и загружаются. Если данные вообще не найдены в кэше, они записываются в него для быстрого извлечения в следующий раз.

## Cache hit and Cache miss

### Cache hit

Cache hit - это ситуация, когда запрашиваемые данные успешно получены из кэша. Теги быстро ищутся в памяти и когда данные найдены и прочитаны это называется cache hit.

**Cold, Warm, and Hot Caches**

Cache-hit принято характеризовать словами cold, warm или hot для описания скорости, с которой данные считываются.

Горячий кэш - это случай, когда данные были считаны из памяти с _максимально_ возможной скоростью. Это происходит, когда данные извлекаются из L1.

Холодный кэш - это _медленнейшая_ возможная скорость для считывания данных, хотя она все равно успешна, поэтому все равно считается кэш-попаданием. Данные просто находятся ниже в иерархии памяти, такие как в L3 или ниже.

Warm cache - используется для описания данных, которые находятся в L2 или L3. Это не так быстро, как горячий кэш, но все равно быстрее, чем холодный кэш. Обычно называть кэш теплым используется для выражения того, что он медленнее и ближе к холодному кэшу, чем к горячему.

### Промах кэша

Промах кэша происходит, когда память проверяется, и данные не находятся. В этом случае содержимое передается и записывается в кэш.

## Инвалидация кэша

Инвалидация кэша - это процесс, при котором компьютерная система объявляет записи кэша недействительными и удаляет их или заменяет их. Если данные изменяются, они должны быть инвалидированы в кэше, иначе это может вызвать несогласованное поведение приложения. Существует три вида систем кэширования:

### Write-through cache

![write-through-cache](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/caching/write-through-cache.png)

Данные записываются в кэш и в соответствующую базу данных одновременно.

**Плюсы**: Быстрое чтение, полная консистентность данных между кэшем и долговременным хранилищем.

**Минусы**: Большие задержки для операций записи.

### Write-around cache

![write-around-cache](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/caching/write-around-cache.png)

Where write directly goes to the database or permanent storage, bypassing the cache.

**Плюсы**: This may reduce latency.

**Минусы**: It increases cache misses because the cache system has to read the information from the database in case of a cache miss. As a result, this can lead to higher read latency in the case of applications that write and re-read the information quickly. Read happen from slower back-end storage and experiences higher latency.

### Write-back cache

![write-back-cache](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/caching/write-back-cache.png)

Где запись происходит только в кэширующем слое, и подтверждается сразу после завершения записи в кэш. Затем кэш асинхронно синхронизирует эту запись с базой данных.

**Преимущества**: Это приведет к снижению задержки и высокой пропускной способности для приложений с интенсивной записью.

**Недостатки**: Существует риск потери данных в случае аварии кэширующего слоя. Мы можем улучшить это, имея более одного репликата, подтверждающего запись в кэше.

## Политики вытеснения

Вот некоторые из наиболее распространенных политик вытеснения из кэша:

- **Первый вошел - первый вышел (FIFO)**: Кэш вытесняет первый доступный блок без учета того, как часто или сколько раз он использовался ранее.
- **Последний вошел - первый вышел (LIFO)**: Кэш вытесняет блок, к которому обращались последним, без учета того, как часто или сколько раз он использовался ранее.
- **Наименее недавно использованный (LRU)**: Вытесняет наименее недавно использованные элементы.
- **Наиболее недавно использованный (MRU)**: В отличие от LRU, вытесняет наиболее недавно использованные элементы.
- **Наименее часто использованный (LFU)**: Считает, насколько часто элемент нужен. Те, которые используются реже всего, вытесняются первыми.
- **Случайная замена (RR)**: Случайным образом выбирает кандидата и вытесняет его, чтобы освободить место, когда это необходимо.

## Distributed Cache

![distributed-cache](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/caching/distributed-cache.png)

Распределенный кэш - это система, которая объединяет оперативную память (RAM) нескольких компьютеров в сети в единую память данных, используемую в качестве кэша данных для быстрого доступа к данным. В то время как большинство кэшей традиционно находятся на одном физическом сервере или аппаратном компоненте, распределенный кэш может превысить ограничения по памяти одного компьютера, объединяя несколько компьютеров.

## Global Cache

![global-cache](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/caching/global-cache.png)

Как следует из названия здесь мы имеем один общий кэш, который используют все ноды приложения. Если запрашиваемые данные в глобальном кэше не найдены, то ответственность самого кэша получить отсутствующий кусок данных из стоящего за ним хранилища данных.

## Применение

Кэширование может иметь множество практических применений, таких как:

- Кэширование баз данных
- Сеть доставки контента (CDN)
- Кэширование системы доменных имен (DNS)
- Кэширование API

**Когда не использовать кэширование?**

Давайте также рассмотрим некоторые сценарии, когда не следует использовать кэш:

- Кэширование бесполезно, когда доступ к кэшу занимает столько же времени, сколько доступ к основному источнику данных.
- Кэширование работает не так хорошо, когда запросы имеют низкую повторяемость (большую случайность), потому что производительность кэширования зависит от повторяющихся шаблонов доступа к памяти.
- Кэширование неэффективно, когда данные часто изменяются, поскольку кэшированная версия становится несогласованной, и основной источник данных должен быть доступен каждый раз.

**Преимущества**

Вот некоторые преимущества кэширования:

- Улучшает производительность
- Сокращает задержку
- Уменьшает нагрузку на базу данных
- Сокращает сетевые затраты
- Увеличивает пропускную способность чтения

## Examples

Вот список некоторых популярных систем, использующихся для кэширования:

- [Redis](https://redis.io)
- [Memcached](https://memcached.org)
- [Amazon Elasticache](https://aws.amazon.com/elasticache)
- [Aerospike](https://aerospike.com)

# Content Delivery Network (CDN)

Content delivery network (CDN) - это географически распределенная группа серверов, работающих совместно для наиболее быстрой доставки интернет контента пользователю. Обычно посредством CDN клиент получает статические файлы: HTML/CSS/JS, картинки, видео.

![cdn-map](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/content-delivery-network/cdn-map.png)

## Why use a CDN?

Content Delivery Network (CDN) повышает доступность и избыточность ресурсов, одновременно снижая затраты на трафик и улучшая безопасность. Предоставляя контент через CDN можно значительно повысить скорость, поскольку пользователи будут получать ресурсы из дата-центров, расположенных рядом и одновременно наши сервера освободятся от части нагрузки.

## How does a CDN work?

![cdn](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/content-delivery-network/cdn.png)

В CDN (сети доставки контента) исходный сервер содержит оригинальные версии контента, в то время как краевые серверы представлены множеством и распределены по различным местоположениям по всему миру.

Для минимизации расстояния между посетителями и сервером веб-сайта CDN хранит кэшированную версию своего контента в нескольких географических точках, известных как краевые местоположения. Каждое краевое местоположение содержит несколько кэширующих серверов, ответственных за доставку контента посетителям в своей близости.

Как только статические ресурсы кэшированы на всех серверах CDN для определенного местоположения, все последующие запросы посетителей веб-сайта к статическим ресурсам будут обслуживаться с этих краевых серверов, а не с источника, тем самым уменьшая нагрузку на источник и повышая масштабируемость.

Например, когда кто-то в Великобритании запрашивает наш веб-сайт, который может быть размещен в США, он будет обслуживаться из ближайшего краевого местоположения, такого как Лондонское краевое местоположение. Это намного быстрее, чем полный запрос к исходному серверу, что сокращает задержку.

## Types

CDNs сервисы в целом делятся на два типа:

### Push CDNs

Push CDN'ы получают новый контент при каждом изменении на сервере. Мы полностью отвечаем за предоставление контента, загрузку напрямую в CDN и изменение URL-адресов, чтобы они указывали на CDN. Мы можем настраивать срок действия контента и время его обновления. Контент загружается только тогда, когда он новый или измененный, минимизируя трафик, но максимизируя использование хранилища.

Сайты с небольшим количеством трафика или сайты с контентом, который не часто обновляется, хорошо работают с push CDN. Контент размещается на CDN только один раз, вместо того чтобы быть периодически запрашиваемым.

### Pull CDNs

В случае Pull CDN кэш обновляется на основе запроса. Когда клиент отправляет запрос, требующий получения статических ресурсов из CDN, если их нет в CDN, то он будет получать вновь обновленные ресурсы из исходного сервера и заполнять свой кэш этими новыми ресурсами, а затем отправлять эти новые кэшированные ресурсы пользователю.

В отличие от Push CDN, это требует меньше обслуживания, потому что обновления кэша на узлах CDN выполняются на основе запросов клиента к исходному серверу. Сайты с высоким трафиком хорошо работают с Pull CDN, поскольку трафик более равномерно распределен, и на CDN остается только недавно запрошенный контент.

## Недостатки

Как мы все знаем, хорошие вещи приносят дополнительные расходы, поэтому давайте обсудим некоторые недостатки CDN:

- **Дополнительные расходы**: Использование CDN может быть дорогим, особенно для сервисов с высоким трафиком.
- **Ограничения**: Некоторые организации и страны заблокировали домены или IP-адреса популярных CDN.
- **Местоположение**: Если большинство нашей аудитории находится в стране, где у CDN нет серверов, данные на нашем веб-сайте могут приходиться проходить большее расстояние, чем без использования какого-либо CDN.

## Примеры

Вот несколько широко используемых CDN:

- [Amazon CloudFront](https://aws.amazon.com/cloudfront)
- [Google Cloud CDN](https://cloud.google.com/cdn)
- [Cloudflare CDN](https://www.cloudflare.com/cdn)
- [Fastly](https://www.fastly.com/products/cdn)

# Proxy

Прокси-сервер - это посредник, являющийся промежуточным аппаратным или программным обеспечением между клиентом и сервером. Он получает запросы от клиентов и передает их на исходные серверы. Обычно прокси используются для фильтрации запросов, регистрации запросов или иногда трансформации запросов (добавление/удаление заголовков, шифрование/дешифрование или сжатие).

## Types

Существуют два типа прокси:

### Forward Proxy

Прямой прокси, часто называемый просто прокси или прокси сервер или веб-прокси - это сервер, который расположен перед определенными клиентскими машинами. Когда с этих компьютеров делаются запросы к сайтам и сервисам в интернете, прокси сервер перехватывает эти запросы и затем взаимодействует с веб-серверами от имени этих клиентов, как посредник (middleman).

![forward-proxy](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/proxy/forward-proxy.png)

**Преимущества**

Вот некоторые преимущества прокси-сервера:

- Блокировка доступа к определенному контенту
- Позволяет получать доступ к [ограниченному географически](https://en.wikipedia.org/wiki/Geo-blocking) контенту
- Обеспечивает анонимность
- Избегает других ограничений в интернете

Хотя прокси обеспечивают анонимность, они всё ещё могут отслеживать наши личные данные. Установка и обслуживание прокси-сервера могут быть дорогостоящими и требуют конфигураций.

### Reverse Proxy

Обратный прокси-сервер - это сервер, который находится перед одним или несколькими веб-серверами и перехватывает запросы от клиентов. Когда клиенты отправляют запросы на исходный сервер веб-сайта, эти запросы перехватываются обратным прокси-сервером.

Разница между прямым и обратным прокси-серверами незначительна, но важна. Упрощенным способом описания этой разницы можно назвать то, что прямой прокси-сервер находится перед клиентом и гарантирует, что ни один исходный сервер никогда не общается напрямую с этим конкретным клиентом. С другой стороны, обратный прокси-сервер находится перед исходным сервером и гарантирует, что ни один клиент никогда не общается напрямую с этим исходным сервером.

![reverse-proxy](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/proxy/reverse-proxy.png)

Внедрение обратного прокси приводит к увеличению сложности. Одиночный обратный прокси является единой точкой отказа, настройка нескольких обратных прокси (т.е. резервирование) еще более увеличивает сложность.

**Преимущества**

Вот некоторые преимущества использования обратного прокси:

- Улучшенная безопасность
- Кэширование
- Шифрование SSL
- Балансировка нагрузки
- Масштабируемость и гибкость

## Балансировщик vs Обратный прокси

Подождите, разве обратный прокси похож на балансировщик нагрузки? Ну, нет, так как балансировщик нагрузки полезен, когда у нас есть несколько серверов. Часто балансировщики направляют трафик на набор серверов, выполняющих одну и ту же функцию, в то время как обратные прокси могут быть полезны даже с одним веб-сервером или сервером приложений. Обратный прокси также может действовать как балансировщик нагрузки, но не наоборот.

Да, вы правы! Хотя как обратные прокси, так и балансировщики нагрузки могут находиться между клиентами и серверами, они выполняют разные функции.

Балансировщик нагрузки в первую очередь используется для распределения входящих запросов клиентов по нескольким серверам, чтобы гарантировать, что ни один сервер не перегружен, тем самым улучшая надежность и масштабируемость. Он особенно полезен в условиях высокого трафика, когда несколько серверов выполняют одну и ту же функцию.

С другой стороны, обратный прокси сосредоточен на перехвате запросов клиентов и их пересылке на сервера внутри сети. Он часто используется для повышения безопасности, улучшения производительности и предоставления дополнительных функций, таких как кэширование и завершение SSL. Обратный прокси также может действовать как балансировщик нагрузки, распределяя запросы между несколькими серверами, но его функциональность превосходит простое балансирование нагрузки.

Таким образом, хотя обратный прокси может выполнять роль балансировщика нагрузки, балансировщик нагрузки не может выполнять все функции обратного прокси.

## Примеры

Ниже приведены некоторые популярные прокси решения:

- [Nginx](https://www.nginx.com)
- [HAProxy](http://www.haproxy.org)
- [Traefik](https://doc.traefik.io/traefik)
- [Envoy](https://www.envoyproxy.io)

# Доступность

Доступность - это время, в течение которого система остается работоспособной для выполнения своих функций в определенный период. Это простая мера процента времени, в течение которого система, сервис или устройство остается работоспособным в нормальных условиях.

## Девятки доступности

Доступность часто количественно измеряется как время безотказной работы (или простой) в процентах от времени доступности службы. Обычно измеряется в количестве 9.

$$
Доступность = \frac{Время \space безотказной \space работы}{(Время \space безотказной \space работы + Время \space простоя)}
$$

Если доступность составляет 99,00%, говорят о "2 девятках" доступности, и если это 99,9%, то говорят о "3 девятках" и так далее.

| Доступность (Проценты)  | Простой (Год)      | Простой (Месяц)   | Простой (Неделя)   |
| ----------------------- | ------------------ | ----------------- | ------------------ |
| 90% (одна девятка)     | 36.53 дня         | 72 часа          | 16.8 часа         |
| 99% (две девятки)      | 3.65 дня          | 7.20 часа        | 1.68 часа         |
| 99.9% (три девятки)    | 8.77 часа         | 43.8 минуты      | 10.1 минута       |
| 99.99% (четыре девятки)| 52.6 минуты       | 4.32 минуты      | 1.01 минута       |
| 99.999% (пять девяток) | 5.25 минуты       | 25.9 секунды     | 6.05 секунд       |
| 99.9999% (шесть девяток)| 31.56 секунд      | 2.59 секунд      | 604.8 миллисекунд |
| 99.99999% (семь девяток)| 3.15 секунд       | 263 миллисекунд  | 60.5 миллисекунд  |
| 99.999999% (восемь девяток)| 315.6 миллисекунд | 26.3 миллисекунд | 6 миллисекунд     |
| 99.9999999% (девять девяток)| 31.6 миллисекунд | 2.6 миллисекунды | 0.6 миллисекунд   |

## Доступность в последовательном и параллельном исполнении

Если сервис состоит из нескольких компонентов, подверженных отказам, общая доступность сервиса зависит от того, находятся ли компоненты в последовательности или в параллели.

### Последовательное исполнение

Общая доступность уменьшается, когда два компонента находятся в последовательности.

$$
Доступность \space (Общая) = Доступность \space (Foo) * Доступность \space (Bar)
$$

Например, если у обоих `Foo` и `Bar` каждый имеет доступность 99.9%, их общая доступность в последовательности составит 99.8%.

### Параллельное исполнение

Общая доступность увеличивается, когда два компонента находятся в параллели.

$$
Доступность \space (Общая) = 1 - (1 - Доступность \space (Foo)) * (1 - Доступность \space (Bar))
$$

Например, если у обоих `Foo` и `Bar` каждый имеет доступность 99.9%, их общая доступность в параллели составит 99.9999%.

## Доступность против Надежности

Если система надежна, она доступна. Однако, если она доступна, это не обязательно означает, что она надежна. Другими словами, высокая надежность способствует высокой доступности, но возможно достичь высокой доступности даже с ненадежной системой.

## Высокая доступность против Устойчивости к сбоям

И высокая доступность, и устойчивость к сбоям применяются для обеспечения высокого уровня времени безотказной работы. Однако они достигают цели по-разному.

Устойчивая к сбоям система не имеет прерывания обслуживания, но требует значительно более высоких затрат, в то время как высокодоступная система имеет минимальные перерывы в обслуживании. Для обеспечения устойчивости к сбоям требуется полная аппаратная избыточность, так как при отказе основной системы без потери времени безотказной работы должна вступить в действие другая система.

# Масштабируемость

Масштабируемость - это мера того, насколько хорошо система реагирует на изменения, добавляя или удаляя ресурсы для удовлетворения требований.

![scalability](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-I/scalability/scalability.png)

## Горизонтальное масштабирование

Горизонтальное масштабирование (также известное как масштабирование вверх) расширяет масштабируемость системы путем добавления большей мощности к существующему компьютеру. Другими словами, горизонтальное масштабирование означает улучшение возможностей приложения путем увеличения мощности оборудования.

### Преимущества

- Прост в реализации
- Легче управлять
- Данные согласованы

### Недостатки

- Риск высокого времени простоя
- Труднее обновить
- Может быть единой точкой отказа

## Вертикальное масштабирование

Вертикальное масштабирование (также известное как масштабирование вниз) расширяет масштаб системы путем добавления большего количества машин. Оно улучшает производительность сервера путем добавления большего количества экземпляров к существующему пулу серверов, позволяя более равномерно распределить нагрузку.

### Преимущества

- Увеличенная избыточность
- Лучшая устойчивость к отказам
- Гибкость и эффективность
- Более простое обновление

### Недостатки

- Увеличенная сложность
- Несогласованность данных
- Увеличенная нагрузка на службы нижнего уровня

# Хранение

Хранение - это механизм, позволяющий системе сохранять данные, как временно, так и постоянно. Эта тема часто пропускается в контексте проектирования системы, однако важно иметь базовое понимание некоторых общих типов техник хранения, которые могут помочь нам настроить наши хранилища более эффективно. Давайте обсудим некоторые важные концепции хранения:

## RAID

RAID (Redundant Array of Independent Disks) - это способ сохранения одних и тех же данных на нескольких жестких дисках или твердотельных накопителях (SSD) для защиты данных в случае отказа диска.

Существуют разные уровни RAID, и не все из них имеют цель обеспечить избыточность. Давайте обсудим некоторые часто используемые уровни RAID:

- **RAID 0**: Также известный как разделение на полосы, данные равномерно разбиваются на все диски в массиве.
- **RAID 1**: Также известный как зеркалирование, по крайней мере, два диска содержат точную копию набора данных. Если один диск выходит из строя, другие продолжат работу.
- **RAID 5**: Разделение с четностию. Требует использования как минимум 3 дисков, разделение данных на несколько дисков, как RAID 0, но также имеет четность, распределенную по дискам.
- **RAID 6**: Разделение с двойной четностью. RAID 6 похож на RAID 5, но данные о четности записываются на два диска.
- **RAID 10**: Комбинирует разделение на полосы и зеркалирование из RAID 0 и RAID 1. Обеспечивает безопасность путем зеркалирования всех данных на вторичных дисках и одновременного разделения на каждый набор дисков для ускорения передачи данных.

### Сравнение

Давайте сравним все особенности различных уровней RAID:

| Характеристики      | RAID 0   | RAID 1               | RAID 5               | RAID 6                      | RAID 10                                  |
| --------------------| -------- | -------------------- | -------------------- | ---------------------------| ---------------------------------------- |
| Описание             | Полосование | Зеркалирование      | Полосование с четности | Полосование с двойной четностью | Полосование и зеркалирование        |
| Минимальное количество дисков | 2    | 2                    | 3                    | 4                           | 4                                        |
| Производительность чтения  | Высокая  | Высокая            | Высокая              | Высокая                     | Высокая                                  |
| Производительность записи   | Высокая  | Средняя            | Высокая              | Высокая                     | Средняя                                  |
| Стоимость            | Низкая   | Высокая              | Низкая               | Низкая                      | Высокая                                  |
| Устойчивость к отказам | Нет     | Отказ одного диска  | Отказ одного диска  | Отказ двух дисков           | До одного отказа диска в каждом подмассиве |
| Использование емкости  | 100%     | 50%                  | 67%-94%              | 50%-80%                     | 50%                                      |

## Тома

Том - это фиксированный объем хранения на диске или ленте. Термин "том" часто используется как синоним для самого хранилища, но возможно, что один диск содержит более одного тома, или том может охватывать более одного диска.

## File storage

Хранилище файлов - это решение для хранения данных в виде файлов и представления их конечным пользователям в виде иерархической структуры каталогов. Основное преимущество заключается в том, что это предоставляет простое в использовании решение для хранения и извлечения файлов. Для поиска файла в файловом хранилище требуется полный путь к файлу. Это экономично и легко структурировано и обычно находится на жестких дисках, что означает, что для пользователя и на самом диске оно выглядит одинаково.

Example: [Amazon EFS](https://aws.amazon.com/efs), [Azure files](https://azure.microsoft.com/en-in/services/storage/files), [Google Cloud Filestore](https://cloud.google.com/filestore), etc.

## Block storage

Блочное хранилище делит данные на блоки (части) и хранит их как отдельные элементы. Каждому блоку данных присваивается уникальный идентификатор, что позволяет системе хранения размещать меньшие части данных там, где это наиболее удобно.

Блочное хранилище также отделяет данные от сред пользователей, что позволяет данным распределяться по нескольким средам. Это создает несколько путей к данным и позволяет пользователю быстро их извлекать. Когда пользователь или приложение запрашивает данные из блочной системы хранения, подлежащая система хранения собирает блоки данных и представляет данные пользователю или приложению.

Example: [Amazon EBS](https://aws.amazon.com/ebs).

## Object Storage

Object storage - также известный как object-based storage, разбивает файлы на части, называемые объектами. И затем эти объекты хранятся в едином репозитории, которое может быть распределено по разным сетевым системам.

Пример: [Amazon S3](https://aws.amazon.com/s3), [Azure Blob Storage](https://azure.microsoft.com/en-in/services/storage/blobs), [Google Cloud Storage](https://cloud.google.com/storage), etc.

## NAS

NAS (Network Attached Storage) - это устройство хранения данных, подключенное к сети, которое позволяет хранить и извлекать данные из центрального местоположения для авторизованных пользователей сети. Устройства NAS гибкие, что означает, что по мере необходимости дополнительного хранилища мы можем добавлять к тому, что у нас уже есть. Они быстрее, менее затратны и обеспечивают все преимущества общедоступного облака на месте, предоставляя нам полный контроль.

## HDFS

Hadoop Distributed File System (HDFS) - это распределенная файловая система, предназначенная для работы на оборудовании стандартного класса. HDFS обладает высокой стойкостью к отказам и спроектирована для развертывания на недорогом оборудовании. Она обеспечивает высокую пропускную способность доступа к данным приложений и подходит для приложений с большими объемами данных. У HDFS много сходств с существующими распределенными файловыми системами.

HDFS спроектирована для надежного хранения очень больших файлов на машинах в больших кластерах. Она хранит каждый файл как последовательность блоков, причем все блоки в файле, кроме последнего блока, имеют одинаковый размер. Блоки файла реплицируются для обеспечения устойчивости к отказам.

# Базы данных и СУБД

## Что такое база данных?

База данных - это организованная коллекция структурированной информации, или данных, обычно хранящаяся электронно в компьютерной системе. База данных обычно управляется Системой Управления Базами Данных (СУБД). Вместе данные и СУБД, а также связанные с ними приложения, называются базовой системой, часто сокращенно называемой просто базой данных.

## Что такое СУБД?

Для работы с базой данных обычно требуется комплексная программа для работы с базами данных, известная как Система Управления Базами Данных (СУБД). СУБД служит интерфейсом между базой данных и ее конечными пользователями или программами, позволяя пользователям извлекать, обновлять и управлять организацией и оптимизацией информации. СУБД также облегчает наблюдение и контроль за базами данных, обеспечивая различные административные операции, такие как мониторинг производительности, настройка и резервное копирование и восстановление.

## Компоненты

Вот некоторые общие компоненты, присутствующие в различных базах данных:

### Схема

Роль схемы состоит в определении формы структуры данных и указании, какие виды данных могут располагаться где. Схемы могут быть строго применяемыми ко всей базе данных, слабо применяемыми к части базы данных или вообще отсутствовать.

### Таблица

Каждая таблица содержит различные столбцы, как в электронной таблице. Таблица может иметь как два столбца, так и сто или более столбцов, в зависимости от вида информации, размещаемой в таблице.

### Столбец

Столбец содержит набор значений определенного типа, одно значение для каждой строки базы данных. Столбец может содержать текстовые значения, числа, перечисления, временные метки и т. д.

### Строка

Данные в таблице записываются в строках. В таблице может быть тысячи или миллионы строк с какой-либо определенной информацией.

## Types

![database-types](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/databases-and-dbms/database-types.png)

Ниже приведены различные типы баз данных:

- **[SQL](https://karanpratapsingh.com/courses/system-design/sql-databases)**
- **[NoSQL](https://karanpratapsingh.com/courses/system-design/nosql-databases)**
  - Document
  - Key-value
  - Graph
  - Timeseries
  - Wide column
  - Multi-model

SQL и NoSQL базы данных это большие темы, которые будут рассмотрены отдельно в разделах [SQL базы данных](https://karanpratapsingh.com/courses/system-design/sql-databases) и [NoSQL базы данных](https://karanpratapsingh.com/courses/system-design/nosql-databases). Узнай, чем они отличаются друг от друга в разделе [SQL vs NoSQL databases](https://karanpratapsingh.com/courses/system-design/sql-vs-nosql-databases).

## Проблемы

Некоторые распространенные проблемы, с которыми сталкиваются при работе с базами данных в масштабе:

- **Поглощение значительного увеличения объема данных**: Взрыв данных, поступающих от датчиков, подключенных машин и десятков других источников.
- **Обеспечение безопасности данных**: Взломы данных происходят повсюду в наши дни, и сейчас важнее, чем когда-либо, обеспечить безопасность данных, но при этом обеспечить их легкий доступ для пользователей.
- **Справление с ростом спроса**: Компаниям необходим доступ к данным в реальном времени для поддержки своевременного принятия решений и использования новых возможностей.
- **Управление и поддержка базы данных и инфраструктуры**: Поскольку базы данных становятся более сложными, а объемы данных растут, компании сталкиваются с расходами на привлечение дополнительных кадров для управления их базами данных.
- **Устранение ограничений масштабируемости**: Бизнес должен расти, чтобы выжить, и его управление данными должно расти вместе с ним. Однако очень сложно предсказать, сколько мощности потребуется компании, особенно с базами данных на собственных серверах.
- **Обеспечение требований к местоположению данных, суверенитету данных или требованиям к задержке**: Некоторые организации имеют использование, которые лучше всего подходят для выполнения на собственных серверах. В таких случаях идеальными являются инженерные системы, предварительно настроенные и предварительно оптимизированные для выполнения базы данных.

# SQL databases

Реляционная база данных (SQL) - это набор данных с заранее определенными отношениями между ними. Эти данные организованы в виде набора таблиц с колонками и строками. Таблицы используются для хранения информации об объектах, представленных в базе данных. Каждая колонка в таблице содержит определенный тип данных, а поле хранит фактическое значение атрибута. Строки в таблице представляют собой набор связанных значений одного объекта или сущности.

Каждая строка в таблице может быть помечена уникальным идентификатором, называемым первичным ключом, и строки между несколькими таблицами могут быть связаны с использованием внешних ключей. Эти данные могут быть доступны различными способами, не изменяя сами таблицы базы данных. Базы данных SQL обычно следуют модели согласованности [ACID consistency model](https://karanpratapsingh.com/courses/system-design/acid-and-base-consistency-models#acid).

## Materialized views

Материализованный вид - это предварительно вычисленный набор данных, полученный из спецификации запроса и сохраненный для последующего использования. Поскольку данные предварительно вычислены, выполнение запроса к материализованному виду происходит быстрее, чем выполнение запроса к базовой таблице вида. Это различие в производительности может быть значительным, когда запрос выполняется часто или достаточно сложен.

Он также позволяет подмножества данных и улучшает производительность сложных запросов, выполняемых на больших объемах данных, что уменьшает нагрузку на сеть. Существуют и другие способы использования материализованных видов, но они в основном используются для повышения производительности и репликации.

## N+1 query problem

Проблема запроса N+1 возникает, когда слой доступа к данным выполняет N дополнительных SQL-запросов для извлечения тех же данных, которые могли быть получены при выполнении первичного SQL-запроса. Чем больше значение N, тем больше запросов будет выполнено, тем больше будет влияние на производительность.

Это часто наблюдается в GraphQL и инструментах ORM (отображение объектно-реляционной модели), и может быть решено путем оптимизации SQL-запроса или использования загрузчика данных, который пакетирует последовательные запросы и делает единственный запрос к данным внутри.

## Преимущества

Давайте посмотрим на некоторые преимущества использования реляционных баз данных:

- Простота и точность
- Доступность данных
- Консистентность данных
- Гибкость

## Недостатки

Ниже приведены недостатки реляционных баз данных:

- Дорогая поддержка (обслуживание)
- Тяжелый процесс модификации схемы
- Проблемы производительности при сложных запросах (join, denormalization, etc.)
- Тяжелый процесс горизонтального масштабирования

## Примеры

Вот примеры популярных реляционных баз данных:

- [PostgreSQL](https://www.postgresql.org)
- [MySQL](https://www.mysql.com)
- [MariaDB](https://mariadb.org)
- [Amazon Aurora](https://aws.amazon.com/rds/aurora)

## Базы данных NoSQL

NoSQL - это широкая категория, которая включает в себя любую базу данных, которая не использует SQL в качестве основного языка доступа к данным. Эти типы баз данных иногда также называют нереляционными базами данных. В отличие от реляционных баз данных, данные в базе данных NoSQL не обязаны соответствовать предварительно определенной схеме. Базы данных NoSQL следуют [модели согласованности BASE](https://karanpratapsingh.com/courses/system-design/acid-and-base-consistency-models#base).

Ниже приведены различные типы баз данных NoSQL:

### Документ

Документоориентированная база данных (также известная как база данных ориентированная на документы или хранилище документов) - это база данных, которая хранит информацию в документах. Они являются универсальными базами данных, которые обслуживают различные сценарии использования как транзакционных, так и аналитических приложений.

**Преимущества**

- Интуитивно-понятные и гибкие
- Хорошо горизонтально масштабируются
- Отсутствие схемы

**Недостатки**

- Отсутствие схемы
- Нет реляционных связей

**Примеры**

- [MongoDB](https://www.mongodb.com)
- [Amazon DocumentDB](https://aws.amazon.com/documentdb)
- [CouchDB](https://couchdb.apache.org)

### Key-value

**Преимущества**

- Простота и производительность
- Высокая масштабируемость для высоких объемов трафика
- Управление сеансами
- Оптимизированные поиски

**Недостатки**

- Основные операции CRUD
- Нельзя фильтровать значения
- Отсутствие возможностей индексации и сканирования
- Не оптимизированы для сложных запросов

**Примеры**

- [Redis](https://redis.io)
- [Memcached](https://memcached.org)
- [Amazon DynamoDB](https://aws.amazon.com/dynamodb)
- [Aerospike](https://aerospike.com)

### Graph

Графовая база данных - это NoSQL база данных, которая использует графовые структуры для семантических запросов с узлами, ребрами и свойствами для представления и хранения данных вместо таблиц или документов.

Граф связывает элементы данных в хранилище с набором узлов и ребер, ребра представляют отношения между узлами. Отношения позволяют прямо связывать данные в хранилище и, во многих случаях, извлекать их с помощью одной операции.

**Преимущества**

- Скорость запросов
- Гибкость и адаптивность
- Явное представление данных

**Недостатки**

- Сложность
- Отсутствие стандартизированного языка запросов

**Примеры использования**

- Выявление мошенничества
- Рекомендательные системы
- Социальные сети
- Картографирование сети

**Примеры**

- [Neo4j](https://neo4j.com)
- [ArangoDB](https://www.arangodb.com)
- [Amazon Neptune](https://aws.amazon.com/neptune)
- [JanusGraph](https://janusgraph.org)

### Временные ряды

База данных временных рядов - это база данных, оптимизированная для данных с метками времени или временных рядов.

**Преимущества**

- Быстрая вставка и извлечение данных
- Эффективное хранение данных

**Примеры использования**

- Данные Интернета вещей (IoT)
- Анализ метрик
- Мониторинг приложений
- Понимание финансовых тенденций

**Примеры**

- [InfluxDB](https://www.influxdata.com)
- [Apache Druid](https://druid.apache.org)

### Широкие колонки

Базы данных с широкими колонками, также известные как хранилища с широкими колонками, не имеют схемы данных. Данные хранятся в семействах столбцов, а не в строках и столбцах.

**Преимущества**

- Высокая масштабируемость, могут обрабатывать петабайты данных
- Идеально подходят для реального времени приложений обработки больших данных

**Недостатки**

- Дорого
- Увеличенное время записи

**Примеры использования**

- Бизнес-аналитика
- Хранение данных на основе атрибутов

**Примеры**

- [BigTable](https://cloud.google.com/bigtable)
- [Apache Cassandra](https://cassandra.apache.org)
- [ScyllaDB](https://www.scylladb.com)

### Мульти-модельные

Мульти-модельные базы данных объединяют различные модели баз данных (например, реляционные, графовые, ключ-значение, документы и т. д.) в единое, интегрированное хранилище данных. Это означает, что они могут адаптироваться к различным типам данных, индексам, запросам и хранить данные в более чем одной модели.

**Преимущества**

- Гибкость
- Подходит для сложных проектов
- Согласованные данные

**Недостатки**

- Сложность
- Меньшая зрелость

**Примеры**

- [ArangoDB](https://www.arangodb.com)
- [Azure Cosmos DB](https://azure.microsoft.com/en-in/services/cosmos-db)
- [Couchbase](https://www.couchbase.com)

# SQL vs NoSQL databases

В мире баз данных существуют два основных типа решений: SQL (реляционные) и NoSQL (нереляционные) базы данных. Оба они отличаются способом, как они были созданы, типом информации, которую они хранят, и способом её хранения. Реляционные базы данных имеют структурированный формат и предопределенные схемы, в то время как нереляционные базы данных являются неструктурированными, распределенными и имеют динамические схемы.

## Различия на высоком уровне

Вот несколько основных различий между SQL и NoSQL:

### Хранение

SQL хранит данные в таблицах, где каждая строка представляет сущность, а каждый столбец представляет собой точку данных об этой сущности.

Базы данных NoSQL имеют различные модели хранения данных, такие как ключ-значение, граф, документ и т. д.

### Схема

В SQL каждая запись соответствует фиксированной схеме, что означает, что столбцы должны быть определены и выбраны до ввода данных, и каждая строка должна содержать данные для каждого столбца. Схему можно изменить позже, но это включает изменение базы данных с использованием миграций.

В то время как в NoSQL схемы динамичны. Поля могут добавляться на лету, и каждая _запись_ (или эквивалент) не обязана содержать данные для каждого _поля_.

### Запросы

SQL-базы данных используют SQL (структурированный язык запросов) для определения и манипулирования данными, что очень мощно.

В базе данных NoSQL запросы сосредоточены на коллекции документов. У различных баз данных разный синтаксис запросов.

### Scalability

В большинстве обычных ситуаций SQL-базы данных масштабируются вертикально, что может стать очень дорогим. Возможно масштабирование реляционной базы данных на несколько серверов, но это сложный и времязатратный процесс.

С другой стороны, NoSQL-базы данных масштабируются горизонтально, что означает, что мы легко можем добавлять больше серверов к нашей инфраструктуре NoSQL для обработки больших нагрузок. Любое дешевое аппаратное обеспечение или облачные экземпляры могут размещать базы данных NoSQL, что делает процесс намного более экономичным, чем вертикальное масштабирование. Многие технологии NoSQL также автоматически распределяют данные по серверам.

### Надежность

Для подавляющего большинства реляционных баз данных характерно соответствие стандарту ACID. Таким образом, когда речь идет о надежности данных и гарантии безопасного выполнения транзакций, SQL-базы данных остаются более надежным выбором.

Большинство решений NoSQL жертвуют соответствием стандарту ACID ради производительности и масштабируемости.

## Причины

Как всегда, мы должны выбирать ту технологию, которая лучше соответствует требованиям. Давайте рассмотрим несколько причин для выбора базы данных на основе SQL или NoSQL:

**Для SQL**

- Структурированные данные с жесткой схемой
- Реляционные данные
- Необходимость в сложных объединениях
- Транзакции
- Поиск по индексу происходит очень быстро

**Для NoSQL**

- Динамическая или гибкая схема
- Не реляционные данные
- Нет необходимости в сложных объединениях
- Очень интенсивная по данным нагрузка
- Очень высокая пропускная способность для операций ввода/вывода

# Репликация баз данных

Репликация - это процесс обмена информацией для обеспечения согласованности между избыточными ресурсами, такими как несколько баз данных, для повышения надежности, отказоустойчивости или доступности.

## Репликация мастер-реплика

Мастер обслуживает чтение и запись, реплицируя записи на один или несколько слейвов, которые обслуживают только чтение. Слейвы также могут реплицировать дополнительные слейвы по дереву. Если мастер выходит из строя, система может продолжать работу только в режиме только для чтения, пока слейв не будет повышен до мастера или не будет назначен новый мастер.

![master-slave-replication](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/database-replication/master-slave-replication.png)

### Преимущества

- Резервные копии всей базы данных почти не влияют на основной сервер.
- Приложения могут читать данные с реплик, не влияя на основной сервер.
- Реплики могут быть отключены и синхронизированы обратно с основным сервером без простоя.

### Недостатки

- Репликация добавляет больше аппаратных средств и дополнительной сложности.
- Простой и, возможно, потеря данных при отказе основного сервера.
- Вся запись также должна быть сделана на основном сервере в архитектуре мастер-реплика.
- Чем больше реплик для чтения, тем больше нам нужно реплицировать, что приведет к увеличению задержки репликации.

## Репликация мастер-мастер

Оба мастера обслуживают чтение/запись и синхронизируются друг с другом. Если отказывается один из мастеров, система может продолжать работать как с чтением, так и с записью.

![master-master-replication](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/database-replication/master-master-replication.png)

### Преимущества

- Приложения могут читать как с первого, так и со второго мастер-узла.
- Распределяет нагрузку на запись между обоими мастер-узлами.
- Простой, автоматический и быстрый переключение на резервный узел.

### Недостатки

- Не так просто настраивать и разворачивать, как мастер-слейв.
- Либо большая угроза консистентности данных, либо увеличивается задержка записи из-за синхронизации.
- Появляется проблема разрешения конфликтов по мере добавления дополнительных узлов записи и увеличения задержки.

## Synchronous vs Asynchronous replication

Основное различие между синхронным и асинхронным реплицированием заключается в том, как данные записываются на реплику. При синхронном реплицировании данные записываются одновременно на первичное хранилище и на реплику. Таким образом, первичная копия и реплика должны всегда оставаться синхронизированными.

В отличие от этого, при асинхронном реплицировании данные копируются на реплику после того, как данные уже записаны в первичное хранилище. Хотя процесс репликации может происходить почти в реальном времени, более распространено проведение репликации по расписанию, что более экономично.

# Indexes

Индексы хорошо известны в контексте баз данных, они используются для улучшения скорости операций по извлечению данных из хранилища данных. Индекс создает компромисс между увеличением накладных расходов на хранение и более медленной записью (поскольку нам необходимо записать данные и обновить индекс) в пользу более быстрых чтений. Индексы используются для быстрого определения местоположения данных без необходимости рассматривать каждую строку в таблице базы данных. Индексы могут быть созданы с использованием одного или нескольких столбцов таблицы базы данных, обеспечивая основу как для быстрого произвольного поиска, так и для эффективного доступа к упорядоченным записям.

![indexes](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/indexes/indexes.png)

Индекс представляет собой структуру данных, которую можно рассматривать как оглавление, указывающее нам местоположение, где находятся фактические данные. Таким образом, когда мы создаем индекс на столбце таблицы, мы сохраняем этот столбец и указатель на всю строку в индексе. Индексы также используются для создания различных представлений одних и тех же данных. Для больших наборов данных это отличный способ указать различные фильтры или схемы сортировки без необходимости создания нескольких дополнительных копий данных.

Одно из качеств, которым могут обладать индексы баз данных, - это **плотность** или **разреженность**. У каждого из этих качеств есть свои компромиссы. Давайте посмотрим, как работает каждый тип индекса:

## Dense Index

В плотном индексе - записи индекса создаются для каждой записи таблицы. Записи могут быть получены напрямую, така как в записи индекса помимо ключа поиска содержится указатель на реальную запись.

![dense-index](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/indexes/dense-index.png)

Плотные индексы требуют больше обслуживания по сравнению с разреженными индексами при записи. Поскольку каждая строка должна иметь запись, база данных должна поддерживать индекс при вставках, обновлениях и удалениях. Наличие записи для каждой строки также означает, что плотные индексы будут требовать больше памяти. Преимущество плотного индекса заключается в том, что значения можно быстро найти с помощью простого двоичного поиска. Плотные индексы также не накладывают каких-либо требований на упорядоченность данных.

## Sparse Index

В разряженном индексе записи создаются только для некоторых строк таблицы.

![sparse-index](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/indexes/sparse-index.png)

С разреженными индексами процесс обслуживания при записи менее интенсивен, чем у плотных индексов, поскольку они содержат только подмножество значений. Это более легкая нагрузка на обслуживание означает, что вставки, обновления и удаления будут быстрее. Меньшее количество записей также означает, что индекс будет использовать меньше памяти. Поиск данных медленнее, поскольку за двоичным поиском typically следует просмотр страницы. С разреженными индексами также необязательно при работе с упорядоченными данными.

# Normalization and Denormalization

## Термины

Прежде чем мы продолжим, давайте рассмотрим некоторые часто используемые термины в нормализации и денормализации.

### Ключи

**Первичный ключ**: Столбец или группа столбцов, которые могут быть использованы для уникальной идентификации каждой строки в таблице.

**Композитный ключ**: Первичный ключ, состоящий из нескольких столбцов.

**Суперключ**: Набор всех ключей, которые могут уникально идентифицировать все строки в таблице.

**Кандидатный ключ**: Атрибуты, которые уникально идентифицируют строки в таблице.

**Внешний ключ**: Ссылка на первичный ключ другой таблицы.

**Альтернативный ключ**: Ключи, которые не являются первичными ключами, известны как альтернативные ключи.

**Вспомогательный ключ**: Значение, сгенерированное системой, которое уникально идентифицирует каждую запись в таблице, когда ни один другой столбец не способен обладать свойствами первичного ключа.

### Зависимости

**Частичная зависимость**: Возникает, когда первичный ключ определяет другие атрибуты.

**Функциональная зависимость**: Это отношение, которое существует между двумя атрибутами, обычно между первичным ключом и неключевым атрибутом в пределах таблицы.

**Транзитивная функциональная зависимость**: Возникает, когда некоторый неключевой атрибут определяет другой атрибут.

### Аномалии

Аномалия базы данных возникает, когда в базе данных есть недостаток из-за неправильного планирования или хранения всего в плоской базе данных. Это обычно устраняется с помощью процесса нормализации.

Существует три типа аномалий базы данных:

**Аномалия вставки**: Возникает, когда мы не можем вставить определенные атрибуты в базу данных без наличия других атрибутов.

**Аномалия обновления**: Возникает в случае избыточности данных и частичного обновления. Другими словами, правильное обновление базы данных требует других действий, таких как добавление, удаление или оба действия.

**Аномалия удаления**: Возникает, когда удаление некоторых данных требует удаления других данных.

**Пример**

Давайте рассмотрим следующую таблицу, которая не нормализована:

| ID  | Name   | Role              | Team |
| --- | ------ | ----------------- | ---- |
| 1   | Peter  | Software Engineer | A    |
| 2   | Brian  | DevOps Engineer   | B    |
| 3   | Hailey | Product Manager   | C    |
| 4   | Hailey | Product Manager   | C    |
| 5   | Steve  | Frontend Engineer | D    |

Let's imagine, we hired a new person "John" but they might not be assigned a team immediately. This will cause an _insertion anomaly_ as the team attribute is not yet present.

Next, let's say Hailey from Team C got promoted, to reflect that change in the database, we will need to update 2 rows to maintain consistency which can cause an _update anomaly_.

Finally, we would like to remove Team B but to do that we will also need to remove additional information such as name and role, this is an example of a _deletion anomaly_.

### Нормализация

Нормализация - это процесс организации данных в базе данных. Это включает создание таблиц и установление отношений между этими таблицами в соответствии с правилами, разработанными как для защиты данных, так и для сделать базу данных более гибкой путем устранения избыточности и несогласованных зависимостей.
Зачем нам нужна нормализация?

Цель нормализации - устранение избыточных данных и обеспечение их согласованности. Полностью нормализованная база данных позволяет расширять свою структуру для вмещения новых типов данных без существенного изменения существующей структуры. В результате приложения, взаимодействующие с базой данных, минимально затрагиваются.

### Normal forms

**1NF**

Первая нормальная форма (1NF) устанавливает следующие правила для таблицы:

- Повторяющиеся группы не допускаются.
- Каждый набор связанных данных должен иметь первичный ключ.
- Набор связанных данных должен иметь отдельную таблицу.
- Смешивание типов данных в одном столбце не допускается.

**2NF**

Вторая нормальная форма (2NF) устанавливает следующие правила для таблицы:

- Удовлетворяет первой нормальной форме (1NF).
- Не должно быть частичной зависимости.

**3NF**

Третья нормальная форма (3NF) устанавливает следующие правила для таблицы:

- Удовлетворяет второй нормальной форме (2NF).
- Транзитивные функциональные зависимости не допускаются.

**BCNF**

Форма Бойса-Кодда (или BCNF) является немного более сильной версией третьей нормальной формы (3NF), используемой для устранения определенных видов аномалий, с которыми изначально не справляется 3NF. Иногда она также известна как 3.5 нормальная форма (3.5NF).

Для того чтобы таблица находилась в нормальной форме Бойса-Кодда (BCNF), она должна следовать следующим правилам:

- Удовлетворяет третьей нормальной форме (3NF).
- Для каждой функциональной зависимости X → Y, X должен быть суперключом.

_Существуют и другие нормальные формы, такие как 4NF, 5NF и 6NF, но мы не будем обсуждать их здесь. Ознакомьтесь с этим [удивительным видео](https://www.youtube.com/watch?v=GFQaEYEc8_8), которое подробно объясняет._

В реляционной базе данных отношение часто описывается как _"нормализованное"_, если оно соответствует третьей нормальной форме. Большинство отношений 3NF свободны от аномалий при вставке, обновлении и удалении.

Как и в случае с многими формальными правилами и спецификациями, реальные сценарии не всегда позволяют идеальное соответствие. Если вы решите нарушить одно из первых трех правил нормализации, убедитесь, что ваше приложение предвидит возможные проблемы, такие как избыточные данные и несогласованные зависимости.

### Преимущества

Вот некоторые преимущества нормализации:

- Снижает избыточность данных.
- Лучшее проектирование данных.
- Увеличивает согласованность данных.
- Обеспечивает целостность ссылочных связей.

### Недостатки

Давайте рассмотрим некоторые недостатки нормализации:

- Сложное проектирование данных.
- Медленная производительность.
- Дополнительная нагрузка при обслуживании.
- Требуются больше соединений (JOIN).

## Денормализация

Денормализация - это техника оптимизации базы данных, при которой мы добавляем избыточные данные в одну или несколько таблиц. Это помогает избежать дорогостоящих объединений в реляционной базе данных. Она стремится улучшить производительность чтения за счет некоторого снижения производительности записи. Избыточные копии данных записываются в несколько таблиц, чтобы избежать дорогостоящих объединений.

Когда данные становятся распределенными с помощью таких техник, как федерация и шардинг, управление объединениями по сети еще больше увеличивает сложность. Денормализация может избежать необходимости таких сложных объединений.

_Примечание: Денормализация не означает отмену нормализации._

### Преимущества

Давайте рассмотрим некоторые преимущества денормализации:

- Получение данных происходит быстрее.
- Запросы составляются проще.
- Уменьшение количества таблиц.
- Удобно управлять.

### Недостатки

Ниже приведены некоторые недостатки денормализации:

- Дорогие вставки и обновления.
- Увеличивает сложность проектирования базы данных.
- Увеличивает избыточность данных.
- Больше шансов на несогласованность данных.

# Модели согласованности ACID и BASE

Давайте обсудим модели согласованности ACID и BASE.

## ACID

Термин ACID означает Atomicity (Атомарность), Consistency (Согласованность), Isolation (Изолированность) и Durability (Устойчивость). Свойства ACID используются для поддержания целостности данных во время обработки транзакций.

Для поддержания согласованности до и после транзакции реляционные базы данных следуют свойствам ACID. Давайте разберем эти термины:

### Атомарность

Все операции в транзакции завершаются успешно или каждая операция отменяется.

### Согласованность

После завершения транзакции база данных имеет структурную целостность.

### Изолированность

Транзакции не конфликтуют друг с другом. Конфликтный доступ к данным управляется базой данных таким образом, что транзакции кажутся выполняющимися последовательно.

### Устойчивость

После завершения транзакции и записи и обновления данных на диске они остаются в системе даже в случае сбоя системы.

## BASE

С увеличивающимся объемом данных и высокими требованиями к доступности подход к проектированию баз данных также радикально изменился. Для повышения масштабируемости и одновременно обеспечения высокой доступности мы перемещаем логику из базы данных на отдельные серверы. Таким образом, база данных становится более независимой и сосредоточена на реальном процессе хранения данных.

В мире баз данных NoSQL транзакции ACID менее распространены, поскольку некоторые базы данных ослабляют требования к мгновенной согласованности, актуальности данных и точности для достижения других преимуществ, таких как масштабирование и устойчивость.

Свойства BASE намного менее строгие, чем гарантии ACID, но между этими двумя моделями согласованности нет прямого однозначного соответствия. Давайте разберем эти термины:

### Основная доступность

База данных кажется работающей большую часть времени.

### Мягкое состояние

Хранилища не обязаны быть согласованными при записи, и различные реплики не обязаны быть взаимно согласованными все время.

### Постепенная согласованность

Данные могут быть не согласованными немедленно, но в конечном итоге они становятся согласованными. Чтение в системе все еще возможно, даже если оно не дает правильного ответа из-за несогласованности.

## ACID vs BASE Trade-offs

Нет однозначного ответа на вопрос, нужна ли нашему приложению модель согласованности ACID или BASE. Обе модели были разработаны для удовлетворения различных требований. При выборе базы данных мы должны учитывать свойства обеих моделей и требования нашего приложения.

Учитывая слабую согласованность BASE, разработчики должны обладать более глубокими знаниями и строгостью в отношении согласованных данных, если они выбирают хранилище BASE для своего приложения. Важно знать поведение BASE выбранной базы данных и работать в рамках этих ограничений.

С другой стороны, планирование вокруг ограничений BASE иногда может быть серьезным недостатком по сравнению с простотой транзакций ACID. Полностью ACID-совместимая база данных идеально подходит для использования в случаях, когда надежность данных и согласованность являются важными.

# CAP Theorem

Теорема CAP говорит, что распределенная система может обеспечить только два из трех желаемых характеристик: Согласованность (Consistency), Доступность (Availability) и Устойчивость к разделению (Partition tolerance).

![cap-theorem](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/cap-theorem/cap-theorem.png)

### Согласованность

Согласованность означает, что все клиенты видят одни и те же данные в одно и то же время, независимо от того, к какому узлу они подключены. Для этого, когда данные записываются на один узел, они должны немедленно пересылаться или реплицироваться на все узлы в системе, прежде чем запись будет считаться "успешной".

### Доступность

Доступность означает, что любой клиент, запрашивающий данные, получает ответ, даже если один или несколько узлов вышли из строя.

### Терпимость к разделению

Терпимость к разделению означает, что система продолжает работать, несмотря на потерю сообщений или частичный сбой. Система, которая терпима к разделению, может выдержать любое количество сбоев сети, которые не приводят к полному сбою всей сети. Данные должны быть достаточно реплицированы среди комбинаций узлов и сетей, чтобы поддерживать систему в рабочем состоянии при периодических сбоях.

## Компромисс между согласованностью и доступностью

Мы живем в физическом мире и не можем гарантировать стабильность сети, поэтому распределенные базы данных должны выбирать Терпимость к разделению (P). Это предполагает компромисс между Согласованностью (C) и Доступностью (A).

### База данных CA

База данных CA обеспечивает согласованность и доступность на всех узлах. Она не может этого сделать, если есть разделение между любыми двумя узлами в системе, и, следовательно, не может обеспечить отказоустойчивость.

**Example**: [PostgreSQL](https://www.postgresql.org), [MariaDB](https://mariadb.org).

### CP database

CP база данных обеспечивает согласованность и устойчивость к разделению за счет отказа от доступности. Когда происходит разделение между любыми двумя узлами, система должна выключить неконсистентный узел до устранения разделения.

**Example**: [MongoDB](https://www.mongodb.com), [Apache HBase](https://hbase.apache.org).

### AP database

AP база данных обеспечивает доступность и устойчивость к разделению за счет согласованности. При разделении все узлы остаются доступными, но узлы, находящиеся в неправильном конце разделения, могут возвращать более старую версию данных, чем другие. Когда разделение разрешается, AP базы данных обычно синхронизируют узлы для устранения всех несогласованностей в системе.

**Example**: [Apache Cassandra](https://cassandra.apache.org), [CouchDB](https://couchdb.apache.org).

# PACELC Theorem

Теорема PACELC является расширением теоремы CAP. Теорема CAP утверждает, что в случае разделения сети (P) в распределенной системе приходится выбирать между доступностью (A) и согласованностью (C).

PACELC расширяет теорему CAP, вводя задержку (L) как дополнительный атрибут распределенной системы. Теорема утверждает, что даже когда система работает нормально в отсутствие разделений, приходится выбирать между задержкой (L) и согласованностью (C).

_The PACELC theorem was first described by [Daniel J. Abadi](https://scholar.google.com/citations?user=zxeEF2gAAAAJ)._

![pacelc-theorem](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/pacelc-theorem/pacelc-theorem.png)

Теорема PACELC была разработана для решения ключевого ограничения теоремы CAP, поскольку она не учитывает производительность или задержку.

Например, согласно теореме CAP, база данных может считаться доступной, если запрос возвращает ответ через 30 дней. Очевидно, что такая задержка была бы неприемлемой для любого прикладного приложения в реальном мире.

# Transactions

Транзакция - это серия операций с базой данных, которые считаются _"единичной рабочей единицей"_. Операции в транзакции либо все успешны, либо все откатываются. Таким образом, понятие транзакции поддерживает целостность данных в случае отказа части системы. Не все базы данных выбирают поддержку ACID-транзакций, обычно потому, что они отдают предпочтение другим оптимизациям, которые сложно или теоретически невозможно реализовать вместе.

_Обычно реляционные базы данных поддерживают ACID-транзакции, а нереляционные базы данных нет (существуют исключения)_.

## Состояния

Транзакция базы данных может иметь одно из следующих состояний:

![transaction-states](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/transactions/transaction-states.png)

### Active

В этом состоянии транзакция выполняется. Это начальное состояние каждой транзакции.

### Partially Committed

Когда транзакция выполняет свою последнюю операцию, она находится в состоянии частичного подтверждения.

### Committed

Если транзакция успешно выполняет все свои операции, она считается подтвержденной. Все ее эффекты теперь окончательно установлены в системе баз данных.

### Failed

Транзакция находится в состоянии отказа, если любая из проверок, выполняемых системой восстановления базы данных, завершается неудачно. Транзакция в состоянии отказа больше не может продолжаться.

### Aborted

Если любая из проверок завершается неудачно и транзакция находится в состоянии отказа, то менеджер восстановления отменяет все ее операции записи в базе данных, чтобы вернуть базу данных к исходному состоянию до выполнения транзакции. Транзакции в этом состоянии абортируются.

Модуль восстановления базы данных может выбрать одну из двух операций после аборта транзакции:

- Перезапустить транзакцию
- Отменить транзакцию

### Terminated

Если нет никакого отката или транзакция происходит из состояния _подтверждено_, то система согласована и готова к новой транзакции, а старая транзакция завершается.

# Распределенные транзакции

Распределенная транзакция - это набор операций с данными, выполняемых в двух или более базах данных. Обычно она координируется через отдельные узлы, соединенные сетью, но также может охватывать несколько баз данных на одном сервере.

## Why do we need distributed transactions?

В отличие от ACID-транзакции в одной базе данных, распределенная транзакция включает изменение данных в нескольких базах данных. Следовательно, обработка распределенных транзакций более сложна, поскольку база данных должна согласовать фиксацию или откат изменений в транзакции как самостоятельной единицы.

Другими словами, все узлы должны фиксировать изменения, либо все должны отменить операции, и вся транзакция откатывается. Вот почему нам нужны распределенные транзакции.

Теперь давайте рассмотрим некоторые популярные решения для распределенных транзакций:

## Two-Phase commit

![two-phase-commit](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/distributed-transactions/two-phase-commit.png)

Протокол двухфазного коммита (2PC) - это распределенный алгоритм, который координирует все процессы, участвующие в распределенной транзакции, в определении, следует ли фиксировать или отменить (откатить) транзакцию.

Этот протокол достигает своей цели даже во многих случаях временного сбоя системы и поэтому широко используется. Однако он не является устойчивым ко всем возможным конфигурациям отказа, и в редких случаях может потребоваться ручное вмешательство для исправления исходного результата.

Этот протокол требует наличия узла-координатора, который фактически координирует и наблюдает за транзакцией на различных узлах. Координатор пытается достичь консенсуса среди набора процессов в две фазы, отсюда и название.

### Фазы

Двухфазное подтверждение состоит из следующих фаз:

**Фаза подготовки**

В фазе подготовки координирующий узел собирает согласие от каждого участвующего узла. Транзакция будет отменена, если каждый узел не ответит, что он _подготовлен_.

**Фаза подтверждения**

Если все участники ответили координатору, что они _подготовлены_, то координатор запрашивает у всех узлов подтверждение транзакции. Если произойдет сбой, транзакция будет откатываться.

### Проблемы

В двухфазном протоколе подтверждения могут возникнуть следующие проблемы:

- Что, если один из узлов выйдет из строя?
- Что, если сам координатор выйдет из строя?
- Это блокирующий протокол.

## Трех-фазовый коммит

![three-phase-commit](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/distributed-transactions/three-phase-commit.png)

Трехфазный коммит (3PC) является расширением двухфазного коммита, где фаза коммита разбивается на две фазы. Это помогает с проблемой блокировки, которая возникает в протоколе двухфазного коммит.
Фазы

Трехфазный коммит состоит из следующих фаз:

Фаза подготовки

Эта фаза такая же, как в двухфазном коммите.

Фаза предварительного коммита

Координатор отправляет сообщение о предварительном коммите, и все участвующие узлы должны его подтвердить. Если участник не успевает получить это сообщение вовремя, тогда транзакция аннулируется.

Фаза подтверждения

Этот шаг также аналогичен протоколу двухфазного коммита.
Почему фаза предварительного подтверждения полезна?

Фаза предварительного подтверждения выполняет следующее:

    Если узлы-участники найдены на этой фазе, это означает, что каждый участник завершил первую фазу. Завершение фазы подготовки гарантировано.
    Теперь каждая фаза может завершиться по тайм-ауту и избежать бесконечных ожиданий.

## Sagas

![sagas](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/distributed-transactions/sagas.png)

Сага представляет собой последовательность локальных транзакций. Каждая локальная транзакция обновляет базу данных и публикует сообщение или событие, чтобы запустить следующую локальную транзакцию в саге. Если локальная транзакция завершается неудачей из-за нарушения бизнес-правила, то сага выполняет серию компенсирующих транзакций, которые отменяют изменения, внесенные предыдущими локальными транзакциями.

### Координация

Существует два распространенных подхода к реализации:

- **Хореография**: Каждая локальная транзакция публикует события домена, которые запускают локальные транзакции в других сервисах.
- **Оркестровка**: Оркестратор сообщает участникам, какие локальные транзакции выполнить.

### Проблемы

- Шаблон саги особенно сложно отлаживать.
- Существует риск циклической зависимости между участниками саги.
- Отсутствие изоляции данных участников влечет проблемы сохранности.
- Тестирование затруднено, потому что все сервисы должны работать для имитации транзакции.

# Шардинг

Прежде чем мы поговорим о шардинге, давайте обсудим разделение данных:

## Разделение данных

Разделение данных - это техника, позволяющая разбить базу данных на множество меньших частей. Это процесс разбиения базы данных или таблицы на несколько машин для улучшения управляемости, производительности и доступности базы данных.

### Методы

Существует множество различных способов, которые можно использовать для определения того, как разбить базу данных приложения на несколько меньших баз данных. Ниже приведены два наиболее популярных метода, используемых в различных крупномасштабных приложениях:

**Горизонтальное разделение (или шардинг)**

При этой стратегии мы разбиваем данные таблицы горизонтально на основе диапазона значений, определенного _ключом разделения_. Это также называется **_шардингом баз данных_**.

**Вертикальное разделение**

При вертикальном разделении мы разбиваем данные вертикально по столбцам. Мы разделяем таблицы на относительно более мелкие таблицы с несколькими элементами, и каждая часть находится в отдельном разделе.

В этом руководстве мы будем сосредотачиваться на шардинге.

## Что такое шардинг?

Шардинг - это архитектурный шаблон базы данных, связанный с _горизонтальным разделением_, практикой разделения строк одной таблицы на несколько различных таблиц, известных как _партиции_ или _шарды_. Каждая партиция имеет ту же схему и столбцы, но также подмножество общих данных. Точно так же, данные, хранящиеся в каждой партиции, уникальны и независимы от данных, хранящихся в других партициях.

![sharding](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/sharding/sharding.png)

Обоснование для шардинга данных заключается в том, что после определенного момента дешевле и более осуществимо масштабировать горизонтально, добавляя больше машин, чем масштабировать вертикально, добавляя мощные серверы. Шардинг может быть реализован как на уровне приложения, так и на уровне базы данных.

## Критерии разделения

Существует большое количество критериев доступных для разделения данных. Некоторые из наиболее часто используемых критериев:

### Основанный на хешах

Эта стратегия делит строки на разные разделы на основе алгоритма хеширования, а не группирует строки базы данных на основе непрерывных индексов.

Недостаток этого метода заключается в том, что динамическое добавление/удаление серверов базы данных становится дорогостоящим.

### Основанный на списке

При разделении на основе списка каждый раздел определяется и выбирается на основе списка значений в столбце, а не на основе набора непрерывных диапазонов значений.

### Основанный на диапазонах

Разделение на основе диапазонов отображает данные в различные разделы на основе диапазонов значений ключа разделения. Другими словами, мы разбиваем таблицу таким образом, чтобы каждый раздел содержал строки в определенном диапазоне, определенном ключом разделения.

Диапазоны должны быть непрерывными, но не перекрывающимися, где каждый диапазон определяет невключительную нижнюю и верхнюю границу для раздела. Любые значения ключа разделения, равные или выше верхней границы диапазона, добавляются в следующий раздел.

### Составной

Как следует из названия, составное разделение данных происходит на основе двух или более методов разделения. Здесь мы сначала разделяем данные с использованием одного метода, а затем каждый раздел дополнительно подразделяется на подразделы с использованием того же или какого-то другого метода.

## Преимущества

Но зачем нам нужен шардинг? Вот несколько преимуществ:

- **Доступность**: Обеспечивает логическую независимость разделенной базы данных, обеспечивая высокую доступность нашего приложения. Здесь отдельные разделы могут управляться независимо.
- **Масштабируемость**: Повышает масштабируемость путем распределения данных по нескольким разделам.
- **Безопасность**: Помогает повысить безопасность системы, храня чувствительные и нечувствительные данные в разных разделах. Это может обеспечить лучшую управляемость и защиту конфиденциальных данных.
- **Производительность запроса**: Улучшает производительность системы. Теперь система должна запрашивать только меньший раздел, а не всю базу данных.
- **Управляемость данных**: Разделяет таблицы и индексы на более мелкие и управляемые единицы.

## Недостатки

- **Сложность**: Шардинг увеличивает сложность системы в целом.
- **Объединения между разделами**: После того как база данных разделена и распределена по нескольким машинам, часто нецелесообразно выполнять объединения, которые охватывают несколько баз данных. Такие объединения не будут эффективными с точки зрения производительности, поскольку данные придется извлекать из нескольких серверов.
- **Перебалансировка**: Если распределение данных неравномерно или на одном разделе слишком большая нагрузка, в таких случаях нам придется перебалансировать наши разделы, чтобы запросы были как можно равномерно распределены между ними.

## Когда использовать шардинг?

Вот несколько причин, почему шардинг может быть правильным выбором:

- Использование существующего оборудования вместо высокопроизводительных машин.
- Хранение данных в различных географических регионах.
- Быстрое масштабирование путем добавления большего количества шардов.
- Лучшая производительность, поскольку каждая машина нагружена меньше.
- Когда требуются более множественные соединения.

# Согласованное хеширование

Давайте сначала поймем проблему, которую мы пытаемся решить.

## Зачем это нужно?

В традиционных методах распределения на основе хеширования мы используем хэш-функцию для хеширования наших ключей раздела (например, идентификатор запроса или IP). Затем, если мы используем операцию взятия остатка от деления на общее количество узлов (серверов или баз данных), это даст нам узел, куда мы хотим направить наш запрос.

![simple-hashing](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/consistent-hashing/simple-hashing.png)

$$
\begin{align*}
& Hash(key_1) \to H_1 \bmod N = Node_0 \\
& Hash(key_2) \to H_2 \bmod N = Node_1 \\
& Hash(key_3) \to H_3 \bmod N = Node_2 \\
& ... \\
& Hash(key_n) \to H_n \bmod N = Node_{n-1}
\end{align*}
$$

Where,

`key`: Request ID or IP.

`H`: Hash function result.

`N`: Total number of nodes.

`Node`: The node where the request will be routed.

The problem with this is if we add or remove a node, it will cause `N` to change, meaning our mapping strategy will break as the same requests will now map to a different server. As a consequence, the majority of requests will need to be redistributed which is very inefficient.

We want to uniformly distribute requests among different nodes such that we should be able to add or remove nodes with minimal effort. Hence, we need a distribution scheme that does not depend directly on the number of nodes (or servers), so that, when adding or removing nodes, the number of keys that need to be relocated is minimized.

Consistent hashing solves this horizontal scalability problem by ensuring that every time we scale up or down, we do not have to re-arrange all the keys or touch all the servers.

Now that we understand the problem, let's discuss consistent hashing in detail.

## How does it work

Consistent Hashing is a distributed hashing scheme that operates independently of the number of nodes in a distributed hash table by assigning them a position on an abstract circle, or hash ring. This allows servers and objects to scale without affecting the overall system.

![consistent-hashing](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/consistent-hashing/consistent-hashing.png)

Using consistent hashing, only `K/N` data would require re-distributing.

$$
R = K/N
$$

Where,

`R`: Data that would require re-distribution.

`K`: Number of partition keys.

`N`: Number of nodes.

The output of the hash function is a range let's say `0...m-1` which we can represent on our hash ring. We hash the requests and distribute them on the ring depending on what the output was. Similarly, we also hash the node and distribute them on the same ring as well.

$$
\begin{align*}
& Hash(key_1) = P_1 \\
& Hash(key_2) = P_2 \\
& Hash(key_3) = P_3 \\
& ... \\
& Hash(key_n) = P_{m-1}
\end{align*}
$$

Where,

`key`: Request/Node ID or IP.

`P`: Position on the hash ring.

`m`: Total range of the hash ring.

Теперь, когда поступает запрос, мы можем просто направить его к ближайшему узлу по часовой стрелке (или против часовой стрелки). Это означает, что если добавлен или удален новый узел, мы можем использовать ближайший узел, и лишь _доля_ запросов потребует перенаправления.

В теории, консистентное хеширование должно равномерно распределять нагрузку, однако на практике это не всегда происходит. Обычно распределение нагрузки неравномерно, и один сервер может обрабатывать большинство запросов, становясь _горячей точкой_, фактическим узким местом для системы. Мы можем исправить это, добавив дополнительные узлы, но это может быть дорогостоящим решением.

Давайте посмотрим, как мы можем решить эти проблемы.

## Виртуальные узлы

Для обеспечения более равномерной распределенной нагрузки мы можем ввести понятие виртуального узла, иногда также называемого VNode.

Вместо назначения одной позиции узлу, диапазон хеширования делится на несколько меньших диапазонов, и каждому физическому узлу назначаются несколько из этих меньших диапазонов. Каждый из этих поддиапазонов считается виртуальным узлом. Таким образом, виртуальные узлы по сути представляют собой существующие физические узлы, отображенные несколько раз по кольцу хешей, чтобы минимизировать изменения диапазона, назначенного узлу.

![virtual-nodes](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/consistent-hashing/virtual-nodes.png)

For this, we can use `k` number of hash functions.

$$
\begin{align*}
& Hash_1(key_1) = P_1 \\
& Hash_2(key_2) = P_2 \\
& Hash_3(key_3) = P_3 \\
& . . . \\
& Hash_k(key_n) = P_{m-1}
\end{align*}
$$

Where,

`key`: Request/Node ID or IP.

`k`: Number of hash functions.

`P`: Position on the hash ring.

`m`: Total range of the hash ring.

## Репликация данных

Для обеспечения высокой доступности и надежности консистентное хеширование реплицирует каждый элемент данных на несколько узлов `N` в системе, где значение `N` эквивалентно _фактору репликации_.

Фактор репликации - это количество узлов, которые получат копию тех же данных. В системах с эвентуальной согласованностью это происходит асинхронно.

## Преимущества

Давайте рассмотрим некоторые преимущества консистентного хеширования:

- Позволяет более предсказуемо масштабировать систему вверх и вниз.
- Упрощает разделение и репликацию данных между узлами.
- Обеспечивает масштабируемость и доступность.
- Снижает вероятность появления горячих точек.

## Недостатки

Ниже приведены некоторые недостатки консистентного хеширования:

- Увеличивает сложность.
- Каскадные сбои.
- Распределение нагрузки все равно может быть неравномерным.
- Управление ключами может быть дорогим в случае временных сбоев узлов.

## Примеры

Давайте рассмотрим некоторые примеры использования согласованного хеширования:

- Разделение данных в [Apache Cassandra](https://cassandra.apache.org).
- Распределение нагрузки между несколькими хранилищами в [Amazon DynamoDB](https://aws.amazon.com/dynamodb).

# Федерация баз данных

Федерация (или функциональное разделение) разбивает базы данных по функциональности. Архитектура федерации делает несколько отдельных физических баз данных видимыми как одну логическую базу данных для конечных пользователей.

Все компоненты в федерации связаны одной или несколькими федеральными схемами, которые выражают общность данных по всей федерации. Эти федеральные схемы используются для указания информации, которая может быть общей для компонентов федерации, и для обеспечения общей основы для взаимодействия между ними.

![database-federation](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-II/database-federation/database-federation.png)

## Характеристики

Давайте рассмотрим некоторые ключевые характеристики федеративной базы данных:

- **Прозрачность**: Федеративная база данных скрывает различия между пользователями и реализациями базовых источников данных. Пользователям не нужно знать, где хранятся данные.
- **Гетерогенность**: Источники данных могут различаться во многих аспектах. Система федеративной базы данных может работать с различным оборудованием, сетевыми протоколами, моделями данных и т. д.
- **Расширяемость**: Для удовлетворения изменяющихся потребностей бизнеса могут потребоваться новые источники данных. Хорошая система федеративной базы данных должна упростить добавление новых источников.
- **Автономность**: Федеративная база данных не изменяет существующие источники данных, интерфейсы должны оставаться прежними.
- **Интеграция данных**: Федеративная база данных может интегрировать данные из разных протоколов, систем управления базами данных и т. д.

## Преимущества

Вот некоторые преимущества федеративных баз данных:

- Гибкое обмен данных.
- Автономия между компонентами базы данных.
- Доступ к гетерогенным данным в унифицированном виде.
- Отсутствие тесной связи приложений с устаревшими базами данных.

## Недостатки

Ниже приведены некоторые недостатки федеративных баз данных:

- Увеличение аппаратных ресурсов и дополнительная сложность.
- Сложность объединения данных из двух баз данных.
- Зависимость от автономных источников данных.
- Производительность запросов и масштабируемость.

# N-tier architecture

N-tier architecture divides an application into logical layers and physical tiers. Layers are a way to separate responsibilities and manage dependencies. Each layer has a specific responsibility. A higher layer can use services in a lower layer, but not the other way around.

![n-tier-architecture](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/n-tier-architecture/n-tier-architecture.png)

Уровни физически разделены и работают на отдельных машинах. Уровень может обращаться к другому уровню напрямую или использовать асинхронное сообщение. Хотя каждый слой может быть размещен на своем собственном уровне, это не является обязательным. Несколько слоев могут быть размещены на одном уровне. Физическое разделение уровней улучшает масштабируемость и надежность, а также добавляет задержку из-за дополнительного сетевого взаимодействия.

Архитектура N-уровней может быть двух типов:

- В закрытой архитектуре слоя слой может обращаться только к следующему слою ниже.
- В открытой архитектуре слоя слой может вызывать любой из слоев ниже него.

Закрытая архитектура слоев ограничивает зависимости между слоями. Однако это может создавать излишний сетевой трафик, если один слой просто передает запросы следующему слою.

## Типы архитектур N-уровней

Давайте рассмотрим некоторые примеры архитектур N-уровней:

### Архитектура 3-уровневой

3-уровневая архитектура широко используется и состоит из следующих различных уровней:

- **Слой представления**: обрабатывает взаимодействие пользователя с приложением.
- **Бизнес-логика**: принимает данные от уровня приложения, проверяет их в соответствии с бизнес-логикой и передает их на уровень доступа к данным.
- **Слой доступа к данным**: получает данные от бизнес-уровня и выполняет необходимые операции с базой данных.

### Архитектура 2-уровневой

В этой архитектуре слой представления работает на клиенте и взаимодействует с хранилищем данных. Здесь нет слоя бизнес-логики или промежуточного слоя между клиентом и сервером.

### Архитектура с одним уровнем или 1-уровневая архитектура

Это самая простая архитектура, так как эквивалентна запуску приложения на персональном компьютере. Все необходимые компоненты для запуска приложения находятся на одном приложении или сервере.

## Преимущества

Вот некоторые преимущества использования архитектуры N-уровней:

- Могут повысить доступность.
- Более высокий уровень безопасности, поскольку уровни могут вести себя как брандмауэр.
- Отдельные уровни позволяют масштабировать их по мере необходимости.
- Улучшают обслуживание, так как различные лица могут управлять различными уровнями.

## Недостатки

Ниже приведены некоторые недостатки архитектуры N-уровней:

- Увеличивается сложность всей системы.
- Увеличивается сетевая задержка с увеличением количества уровней.
- Дорого в эксплуатации, так как каждый уровень будет иметь свою собственную стоимость оборудования.
- Сложно управлять сетевой безопасностью.

# Брокеры сообщений

Брокер сообщений - это программное обеспечение, позволяющее приложениям, системам и службам обмениваться информацией и взаимодействовать друг с другом. Брокер сообщений делает это, переводя сообщения между формальными протоколами передачи сообщений. Это позволяет взаимозависимым службам "общаться" друг с другом напрямую, даже если они написаны на разных языках или реализованы на разных платформах.

![message-broker](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/message-brokers/message-broker.png)

## Модели

Брокеры сообщений предлагают две основные модели распределения сообщений или стиля обмена сообщениями:

- **[Сообщения точка-точка](https://karanpratapsingh.com/courses/system-design/message-queues)**: Это модель распределения, используемая в очередях сообщений с однозначным соответствием между отправителем сообщения и получателем.
- **[Сообщения издатель-подписчик](https://karanpratapsingh.com/courses/system-design/publish-subscribe)**: В этой модели распределения сообщений, часто называемой _"издатель-подписчик"_, производитель каждого сообщения публикует его в теме, и несколько потребителей сообщений подписываются на темы, из которых они хотят получать сообщения.

_Мы подробно обсудим эти модели обмена сообщениями в последующих учебниках._

## Брокеры сообщений VS потоки событий

Брокеры сообщений могут поддерживать две или более модели передачи сообщений, включая очереди сообщений и издатель-подписчик, в то время как платформы потоков событий предлагают только модели распространения в стиле издатель-подписчик. Разработанные для использования с большим объемом сообщений, платформы потоков событий легко масштабируются. Они способны упорядочивать потоки записей по категориям, называемым _темами_, и хранить их в течение определенного времени. Однако, в отличие от брокеров сообщений, платформы потоков событий не могут гарантировать доставку сообщений или отслеживать, какие потребители получили сообщения.

Платформы потоков событий предлагают большую масштабируемость по сравнению с брокерами сообщений, но меньше функций, обеспечивающих отказоустойчивость, таких как повторная отправка сообщений, а также более ограниченные возможности маршрутизации сообщений и управления очередями.

## Брокеры сообщений VS Enterprise Service Bus

Инфраструктура Корпоративной Шины Служб (ESB) сложна и может быть сложно интегрирована и дорого поддерживаться. Их трудно устранять, когда возникают проблемы в производственных средах, они не могут легко масштабироваться, а обновление требует много времени и труда.

В то время как брокеры сообщений являются _"легковесной"_ альтернативой ESB, предоставляя аналогичную функциональность, механизм взаимодействия между службами, по более низкой цене. Они хорошо подходят для использования в [микросервисных архитектурах](https://karanpratapsingh.com/courses/system-design/monoliths-microservices#microservices), которые стали более распространенными с уходом ESB из моды.

## Examples

Here are some commonly used message brokers:

- [NATS](https://nats.io)
- [Apache Kafka](https://kafka.apache.org)
- [RabbitMQ](https://www.rabbitmq.com)
- [ActiveMQ](https://activemq.apache.org)

# Message Queues

A message queue is a form of service-to-service communication that facilitates asynchronous communication. It asynchronously receives messages from producers and sends them to consumers.

Queues are used to effectively manage requests in large-scale distributed systems. In small systems with minimal processing loads and small databases, writes can be predictably fast. However, in more complex and large systems writes can take an almost non-deterministic amount of time.

![message-queue](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/message-queues/message-queue.png)

## Работа

Сообщения хранятся в очереди до их обработки и удаления. Каждое сообщение обрабатывается только один раз одним потребителем. Вот как это работает:

- Производитель публикует задание в очереди, затем уведомляет пользователя о состоянии задания.
- Потребитель выбирает задание из очереди, обрабатывает его, затем сигнализирует о завершении задания.

## Преимущества

Давайте обсудим некоторые преимущества использования очереди сообщений:

- **Масштабируемость**: Очереди сообщений позволяют точно масштабировать то, где нам это нужно. При пиковых нагрузках несколько экземпляров нашего приложения могут добавлять все запросы в очередь без риска столкновения.
- **Разделение компонентов**: Очереди сообщений удаляют зависимости между компонентами и значительно упрощают реализацию разделенных приложений.
- **Производительность**: Очереди сообщений обеспечивают асинхронное взаимодействие, что означает, что точки конечные точки, производящие и потребляющие сообщения, взаимодействуют с очередью, а не друг с другом. Производители могут добавлять запросы в очередь без ожидания их обработки.
- **Надежность**: Очереди делают наши данные устойчивыми и уменьшают ошибки, которые возникают, когда разные части нашей системы выходят из строя.

## Характеристики

Теперь давайте обсудим некоторые желаемые характеристики очередей сообщений:

### Доставка методом Push или Pull

Большинство очередей сообщений предоставляют как вариант доставки метод Push, так и метод Pull для получения сообщений. Pull означает постоянный запрос очереди на наличие новых сообщений. Push означает, что потребителю сообщается о наличии нового сообщения. Мы также можем использовать длинное ожидание (long-polling), чтобы позволить Pull-запросам ожидать появления новых сообщений в течение указанного времени.

### Очереди FIFO (First-In-First-Out)

В таких очередях самая старая (или первая) запись, иногда называемая _"головой"_ очереди, обрабатывается первой.

### Планирование или отсроченная доставка

Многие очереди сообщений поддерживают установку определенного времени доставки сообщения. Если нам нужно установить общую задержку для всех сообщений, мы можем настроить очередь с отсроченной доставкой.

### Гарантированная доставка как минимум один раз

Очереди сообщений могут хранить несколько копий сообщений для обеспечения избыточности и высокой доступности, а также повторно отправлять сообщения в случае сбоев связи или ошибок, чтобы гарантировать, что они будут доставлены как минимум один раз.

### Гарантированная доставка ровно один раз

Когда дубликаты недопустимы, очереди сообщений FIFO (первым вошел - первым вышел) будут гарантировать, что каждое сообщение будет доставлено ровно один раз (и только один раз), автоматически отфильтровывая дубликаты.

### Очереди для обработки ошибочных сообщений

Очередь для обработки ошибок (dead-letter queue) - это очередь, в которую другие очереди могут отправлять сообщения, которые не могут быть успешно обработаны. Это позволяет установить их в сторону для дальнейшего исследования без блокировки обработки очереди или затрат ресурсов процессора на сообщение, которое возможно никогда не будет успешно обработано.

### Упорядочение

Большинство очередей сообщений обеспечивают доставку по мере возможности, что гарантирует, что сообщения, как правило, доставляются в том же порядке, в котором они отправляются, и что сообщение доставляется как минимум один раз.

### Poison-pill messages

Специальные сообщения-яды могут быть получены, но не обработаны. Они являются механизмом, используемым для сигнализации потребителю о прекращении его работы, чтобы он больше не ожидал новых входных данных, и аналогичны закрытию сокета в модели клиент-сервер.

### Безопасность

Очереди сообщений аутентифицируют приложения, которые пытаются получить доступ к очереди, что позволяет нам шифровать сообщения по сети, а также в самой очереди.

### Очереди задач

Очереди задач принимают задачи и связанные с ними данные, выполняют их, а затем доставляют результаты. Они могут поддерживать планирование и использоваться для выполнения вычислительно интенсивных задач в фоновом режиме.

## Обратная связь

Если очереди начинают значительно увеличиваться, их размер может стать больше памяти, что приведет к промахам кэша, чтению с диска и даже медленной производительности. Обратная связь может помочь, ограничивая размер очереди, тем самым поддерживая высокую скорость передачи данных и хорошее время отклика для задач, уже находящихся в очереди. Когда очередь заполняется, клиенты получают код состояния сервера 503 и пытаются повторить запрос позже. Клиенты могут повторно попытаться запросить ресурсы в более позднее время, возможно, используя стратегию [экспоненциальной задержки](https://en.wikipedia.org/wiki/Exponential_backoff).

## Examples

Following are some widely used message queues:

- [Amazon SQS](https://aws.amazon.com/sqs)
- [RabbitMQ](https://www.rabbitmq.com)
- [ActiveMQ](https://activemq.apache.org)
- [ZeroMQ](https://zeromq.org)

# Publish-Subscribe

Similar to a message queue, publish-subscribe is also a form of service-to-service communication that facilitates asynchronous communication. In a pub/sub model, any message published to a topic is pushed immediately to all the subscribers of the topic.

![publish-subscribe](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/publish-subscribe/publish-subscribe.png)

## Принцип работы

В отличие от очередей сообщений, которые пакетируют сообщения до их получения, темы сообщений передают сообщения с минимальной или без очереди и мгновенно отправляют их всем подписчикам. Вот как это работает:

- Тема сообщений предоставляет легкий механизм для передачи асинхронных уведомлений о событиях и конечные точки, позволяющие программным компонентам подключаться к теме для отправки и получения этих сообщений.
- Чтобы передать сообщение, компонент, называемый _издателем_, просто отправляет сообщение в тему.
- Все компоненты, которые подписаны на тему (известные как _подписчики_), получают каждое сообщение, которое было передано.

## Преимущества

Давайте обсудим некоторые преимущества использования модели "публикация-подписка":

- **Исключение опросов**: Темы сообщений позволяют мгновенную доставку на основе push, устраняя необходимость для потребителей сообщений периодически проверять или _"опрашивать"_ новую информацию и обновления. Это способствует более быстрому времени реакции и снижает задержку доставки, что может быть особенно проблематично в системах, где задержки не могут быть терпимы.
- **Динамическое определение цели**: Pub/Sub упрощает обнаружение служб, делая его более естественным и менее ошибочным. Вместо того чтобы поддерживать реестр пиров, куда приложение может отправлять сообщения, издатель просто публикует сообщения в тему. Затем любая заинтересованная сторона подпишет свою конечную точку на тему и начнет получать эти сообщения. Подписчики могут меняться, обновляться, увеличиваться или исчезать, и система динамически настраивается.
- **Разрыв и независимость масштабирования**: Издатели и подписчики разделены и работают независимо друг от друга, что позволяет нам разрабатывать и масштабировать их независимо.
- **Упрощение коммуникации**: Модель "публикация-подписка" уменьшает сложность, удаляя все точка-точка-соединения с единственным подключением к теме сообщений, которая управляет подписками и решает, какие сообщения должны быть доставлены на какие конечные точки.

## Характеристики

Теперь давайте обсудим некоторые желательные характеристики модели "публикация-подписка":

### Push-доставка

Система сообщений "публикация-подписка" мгновенно отправляет асинхронные уведомления о событиях при публикации сообщений в тему сообщений. Подписчики получают уведомление о доступности сообщения.

### Множество протоколов доставки

В модели "публикация-подписка" темы обычно могут подключаться к нескольким типам конечных точек, таким как очереди сообщений, серверные функции, HTTP-серверы и т. д.

### Fanout

Этот сценарий происходит, когда сообщение отправляется в тему, а затем реплицируется и отправляется на несколько конечных точек. Фанаут обеспечивает асинхронные уведомления о событиях, что в свою очередь позволяет выполнять параллельную обработку.

### Фильтрация

Эта функция дает возможность подписчику создавать политику фильтрации сообщений, чтобы получать только те уведомления, которые его интересуют, в отличие от получения каждого отдельного сообщения, опубликованного в теме.

### Надежность

Сервисы сообщений "публикация-подписка" часто обеспечивают очень высокую надежность и доставку хотя бы один раз, храня копии того же сообщения на нескольких серверах.

### Безопасность

Темы сообщений аутентифицируют приложения, которые пытаются опубликовать контент, что позволяет использовать зашифрованные конечные точки и шифровать сообщения при передаче по сети.

## Examples

Вот примеры некоторых часто используемых publish-subscribe сервисов:

- [Amazon SNS](https://aws.amazon.com/sns)
- [Google Pub/Sub](https://cloud.google.com/pubsub)

# Enterprise Service Bus (ESB)

An Enterprise Service Bus (ESB) is an architectural pattern whereby a centralized software component performs integrations between applications. It performs transformations of data models, handles connectivity, performs message routing, converts communication protocols, and potentially manages the composition of multiple requests. The ESB can make these integrations and transformations available as a service interface for reuse by new applications.

![enterprise-service-bus](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/enterprise-service-bus/enterprise-service-bus.png)

## Преимущества

В теории централизованный ESB предлагает потенциал для стандартизации и существенного упрощения коммуникации, обмена сообщениями и интеграции между службами в предприятии. Вот некоторые преимущества использования ESB:

- **Повышение производительности разработчиков**: Позволяет разработчикам внедрять новые технологии в одной части приложения без изменения остальной части приложения.
- **Проще, более экономически эффективное масштабирование**: Компоненты могут масштабироваться независимо друг от друга.
- **Большая надежность**: Отказ одного компонента не влияет на другие, и каждый микросервис может придерживаться своих собственных требований к доступности без риска доступности других компонентов в системе.

## Недостатки

Хотя ESB успешно внедрялись во многих организациях, во многих других организациях ESB начали восприниматься как узкое место. Вот некоторые недостатки использования ESB:

- Внесение изменений или улучшений в одну интеграцию может нарушить другие, которые используют ту же интеграцию.
- Одна точка отказа может привести к прекращению всех коммуникаций.
- Обновления ESB часто влияют на существующие интеграции, поэтому для выполнения любого обновления требуется значительное тестирование.
- ESB централизованно управляется, что затрудняет совместную работу между командами.
- Высокая сложность конфигурации и обслуживания.

## Examples

Ниже приведен список некоторых широкоиспользуемых Enterprise Service Bus (ESB):

- [Azure Service Bus](https://azure.microsoft.com/en-in/services/service-bus)
- [IBM App Connect](https://www.ibm.com/in-en/cloud/app-connect)
- [Apache Camel](https://camel.apache.org)
- [Fuse ESB](https://www.redhat.com/en/technologies/jboss-middleware/fuse)

# Monoliths and Microservices

## Monoliths

A monolith is a self-contained and independent application. It is built as a single unit and is responsible for not just a particular task, but can perform every step needed to satisfy a business need.

![monolith](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/monoliths-microservices/monolith.png)

### Преимущества

Вот некоторые преимущества монолитов:

- Простота разработки и отладки.
- Быстрая и надежная коммуникация.
- Легкое мониторинг и тестирование.
- Поддержка ACID-транзакций.

### Недостатки

Некоторые распространенные недостатки монолитов:

- Усложняется обслуживание по мере роста кодовой базы.
- Плотно связанные приложения, трудно расширяемые.
- Требует приверженности к определенному стеку технологий.
- При каждом обновлении приложения полностью пересобирается.
- Снижается надежность, так как одна ошибка может привести к падению всей системы.
- Трудно масштабируется или принимает новые технологии.

## Модульные монолиты

Модульный монолит - это подход, при котором мы строим и развертываем единственное приложение (это часть _Монолита_), но делаем это таким образом, что разбиваем код на независимые модули для каждой из функций, необходимых в нашем приложении.

Этот подход уменьшает зависимости модуля таким образом, что мы можем улучшить или изменить модуль, не затрагивая другие модули. Правильно выполненный, это может быть действительно полезным в долгосрочной перспективе, так как уменьшает сложность, связанную с поддержкой монолита по мере роста системы.

## Микросервисы

Архитектура микросервисов состоит из набора маленьких, автономных служб, где каждая служба является самодостаточной и должна реализовывать одну бизнес-возможность в рамках ограниченного контекста. Ограниченный контекст - это естественное разделение бизнес-логики, которое обеспечивает явную границу, в пределах которой существует доменная модель.

![microservices](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/monoliths-microservices/microservices.png)

Каждый сервис имеет отдельную кодовую базу, которой может управлять небольшая команда разработчиков. Сервисы могут быть развернуты независимо, и команда может обновлять существующий сервис без пересборки и повторного развертывания всего приложения.

Сервисы отвечают за сохранение своих собственных данных или внешнего состояния (база данных на сервис). Это отличается от традиционной модели, где отдельный уровень данных обрабатывает сохранение данных.

### Характеристики

Архитектура микросервисов имеет следующие характеристики:

- **Слабая связность**: Сервисы должны быть слабо связаны, чтобы их можно было независимо развертывать и масштабировать. Это приведет к децентрализации разработчиков и позволит им разрабатывать и разворачивать приложения быстрее с минимальными ограничениями и операционными зависимостями.
- **Маленькие, но сфокусированные**: Это не о размере, а о зоне ответственности, сервис должен быть сосредоточен на конкретной проблеме. В основном, _"Он делает одну вещь и делает это хорошо"_. В идеале, они могут быть независимы от базовой архитектуры.
- **Созданы для бизнеса**: Архитектура микросервисов обычно организована вокруг деловых возможностей и приоритетов.
- **Устойчивость и Толерантность к сбоям**: Сервисы должны быть спроектированы таким образом, чтобы они продолжали работать в случае сбоя или ошибок. В средах с независимо развертываемыми сервисами устойчивость к отказам имеет высшее значение.
- **Высокая поддерживаемость**: Сервисы должны быть легкими в обслуживании и тестировании, потому что сервисы, которые невозможно обслуживать, будут переписаны.

### Advantages

Here are some advantages of microservices architecture:

- Loosely coupled services.
- Services can be deployed independently.
- Highly agile for multiple development teams.
- Improves fault tolerance and data isolation.
- Better scalability as each service can be scaled independently.
- Eliminates any long-term commitment to a particular technology stack.

### Disadvantages

Microservices architecture brings its own set of challenges:

- Complexity of a distributed system.
- Testing is more difficult.
- Expensive to maintain (individual servers, databases, etc.).
- Inter-service communication has its own challenges.
- Data integrity and consistency.
- Network congestion and latency.

### Best practices

Let's discuss some microservices best practices:

- Model services around the business domain.
- Services should have loose coupling and high functional cohesion.
- Isolate failures and use resiliency strategies to prevent failures within a service from cascading.
- Services should only communicate through well-designed APIs. Avoid leaking implementation details.
- Data storage should be private to the service that owns the data
- Avoid coupling between services. Causes of coupling include shared database schemas and rigid communication protocols.
- Decentralize everything. Individual teams are responsible for designing and building services. Avoid sharing code or data schemas.
- Fail fast by using a [circuit breaker](https://karanpratapsingh.com/courses/system-design/circuit-breaker) to achieve fault tolerance.
- Ensure that the API changes are backward compatible.

### Pitfalls

Below are some common pitfalls of microservices architecture:

- Service boundaries are not based on the business domain.
- Underestimating how hard is to build a distributed system.
- Shared database or common dependencies between services.
- Lack of Business Alignment.
- Lack of clear ownership.
- Lack of idempotency.
- Trying to do everything [ACID instead of BASE](https://karanpratapsingh.com/courses/system-design/acid-and-base-consistency-models).
- Lack of design for fault tolerance may result in cascading failures.

## Beware of the distributed monolith

Distributed Monolith is a system that resembles the microservices architecture but is tightly coupled within itself like a monolithic application. Adopting microservices architecture comes with a lot of advantages. But while making one, there are good chances that we might end up with a distributed monolith.

Our microservices are just a distributed monolith if any of these apply to it:

- Requires low latency communication.
- Services don't scale easily.
- Dependency between services.
- Sharing the same resources such as databases.
- Tightly coupled systems.

One of the primary reasons to build an application using microservices architecture is to have scalability. Therefore, microservices should have loosely coupled services which enable every service to be independent. The distributed monolith architecture takes this away and causes most components to depend on one another, increasing design complexity.

## Microservices vs Service-oriented architecture (SOA)

You might have seen _Service-oriented architecture (SOA)_ mentioned around the internet, sometimes even interchangeably with microservices, but they are different from each other and the main distinction between the two approaches comes down to _scope_.

Service-oriented architecture (SOA) defines a way to make software components reusable via service interfaces. These interfaces utilize common communication standards and focus on maximizing application service reusability whereas microservices are built as a collection of various smallest independent service units focused on team autonomy and decoupling.

## Why you don't need microservices

![architecture-range](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/monoliths-microservices/architecture-range.png)

So, you might be wondering, monoliths seem like a bad idea to begin with, why would anyone use that?

Well, it depends. While each approach has its own advantages and disadvantages, it is advised to start with a monolith when building a new system. It is important to understand, that microservices are not a silver bullet, instead, they solve an organizational problem. Microservices architecture is about your organizational priorities and team as much as it's about technology.

Before making the decision to move to microservices architecture, you need to ask yourself questions like:

- _"Is the team too large to work effectively on a shared codebase?"_
- _"Are teams blocked on other teams?"_
- _"Does microservices deliver clear business value for us?"_
- _"Is my business mature enough to use microservices?"_
- _"Is our current architecture limiting us with communication overhead?"_

If your application does not require to be broken down into microservices, you don't need this. There is no absolute necessity that all applications should be broken down into microservices.

We frequently draw inspiration from companies such as Netflix and their use of microservices, but we overlook the fact that we are not Netflix. They went through a lot of iterations and models before they had a market-ready solution, and this architecture became acceptable for them when they identified and solved the problem they were trying to tackle.

That's why it's essential to understand in-depth if your business _actually_ needs microservices. What I'm trying to say is microservices are solutions to complex concerns and if your business doesn't have complex issues, you don't need them.

# Event-Driven Architecture (EDA)

Event-Driven Architecture (EDA) is about using events as a way to communicate within a system. Generally, leveraging a message broker to publish and consume events asynchronously. The publisher is unaware of who is consuming an event and the consumers are unaware of each other. Event-Driven Architecture is simply a way of achieving loose coupling between services within a system.

## What is an event?

An event is a data point that represents state changes in a system. It doesn't specify what should happen and how the change should modify the system, it only notifies the system of a particular state change. When a user makes an action, they trigger an event.

## Components

Event-driven architectures have three key components:

- **Event producers**: Publishes an event to the router.
- **Event routers**: Filters and pushes the events to consumers.
- **Event consumers**: Uses events to reflect changes in the system.

![event-driven-architecture](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/event-driven-architecture/event-driven-architecture.png)

_Note: Dots in the diagram represents different events in the system._

## Patterns

There are several ways to implement the event-driven architecture, and which method we use depends on the use case but here are some common examples:

- [Sagas](https://karanpratapsingh.com/courses/system-design/distributed-transactions#sagas)
- [Publish-Subscribe](https://karanpratapsingh.com/courses/system-design/publish-subscribe)
- [Event Sourcing](https://karanpratapsingh.com/courses/system-design/event-sourcing)
- [Command and Query Responsibility Segregation (CQRS)](https://karanpratapsingh.com/courses/system-design/command-and-query-responsibility-segregation)

_Note: Each of these methods is discussed separately._

## Advantages

Let's discuss some advantages:

- Decoupled producers and consumers.
- Highly scalable and distributed.
- Easy to add new consumers.
- Improves agility.

## Challenges

Here are some challenges of event-drive architecture:

- Guaranteed delivery.
- Error handling is difficult.
- Event-driven systems are complex in general.
- Exactly once, in-order processing of events.

## Use cases

Below are some common use cases where event-driven architectures are beneficial:

- Metadata and metrics.
- Server and security logs.
- Integrating heterogeneous systems.
- Fanout and parallel processing.

## Examples

Here are some widely used technologies for implementing event-driven architectures:

- [NATS](https://nats.io)
- [Apache Kafka](https://kafka.apache.org)
- [Amazon EventBridge](https://aws.amazon.com/eventbridge)
- [Amazon SNS](https://aws.amazon.com/sns)
- [Google PubSub](https://cloud.google.com/pubsub)

# Event Sourcing

Instead of storing just the current state of the data in a domain, use an append-only store to record the full series of actions taken on that data. The store acts as the system of record and can be used to materialize the domain objects.

![event-sourcing](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/event-sourcing/event-sourcing.png)

This can simplify tasks in complex domains, by avoiding the need to synchronize the data model and the business domain, while improving performance, scalability, and responsiveness. It can also provide consistency for transactional data, and maintain full audit trails and history that can enable compensating actions.

## Event sourcing vs Event-Driven Architecture (EDA)

Event sourcing is seemingly constantly being confused with [Event-driven Architecture (EDA)](https://karanpratapsingh.com/courses/system-design/event-driven-architecture). Event-driven architecture is about using events to communicate between service boundaries. Generally, leveraging a message broker to publish and consume events asynchronously within other boundaries.

Whereas, event sourcing is about using events as a state, which is a different approach to storing data. Rather than storing the current state, we're instead going to be storing events. Also, event sourcing is one of the several patterns to implement an event-driven architecture.

## Advantages

Let's discuss some advantages of using event sourcing:

- Excellent for real-time data reporting.
- Great for fail-safety, data can be reconstituted from the event store.
- Extremely flexible, any type of message can be stored.
- Preferred way of achieving audit logs functionality for high compliance systems.

## Disadvantages

Following are the disadvantages of event sourcing:

- Requires an extremely efficient network infrastructure.
- Requires a reliable way to control message formats, such as a schema registry.
- Different events will contain different payloads.

# Command and Query Responsibility Segregation (CQRS)

Command Query Responsibility Segregation (CQRS) is an architectural pattern that divides a system's actions into commands and queries. It was first described by [Greg Young](https://twitter.com/gregyoung).

In CQRS, a _command_ is an instruction, a directive to perform a specific task. It is an intention to change something and doesn't return a value, only an indication of success or failure. And, a _query_ is a request for information that doesn't change the system's state or cause any side effects.

![command-and-query-responsibility-segregation](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/command-and-query-responsibility-segregation/command-and-query-responsibility-segregation.png)

The core principle of CQRS is the separation of commands and queries. They perform fundamentally different roles within a system, and separating them means that each can be optimized as needed, which distributed systems can really benefit from.

## CQRS with Event Sourcing

The CQRS pattern is often used along with the Event Sourcing pattern. CQRS-based systems use separate read and write data models, each tailored to relevant tasks and often located in physically separate stores.

When used with the Event Sourcing pattern, the store of events is the write model and is the official source of information. The read model of a CQRS-based system provides materialized views of the data, typically as highly denormalized views.

## Advantages

Let's discuss some advantages of CQRS:

- Allows independent scaling of read and write workloads.
- Easier scaling, optimizations, and architectural changes.
- Closer to business logic with loose coupling.
- The application can avoid complex joins when querying.
- Clear boundaries between the system behavior.

## Disadvantages

Below are some disadvantages of CQRS:

- More complex application design.
- Message failures or duplicate messages can occur.
- Dealing with eventual consistency is a challenge.
- Increased system maintenance efforts.

## Use cases

Here are some scenarios where CQRS will be helpful:

- The performance of data reads must be fine-tuned separately from the performance of data writes.
- The system is expected to evolve over time and might contain multiple versions of the model, or where business rules change regularly.
- Integration with other systems, especially in combination with event sourcing, where the temporal failure of one subsystem shouldn't affect the availability of the others.
- Better security to ensure that only the right domain entities are performing writes on the data.

# API Gateway

The API Gateway is an API management tool that sits between a client and a collection of backend services. It is a single entry point into a system that encapsulates the internal system architecture and provides an API that is tailored to each client. It also has other responsibilities such as authentication, monitoring, load balancing, caching, throttling, logging, etc.

![api-gateway](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/api-gateway/api-gateway.png)

## Why do we need an API Gateway?

The granularity of APIs provided by microservices is often different than what a client needs. Microservices typically provide fine-grained APIs, which means that clients need to interact with multiple services. Hence, an API gateway can provide a single entry point for all clients with some additional features and better management.

## Features

Below are some desired features of an API Gateway:

- Authentication and Authorization
- [Service discovery](https://karanpratapsingh.com/courses/system-design/service-discovery)
- [Reverse Proxy](https://karanpratapsingh.com/courses/system-design/proxy#reverse-proxy)
- [Caching](https://karanpratapsingh.com/courses/system-design/caching)
- Security
- Retry and [Circuit breaking](https://karanpratapsingh.com/courses/system-design/circuit-breaker)
- [Load balancing](https://karanpratapsingh.com/courses/system-design/load-balancing)
- Logging, Tracing
- API composition
- [Rate limiting](https://karanpratapsingh.com/courses/system-design/rate-limiting) and throttling
- Versioning
- Routing
- IP whitelisting or blacklisting

## Advantages

Let's look at some advantages of using an API Gateway:

- Encapsulates the internal structure of an API.
- Provides a centralized view of the API.
- Simplifies the client code.
- Monitoring, analytics, tracing, and other such features.

## Disadvantages

Here are some possible disadvantages of an API Gateway:

- Possible single point of failure.
- Might impact performance.
- Can become a bottleneck if not scaled properly.
- Configuration can be challenging.

## Backend For Frontend (BFF) pattern

In the Backend For Frontend (BFF) pattern, we create separate backend services to be consumed by specific frontend applications or interfaces. This pattern is useful when we want to avoid customizing a single backend for multiple interfaces. This pattern was first described by [Sam Newman](https://samnewman.io).

Also, sometimes the output of data returned by the microservices to the front end is not in the exact format or filtered as needed by the front end. To solve this issue, the frontend should have some logic to reformat the data, and therefore, we can use BFF to shift some of this logic to the intermediate layer.

![backend-for-frontend](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/api-gateway/backend-for-frontend.png)

The primary function of the backend for the frontend pattern is to get the required data from the appropriate service, format the data, and sent it to the frontend.

_[GraphQL](https://karanpratapsingh.com/courses/system-design/rest-graphql-grpc#graphql) performs really well as a backend for frontend (BFF)._

### When to use this pattern?

We should consider using a Backend For Frontend (BFF) pattern when:

- A shared or general purpose backend service must be maintained with significant development overhead.
- We want to optimize the backend for the requirements of a specific client.
- Customizations are made to a general-purpose backend to accommodate multiple interfaces.

## Examples

Following are some widely used gateways technologies:

- [Amazon API Gateway](https://aws.amazon.com/api-gateway)
- [Apigee API Gateway](https://cloud.google.com/apigee)
- [Azure API Gateway](https://azure.microsoft.com/en-in/services/api-management)
- [Kong API Gateway](https://konghq.com/kong)

# REST, GraphQL, gRPC

A good API design is always a crucial part of any system. But it is also important to pick the right API technology. So, in this tutorial, we will briefly discuss different API technologies such as REST, GraphQL, and gRPC.

## What's an API?

Before we even get into API technologies, let's first understand what is an API.

API stands for Application Programming Interface. It is a set of definitions and protocols for building and integrating application software. It's sometimes referred to as a contract between an information provider and an information user establishing the content required from the producer and the content required by the consumer.

In other words, if you want to interact with a computer or system to retrieve information or perform a function, an API helps you communicate what you want to that system so it can understand and complete the request.

## REST

A [REST API](https://www.ics.uci.edu/~fielding/pubs/dissertation/rest_arch_style.htm) (also known as RESTful API) is an application programming interface that conforms to the constraints of REST architectural style and allows for interaction with RESTful web services. REST stands for Representational State Transfer and it was first introduced by [Roy Fielding](https://roy.gbiv.com) in the year 2000.

_In REST API, the fundamental unit is a resource._

### Concepts

Let's discuss some concepts of a RESTful API.

**Constraints**

In order for an API to be considered _RESTful_, it has to conform to these architectural constraints:

- **Uniform Interface**: There should be a uniform way of interacting with a given server.
- **Client-Server**: A client-server architecture managed through HTTP.
- **Stateless**: No client context shall be stored on the server between requests.
- **Cacheable**: Every response should include whether the response is cacheable or not and for how much duration responses can be cached at the client-side.
- **Layered system**: An application architecture needs to be composed of multiple layers.
- **Code on demand**: Return executable code to support a part of your application. _(optional)_

**HTTP Verbs**

HTTP defines a set of request methods to indicate the desired action to be performed for a given resource. Although they can also be nouns, these request methods are sometimes referred to as _HTTP verbs_. Each of them implements a different semantic, but some common features are shared by a group of them.

Below are some commonly used HTTP verbs:

- **GET**: Request a representation of the specified resource.
- **HEAD**: Response is identical to a `GET` request, but without the response body.
- **POST**: Submits an entity to the specified resource, often causing a change in state or side effects on the server.
- **PUT**: Replaces all current representations of the target resource with the request payload.
- **DELETE**: Deletes the specified resource.
- **PATCH**: Applies partial modifications to a resource.

**HTTP response codes**

[HTTP response status codes](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes) indicate whether a specific HTTP request has been successfully completed.

There are five classes defined by the standard:

- 1xx - Informational responses.
- 2xx - Successful responses.
- 3xx - Redirection responses.
- 4xx - Client error responses.
- 5xx - Server error responses.

For example, HTTP 200 means that the request was successful.

### Advantages

Let's discuss some advantages of REST API:

- Simple and easy to understand.
- Flexible and portable.
- Good caching support.
- Client and server are decoupled.

### Disadvantages

Let's discuss some disadvantages of REST API:

- Over-fetching of data.
- Sometimes multiple round trips to the server are required.

### Use cases

REST APIs are pretty much used universally and are the default standard for designing APIs. Overall REST APIs are quite flexible and can fit almost all scenarios.

### Example

Here's an example usage of a REST API that operates on a **users** resource.

| URI           | HTTP verb | Description         |
| ------------- | --------- | ------------------- |
| /users        | GET       | Get all users       |
| /users/\{id\} | GET       | Get a user by id    |
| /users        | POST      | Add a new user      |
| /users/\{id\} | PATCH     | Update a user by id |
| /users/\{id\} | DELETE    | Delete a user by id |

_There is so much more to learn when it comes to REST APIs, I will highly recommend looking into [Hypermedia as the Engine of Application State (HATEOAS)](https://en.wikipedia.org/wiki/HATEOAS)._

## GraphQL

[GraphQL](https://graphql.org) is a query language and server-side runtime for APIs that prioritizes giving clients exactly the data they request and no more. It was developed by [Facebook](https://engineering.fb.com) and later open-sourced in 2015.

GraphQL is designed to make APIs fast, flexible, and developer-friendly. Additionally, GraphQL gives API maintainers the flexibility to add or deprecate fields without impacting existing queries. Developers can build APIs with whatever methods they prefer, and the GraphQL specification will ensure they function in predictable ways to clients.

_In GraphQL, the fundamental unit is a query._

### Concepts

Let's briefly discuss some key concepts in GraphQL:

**Schema**

A GraphQL schema describes the functionality clients can utilize once they connect to the GraphQL server.

**Queries**

A query is a request made by the client. It can consist of fields and arguments for the query. The operation type of a query can also be a [mutation](https://graphql.org/learn/queries/#mutations) which provides a way to modify server-side data.

**Resolvers**

Resolver is a collection of functions that generate responses for a GraphQL query. In simple terms, a resolver acts as a GraphQL query handler.

### Advantages

Let's discuss some advantages of GraphQL:

- Eliminates over-fetching of data.
- Strongly defined schema.
- Code generation support.
- Payload optimization.

### Disadvantages

Let's discuss some disadvantages of GraphQL:

- Shifts complexity to server-side.
- Caching becomes hard.
- Versioning is ambiguous.
- N+1 problem.

### Use cases

GraphQL proves to be essential in the following scenarios:

- Reducing app bandwidth usage as we can query multiple resources in a single query.
- Rapid prototyping for complex systems.
- When we are working with a graph-like data model.

### Example

Here's a GraphQL schema that defines a `User` type and a `Query` type.

```graphql
type Query {
  getUser: User
}

type User {
  id: ID
  name: String
  city: String
  state: String
}
```

Using the above schema, the client can request the required fields easily without having to fetch the entire resource or guess what the API might return.

```graphql
{
  getUser {
    id
    name
    city
  }
}
```

This will give the following response to the client.

```json
{
  "getUser": {
    "id": 123,
    "name": "Karan",
    "city": "San Francisco"
  }
}
```

_Learn more about GraphQL at [graphql.org](https://graphql.org)._

## gRPC

[gRPC](https://grpc.io) is a modern open-source high-performance [Remote Procedure Call (RPC)](https://en.wikipedia.org/wiki/Remote_procedure_call) framework that can run in any environment. It can efficiently connect services in and across data centers with pluggable support for load balancing, tracing, health checking, authentication and much more.

### Concepts

Let's discuss some key concepts of gRPC.

**Protocol buffers**

Protocol buffers provide a language and platform-neutral extensible mechanism for serializing structured data in a forward and backward-compatible way. It's like JSON, except it's smaller and faster, and it generates native language bindings.

**Service definition**

Like many RPC systems, gRPC is based on the idea of defining a service and specifying the methods that can be called remotely with their parameters and return types. gRPC uses protocol buffers as the [Interface Definition Language (IDL)](https://en.wikipedia.org/wiki/Interface_description_language) for describing both the service interface and the structure of the payload messages.

### Advantages

Let's discuss some advantages of gRPC:

- Lightweight and efficient.
- High performance.
- Built-in code generation support.
- Bi-directional streaming.

### Disadvantages

Let's discuss some disadvantages of gRPC:

- Relatively new compared to REST and GraphQL.
- Limited browser support.
- Steeper learning curve.
- Not human readable.

### Use cases

Below are some good use cases for gRPC:

- Real-time communication via bi-directional streaming.
- Efficient inter-service communication in microservices.
- Low latency and high throughput communication.
- Polyglot environments.

### Example

Here's a basic example of a gRPC service defined in a `*.proto` file. Using this definition, we can easily code generate the `HelloService` service in the programming language of our choice.

```protobuf
service HelloService {
  rpc SayHello (HelloRequest) returns (HelloResponse);
}

message HelloRequest {
  string greeting = 1;
}

message HelloResponse {
  string reply = 1;
}
```

## REST vs GraphQL vs gRPC

Now that we know how these API designing techniques work, let's compare them based on the following parameters:

- Will it cause tight coupling?
- How _chatty_ (distinct API calls to get needed information) are the APIs?
- What's the performance like?
- How complex is it to integrate?
- How well does the caching work?
- Built-in tooling and code generation?
- What's API discoverability like?
- How easy is it to version APIs?

| Type    | Coupling | Chattiness | Performance | Complexity | Caching | Codegen | Discoverability | Versioning |
| ------- | -------- | ---------- | ----------- | ---------- | ------- | ------- | --------------- | ---------- |
| REST    | Low      | High       | Good        | Medium     | Great   | Bad     | Good            | Easy       |
| GraphQL | Medium   | Low        | Good        | High       | Custom  | Good    | Good            | Custom     |
| gRPC    | High     | Medium     | Great       | Low        | Custom  | Great   | Bad             | Hard       |

### Which API technology is better?

Well, the answer is none of them. There is no silver bullet as each of these technologies has its own advantages and disadvantages. Users only care about using our APIs in a consistent way, so make sure to focus on your domain and requirements when designing your API.

# Long polling, WebSockets, Server-Sent Events (SSE)

Web applications were initially developed around a client-server model, where the web client is always the initiator of transactions like requesting data from the server. Thus, there was no mechanism for the server to independently send, or push, data to the client without the client first making a request. Let's discuss some approaches to overcome this problem.

## Long polling

HTTP Long polling is a technique used to push information to a client as soon as possible from the server. As a result, the server does not have to wait for the client to send a request.

In Long polling, the server does not close the connection once it receives a request from the client. Instead, the server responds only if any new message is available or a timeout threshold is reached.

![long-polling](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/long-polling-websockets-server-sent-events/long-polling.png)

Once the client receives a response, it immediately sends a new request to the server to have a new pending connection to send data to the client, and the operation is repeated. With this approach, the server emulates a real-time server push feature.

### Working

Let's understand how long polling works:

1. The client makes an initial request and waits for a response.
2. The server receives the request and delays sending anything until an update is available.
3. Once an update is available, the response is sent to the client.
4. The client receives the response and makes a new request immediately or after some defined interval to establish a connection again.

### Advantages

Here are some advantages of long polling:

- Easy to implement, good for small-scale projects.
- Nearly universally supported.

### Disadvantages

A major downside of long polling is that it is usually not scalable. Below are some of the other reasons:

- Creates a new connection each time, which can be intensive on the server.
- Reliable message ordering can be an issue for multiple requests.
- Increased latency as the server needs to wait for a new request.

## WebSockets

WebSocket provides full-duplex communication channels over a single TCP connection. It is a persistent connection between a client and a server that both parties can use to start sending data at any time.

The client establishes a WebSocket connection through a process known as the WebSocket handshake. If the process succeeds, then the server and client can exchange data in both directions at any time. The WebSocket protocol enables the communication between a client and a server with lower overheads, facilitating real-time data transfer from and to the server.

![websockets](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/long-polling-websockets-server-sent-events/websockets.png)

This is made possible by providing a standardized way for the server to send content to the client without being asked and allowing for messages to be passed back and forth while keeping the connection open.

### Working

Let's understand how WebSockets work:

1. The client initiates a WebSocket handshake process by sending a request.
2. The request also contains an [HTTP Upgrade](https://en.wikipedia.org/wiki/HTTP/1.1_Upgrade_header) header that allows the request to switch to the WebSocket protocol (`ws://`).
3. The server sends a response to the client, acknowledging the WebSocket handshake request.
4. A WebSocket connection will be opened once the client receives a successful handshake response.
5. Now the client and server can start sending data in both directions allowing real-time communication.
6. The connection is closed once the server or the client decides to close the connection.

### Advantages

Below are some advantages of WebSockets:

- Full-duplex asynchronous messaging.
- Better origin-based security model.
- Lightweight for both client and server.

### Disadvantages

Let's discuss some disadvantages of WebSockets:

- Terminated connections aren't automatically recovered.
- Older browsers don't support WebSockets (becoming less relevant).

## Server-Sent Events (SSE)

Server-Sent Events (SSE) is a way of establishing long-term communication between client and server that enables the server to proactively push data to the client.

![server-sent-events](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-III/long-polling-websockets-server-sent-events/server-sent-events.png)

It is unidirectional, meaning once the client sends the request it can only receive the responses without the ability to send new requests over the same connection.

### Working

Let's understand how server-sent events work:

1. The client makes a request to the server.
2. The connection between client and server is established and it remains open.
3. The server sends responses or events to the client when new data is available.

### Advantages

- Simple to implement and use for both client and server.
- Supported by most browsers.
- No trouble with firewalls.

### Disadvantages

- Unidirectional nature can be limiting.
- Limitation for the maximum number of open connections.
- Does not support binary data.

# Geohashing and Quadtrees

## Geohashing

Geohashing is a [geocoding](https://en.wikipedia.org/wiki/Address_geocoding) method used to encode geographic coordinates such as latitude and longitude into short alphanumeric strings. It was created by [Gustavo Niemeyer](https://twitter.com/gniemeyer) in 2008.

For example, San Francisco with coordinates `37.7564, -122.4016` can be represented in geohash as `9q8yy9mf`.

### How does Geohashing work?

Geohash is a hierarchical spatial index that uses Base-32 alphabet encoding, the first character in a geohash identifies the initial location as one of the 32 cells. This cell will also contain 32 cells. This means that to represent a point, the world is recursively divided into smaller and smaller cells with each additional bit until the desired precision is attained. The precision factor also determines the size of the cell.

![geohashing](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/geohashing-and-quadtrees/geohashing.png)

Geohashing guarantees that points are spatially closer if their Geohashes share a longer prefix which means the more characters in the string, the more precise the location. For example, geohashes `9q8yy9mf` and `9q8yy9vx` are spatially closer as they share the prefix `9q8yy9`.

Geohashing can also be used to provide a degree of anonymity as we don't need to expose the exact location of the user because depending on the length of the geohash we just know they are somewhere within an area.

The cell sizes of the geohashes of different lengths are as follows:

| Geohash length | Cell width | Cell height |
| -------------- | ---------- | ----------- |
| 1              | 5000 km    | 5000 km     |
| 2              | 1250 km    | 1250 km     |
| 3              | 156 km     | 156 km      |
| 4              | 39.1 km    | 19.5 km     |
| 5              | 4.89 km    | 4.89 km     |
| 6              | 1.22 km    | 0.61 km     |
| 7              | 153 m      | 153 m       |
| 8              | 38.2 m     | 19.1 m      |
| 9              | 4.77 m     | 4.77 m      |
| 10             | 1.19 m     | 0.596 m     |
| 11             | 149 mm     | 149 mm      |
| 12             | 37.2 mm    | 18.6 mm     |

### Use cases

Here are some common use cases for Geohashing:

- It is a simple way to represent and store a location in a database.
- It can also be shared on social media as URLs since it is easier to share, and remember than latitudes and longitudes.
- We can efficiently find the nearest neighbors of a point through very simple string comparisons and efficient searching of indexes.

### Examples

Geohashing is widely used and it is supported by popular databases.

- [MySQL](https://www.mysql.com)
- [Redis](http://redis.io)
- [Amazon DynamoDB](https://aws.amazon.com/dynamodb)
- [Google Cloud Firestore](https://cloud.google.com/firestore)

## Quadtrees

A quadtree is a tree data structure in which each internal node has exactly four children. They are often used to partition a two-dimensional space by recursively subdividing it into four quadrants or regions. Each child or leaf node stores spatial information. Quadtrees are the two-dimensional analog of [Octrees](https://en.wikipedia.org/wiki/Octree) which are used to partition three-dimensional space.

![quadtree](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/geohashing-and-quadtrees/quadtree.png)

### Types of Quadtrees

Quadtrees may be classified according to the type of data they represent, including areas, points, lines, and curves. The following are common types of quadtrees:

- Point quadtrees
- Point-region (PR) quadtrees
- Polygonal map (PM) quadtrees
- Compressed quadtrees
- Edge quadtrees

### Why do we need Quadtrees?

Aren't latitudes and longitudes enough? Why do we need quadtrees? While in theory using latitude and longitude we can determine things such as how close points are to each other using [euclidean distance](https://en.wikipedia.org/wiki/Euclidean_distance), for practical use cases it is simply not scalable because of its CPU-intensive nature with large data sets.

![quadtree-subdivision](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/geohashing-and-quadtrees/quadtree-subdivision.png)

Quadtrees enable us to search points within a two-dimensional range efficiently, where those points are defined as latitude/longitude coordinates or as cartesian (x, y) coordinates. Additionally, we can save further computation by only subdividing a node after a certain threshold. And with the application of mapping algorithms such as the [Hilbert curve](https://en.wikipedia.org/wiki/Hilbert_curve), we can easily improve range query performance.

### Use cases

Below are some common uses of quadtrees:

- Image representation, processing, and compression.
- Spacial indexing and range queries.
- Location-based services like Google Maps, Uber, etc.
- Mesh generation and computer graphics.
- Sparse data storage.

# Circuit breaker

The circuit breaker is a design pattern used to detect failures and encapsulates the logic of preventing a failure from constantly recurring during maintenance, temporary external system failure, or unexpected system difficulties.

![circuit-breaker](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/circuit-breaker/circuit-breaker.png)

The basic idea behind the circuit breaker is very simple. We wrap a protected function call in a circuit breaker object, which monitors for failures. Once the failures reach a certain threshold, the circuit breaker trips, and all further calls to the circuit breaker return with an error, without the protected call being made at all. Usually, we'll also want some kind of monitor alert if the circuit breaker trips.

## Why do we need circuit breaking?

It's common for software systems to make remote calls to software running in different processes, probably on different machines across a network. One of the big differences between in-memory calls and remote calls is that remote calls can fail, or hang without a response until some timeout limit is reached. What's worse is if we have many callers on an unresponsive supplier, then we can run out of critical resources leading to cascading failures across multiple systems.

## States

Let's discuss circuit breaker states:

### Closed

When everything is normal, the circuit breakers remain closed, and all the request passes through to the services as normal. If the number of failures increases beyond the threshold, the circuit breaker trips and goes into an open state.

### Open

In this state circuit breaker returns an error immediately without even invoking the services. The Circuit breakers move into the half-open state after a certain timeout period elapses. Usually, it will have a monitoring system where the timeout will be specified.

### Half-open

In this state, the circuit breaker allows a limited number of requests from the service to pass through and invoke the operation. If the requests are successful, then the circuit breaker will go to the closed state. However, if the requests continue to fail, then it goes back to the open state.

# Rate Limiting

Rate limiting refers to preventing the frequency of an operation from exceeding a defined limit. In large-scale systems, rate limiting is commonly used to protect underlying services and resources. Rate limiting is generally used as a defensive mechanism in distributed systems, so that shared resources can maintain availability. It also protects our APIs from unintended or malicious overuse by limiting the number of requests that can reach our API in a given period of time.

![rate-limiting](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/rate-limiting/rate-limiting.png)

## Why do we need Rate Limiting?

Rate limiting is a very important part of any large-scale system and it can be used to accomplish the following:

- Avoid resource starvation as a result of Denial of Service (DoS) attacks.
- Rate Limiting helps in controlling operational costs by putting a virtual cap on the auto-scaling of resources which if not monitored might lead to exponential bills.
- Rate limiting can be used as defense or mitigation against some common attacks.
- For APIs that process massive amounts of data, rate limiting can be used to control the flow of that data.

## Algorithms

There are various algorithms for API rate limiting, each with its advantages and disadvantages. Let's briefly discuss some of these algorithms:

### Leaky Bucket

Leaky Bucket is an algorithm that provides a simple, intuitive approach to rate limiting via a queue. When registering a request, the system appends it to the end of the queue. Processing for the first item on the queue occurs at a regular interval or first-in, first-out (FIFO). If the queue is full, then additional requests are discarded (or leaked).

### Token Bucket

Here we use a concept of a _bucket_. When a request comes in, a token from the bucket must be taken and processed. The request will be refused if no token is available in the bucket, and the requester will have to try again later. As a result, the token bucket gets refreshed after a certain time period.

### Fixed Window

The system uses a window size of `n` seconds to track the fixed window algorithm rate. Each incoming request increments the counter for the window. It discards the request if the counter exceeds a threshold.

### Sliding Log

Sliding Log rate-limiting involves tracking a time-stamped log for each request. The system stores these logs in a time-sorted hash set or table. It also discards logs with timestamps beyond a threshold. When a new request comes in, we calculate the sum of logs to determine the request rate. If the request would exceed the threshold rate, then it is held.

### Sliding Window

Sliding Window is a hybrid approach that combines the fixed window algorithm's low processing cost and the sliding log's improved boundary conditions. Like the fixed window algorithm, we track a counter for each fixed window. Next, we account for a weighted value of the previous window's request rate based on the current timestamp to smooth out bursts of traffic.

## Rate Limiting in Distributed Systems

Rate Limiting becomes complicated when distributed systems are involved. The two broad problems that come with rate limiting in distributed systems are:

### Inconsistencies

When using a cluster of multiple nodes, we might need to enforce a global rate limit policy. Because if each node were to track its rate limit, a consumer could exceed a global rate limit when sending requests to different nodes. The greater the number of nodes, the more likely the user will exceed the global limit.

The simplest way to solve this problem is to use sticky sessions in our load balancers so that each consumer gets sent to exactly one node but this causes a lack of fault tolerance and scaling problems. Another approach might be to use a centralized data store like [Redis](https://redis.io) but this will increase latency and cause race conditions.

### Race Conditions

This issue happens when we use a naive _"get-then-set"_ approach, in which we retrieve the current rate limit counter, increment it, and then push it back to the datastore. This model's problem is that additional requests can come through in the time it takes to perform a full cycle of read-increment-store, each attempting to store the increment counter with an invalid (lower) counter value. This allows a consumer to send a very large number of requests to bypass the rate limiting controls.

One way to avoid this problem is to use some sort of distributed locking mechanism around the key, preventing any other processes from accessing or writing to the counter. Though the lock will become a significant bottleneck and will not scale well. A better approach might be to use a _"set-then-get"_ approach, allowing us to quickly increment and check counter values without letting the atomic operations get in the way.

# Service Discovery

Service discovery is the detection of services within a computer network. Service Discovery Protocol (SDP) is a networking standard that accomplishes the detection of networks by identifying resources.

## Why do we need Service Discovery?

In a monolithic application, services invoke one another through language-level methods or procedure calls. However, modern microservices-based applications typically run in virtualized or containerized environments where the number of instances of a service and their locations change dynamically. Consequently, we need a mechanism that enables the clients of service to make requests to a dynamically changing set of ephemeral service instances.

## Implementations

There are two main service discovery patterns:

### Client-side discovery

![client-side-service-discovery](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/service-discovery/client-side-service-discovery.png)

In this approach, the client obtains the location of another service by querying a service registry which is responsible for managing and storing the network locations of all the services.

### Server-side discovery

![server-side-service-discovery](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/service-discovery/server-side-service-discovery.png)

In this approach, we use an intermediate component such as a load balancer. The client makes a request to the service via a load balancer which then forwards the request to an available service instance.

## Service Registry

A service registry is basically a database containing the network locations of service instances to which the clients can reach out. A Service Registry must be highly available and up-to-date.

## Service Registration

We also need a way to obtain service information, often known as service registration. Let's look at two possible service registration approaches:

### Self-Registration

When using the self-registration model, a service instance is responsible for registering and de-registering itself in the Service Registry. In addition, if necessary, a service instance sends heartbeat requests to keep its registration alive.

### Third-party Registration

The registry keeps track of changes to running instances by polling the deployment environment or subscribing to events. When it detects a newly available service instance, it records it in its database. The Service Registry also de-registers terminated service instances.

## Service mesh

Service-to-service communication is essential in a distributed application but routing this communication, both within and across application clusters, becomes increasingly complex as the number of services grows. Service mesh enables managed, observable, and secure communication between individual services. It works with a service discovery protocol to detect services. [Istio](https://istio.io/latest/about/service-mesh) and [envoy](https://www.envoyproxy.io) are some of the most commonly used service mesh technologies.

## Examples

Here are some commonly used service discovery infrastructure tools:

- [etcd](https://etcd.io)
- [Consul](https://www.consul.io)
- [Apache Thrift](https://thrift.apache.org)
- [Apache Zookeeper](https://zookeeper.apache.org)

# SLA, SLO, SLI

Let's briefly discuss SLA, SLO, and SLI. These are mostly related to the business and site reliability side of things but good to know nonetheless.

## Why are they important?

SLAs, SLOs, and SLIs allow companies to define, track and monitor the promises made for a service to its users. Together, SLAs, SLOs, and SLIs should help teams generate more user trust in their services with an added emphasis on continuous improvement to incident management and response processes.

## SLA

An SLA, or Service Level Agreement, is an agreement made between a company and its users of a given service. The SLA defines the different promises that the company makes to users regarding specific metrics, such as service availability.

_SLAs are often written by a company's business or legal team._

## SLO

An SLO, or Service Level Objective, is the promise that a company makes to users regarding a specific metric such as incident response or uptime. SLOs exist within an SLA as individual promises contained within the full user agreement. The SLO is the specific goal that the service must meet in order to comply with the SLA. SLOs should always be simple, clearly defined, and easily measured to determine whether or not the objective is being fulfilled.

## SLI

An SLI, or Service Level Indicator, is a key metric used to determine whether or not the SLO is being met. It is the measured value of the metric described within the SLO. In order to remain in compliance with the SLA, the SLI's value must always meet or exceed the value determined by the SLO.

# Disaster recovery

Disaster recovery (DR) is a process of regaining access and functionality of the infrastructure after events like a natural disaster, cyber attack, or even business disruptions.

Disaster recovery relies upon the replication of data and computer processing in an off-premises location not affected by the disaster. When servers go down because of a disaster, a business needs to recover lost data from a second location where the data is backed up. Ideally, an organization can transfer its computer processing to that remote location as well in order to continue operations.

_Disaster Recovery is often not actively discussed during system design interviews but it's important to have some basic understanding of this topic. You can learn more about disaster recovery from [AWS Well-Architected Framework](https://docs.aws.amazon.com/wellarchitected/latest/reliability-pillar/plan-for-disaster-recovery-dr.html)._

## Why is disaster recovery important?

Disaster recovery can have the following benefits:

- Minimize interruption and downtime
- Limit damages
- Fast restoration
- Better customer retention

## Terms

Let's discuss some important terms relevantly for disaster recovery:

![disaster-recovery](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/disaster-recovery/disaster-recovery.png)

### RTO

Recovery Time Objective (RTO) is the maximum acceptable delay between the interruption of service and restoration of service. This determines what is considered an acceptable time window when service is unavailable.

### RPO

Recovery Point Objective (RPO) is the maximum acceptable amount of time since the last data recovery point. This determines what is considered an acceptable loss of data between the last recovery point and the interruption of service.

## Strategies

A variety of disaster recovery (DR) strategies can be part of a disaster recovery plan.

### Back-up

This is the simplest type of disaster recovery and involves storing data off-site or on a removable drive.

### Cold Site

In this type of disaster recovery, an organization sets up basic infrastructure in a second site.

### Hot site

A hot site maintains up-to-date copies of data at all times. Hot sites are time-consuming to set up and more expensive than cold sites, but they dramatically reduce downtime.

# Virtual Machines (VMs) and Containers

Before we discuss virtualization vs containerization, let's learn what are virtual machines (VMs) and Containers.

## Virtual Machines (VM)

A Virtual Machine (VM) is a virtual environment that functions as a virtual computer system with its own CPU, memory, network interface, and storage, created on a physical hardware system. A software called a hypervisor separates the machine's resources from the hardware and provisions them appropriately so they can be used by the VM.

VMs are isolated from the rest of the system, and multiple VMs can exist on a single piece of hardware, like a server. They can be moved between host servers depending on the demand or to use resources more efficiently.

### What is a Hypervisor?

A Hypervisor sometimes called a Virtual Machine Monitor (VMM), isolates the operating system and resources from the virtual machines and enables the creation and management of those VMs. The hypervisor treats resources like CPU, memory, and storage as a pool of resources that can be easily reallocated between existing guests or new virtual machines.

### Why use a Virtual Machine?

Server consolidation is a top reason to use VMs. Most operating system and application deployments only use a small amount of the physical resources available. By virtualizing our servers, we can place many virtual servers onto each physical server to improve hardware utilization. This keeps us from needing to purchase additional physical resources.

A VM provides an environment that is isolated from the rest of a system, so whatever is running inside a VM won't interfere with anything else running on the host hardware. Because VMs are isolated, they are a good option for testing new applications or setting up a production environment. We can also run a single-purpose VM to support a specific use case.

## Containers

A container is a standard unit of software that packages up code and all its dependencies such as specific versions of runtimes and libraries so that the application runs quickly and reliably from one computing environment to another. Containers offer a logical packaging mechanism in which applications can be abstracted from the environment in which they actually run. This decoupling allows container-based applications to be deployed easily and consistently, regardless of the target environment.

### Why do we need containers?

Let's discuss some advantages of using containers:

**Separation of responsibility**

Containerization provides a clear separation of responsibility, as developers focus on application logic and dependencies, while operations teams can focus on deployment and management.

**Workload portability**

Containers can run virtually anywhere, greatly easing development and deployment.

**Application isolation**

Containers virtualize CPU, memory, storage, and network resources at the operating system level, providing developers with a view of the OS logically isolated from other applications.

**Agile development**

Containers allow developers to move much more quickly by avoiding concerns about dependencies and environments.

**Efficient operations**

Containers are lightweight and allow us to use just the computing resources we need.

## Virtualization vs Containerization

![virtualization-vs-containerization](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/virtual-machines-and-containers/virtualization-vs-containerization.png)

In traditional virtualization, a hypervisor virtualizes physical hardware. The result is that each virtual machine contains a guest OS, a virtual copy of the hardware that the OS requires to run, and an application and its associated libraries and dependencies.

Instead of virtualizing the underlying hardware, containers virtualize the operating system so each container contains only the application and its dependencies making them much more lightweight than VMs. Containers also share the OS kernel and use a fraction of the memory VMs require.

# OAuth 2.0 and OpenID Connect (OIDC)

## OAuth 2.0

OAuth 2.0, which stands for Open Authorization, is a standard designed to provide consented access to resources on behalf of the user, without ever sharing the user's credentials. OAuth 2.0 is an authorization protocol and not an authentication protocol, it is designed primarily as a means of granting access to a set of resources, for example, remote APIs or user's data.

### Concepts

The OAuth 2.0 protocol defines the following entities:

- **Resource Owner**: The user or system that owns the protected resources and can grant access to them.
- **Client**: The client is the system that requires access to the protected resources.
- **Authorization Server**: This server receives requests from the Client for Access Tokens and issues them upon successful authentication and consent by the Resource Owner.
- **Resource Server**: A server that protects the user's resources and receives access requests from the Client. It accepts and validates an Access Token from the Client and returns the appropriate resources.
- **Scopes**: They are used to specify exactly the reason for which access to resources may be granted. Acceptable scope values, and which resources they relate to, are dependent on the Resource Server.
- **Access Token**: A piece of data that represents the authorization to access resources on behalf of the end-user.

### How does OAuth 2.0 work?

Let's learn how OAuth 2.0 works:

![oauth2](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/oauth2-and-openid-connect/oauth2.png)

1. The client requests authorization from the Authorization Server, supplying the client id and secret as identification. It also provides the scopes and an endpoint URI to send the Access Token or the Authorization Code.
2. The Authorization Server authenticates the client and verifies that the requested scopes are permitted.
3. The resource owner interacts with the authorization server to grant access.
4. The Authorization Server redirects back to the client with either an Authorization Code or Access Token, depending on the grant type. A Refresh Token may also be returned.
5. With the Access Token, the client can request access to the resource from the Resource Server.

### Disadvantages

Here are the most common disadvantages of OAuth 2.0:

- Lacks built-in security features.
- No standard implementation.
- No common set of scopes.

## OpenID Connect

OAuth 2.0 is designed only for _authorization_, for granting access to data and features from one application to another. OpenID Connect (OIDC) is a thin layer that sits on top of OAuth 2.0 that adds login and profile information about the person who is logged in.

When an Authorization Server supports OIDC, it is sometimes called an Identity Provider (IdP), since it provides information about the Resource Owner back to the Client. OpenID Connect is relatively new, resulting in lower adoption and industry implementation of best practices compared to OAuth.

### Concepts

The OpenID Connect (OIDC) protocol defines the following entities:

- **Relying Party**: The current application.
- **OpenID Provider**: This is essentially an intermediate service that provides a one-time code to the Relying Party.
- **Token Endpoint**: A web server that accepts the One-Time Code (OTC) and provides an access code that's valid for an hour. The main difference between OIDC and OAuth 2.0 is that the token is provided using JSON Web Token (JWT).
- **UserInfo Endpoint**: The Relying Party communicates with this endpoint, providing a secure token and receiving information about the end-user

Both OAuth 2.0 and OIDC are easy to implement and are JSON based, which is supported by most web and mobile applications. However, the OpenID Connect (OIDC) specification is more strict than that of basic OAuth.

# Single Sign-On (SSO)

Single Sign-On (SSO) is an authentication process in which a user is provided access to multiple applications or websites by using only a single set of login credentials. This prevents the need for the user to log separately into the different applications.

The user credentials and other identifying information are stored and managed by a centralized system called Identity Provider (IdP). The Identity Provider is a trusted system that provides access to other websites and applications.

Single Sign-On (SSO) based authentication systems are commonly used in enterprise environments where employees require access to multiple applications of their organizations.

## Components

Let's discuss some key components of Single Sign-On (SSO).

### Identity Provider (IdP)

User Identity information is stored and managed by a centralized system called Identity Provider (IdP). The Identity Provider authenticates the user and provides access to the service provider.

The identity provider can directly authenticate the user by validating a username and password or by validating an assertion about the user's identity as presented by a separate identity provider. The identity provider handles the management of user identities in order to free the service provider from this responsibility.

### Service Provider

A service provider provides services to the end-user. They rely on identity providers to assert the identity of a user, and typically certain attributes about the user are managed by the identity provider. Service providers may also maintain a local account for the user along with attributes that are unique to their service.

### Identity Broker

An identity broker acts as an intermediary that connects multiple service providers with various different identity providers. Using Identity Broker, we can perform single sign-on over any application without the hassle of the protocol it follows.

## SAML

Security Assertion Markup Language is an open standard that allows clients to share security information about identity, authentication, and permission across different systems. SAML is implemented with the Extensible Markup Language (XML) standard for sharing data.

SAML specifically enables identity federation, making it possible for identity providers (IdPs) to seamlessly and securely pass authenticated identities and their attributes to service providers.

## How does SSO work?

Now, let's discuss how Single Sign-On works:

![sso](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/single-sign-on/sso.png)

1. The user requests a resource from their desired application.
2. The application redirects the user to the Identity Provider (IdP) for authentication.
3. The user signs in with their credentials (usually, username and password).
4. Identity Provider (IdP) sends a Single Sign-On response back to the client application.
5. The application grants access to the user.

## SAML vs OAuth 2.0 and OpenID Connect (OIDC)

There are many differences between SAML, OAuth, and OIDC. SAML uses XML to pass messages, while OAuth and OIDC use JSON. OAuth provides a simpler experience, while SAML is geared towards enterprise security.

OAuth and OIDC use RESTful communication extensively, which is why mobile, and modern web applications find OAuth and OIDC a better experience for the user. SAML, on the other hand, drops a session cookie in a browser that allows a user to access certain web pages. This is great for short-lived workloads.

OIDC is developer-friendly and simpler to implement, which broadens the use cases for which it might be implemented. It can be implemented from scratch pretty fast, via freely available libraries in all common programming languages. SAML can be complex to install and maintain, which only enterprise-size companies can handle well.

OpenID Connect is essentially a layer on top of the OAuth framework. Therefore, it can offer a built-in layer of permission that asks a user to agree to what the service provider might access. Although SAML is also capable of allowing consent flow, it achieves this by hard-coding carried out by a developer and not as part of its protocol.

_Both of these authentication protocols are good at what they do. As always, a lot depends on our specific use cases and target audience._

## Advantages

Following are the benefits of using Single Sign-On:

- Ease of use as users only need to remember one set of credentials.
- Ease of access without having to go through a lengthy authorization process.
- Enforced security and compliance to protect sensitive data.
- Simplifying the management with reduced IT support cost and admin time.

## Disadvantages

Here are some disadvantages of Single Sign-On:

- Single Password Vulnerability, if the main SSO password gets compromised, all the supported applications get compromised.
- The authentication process using Single Sign-On is slower than traditional authentication as every application has to request the SSO provider for verification.

## Examples

These are some commonly used Identity Providers (IdP):

- [Okta](https://www.okta.com)
- [Google](https://cloud.google.com/architecture/identity/single-sign-on)
- [Auth0](https://auth0.com)
- [OneLogin](https://www.onelogin.com)

# SSL, TLS, mTLS

Let's briefly discuss some important communication security protocols such as SSL, TLS, and mTLS. I would say that from a _"big picture"_ system design perspective, this topic is not very important but still good to know about.

## SSL

SSL stands for Secure Sockets Layer, and it refers to a protocol for encrypting and securing communications that take place on the internet. It was first developed in 1995 but since has been deprecated in favor of TLS (Transport Layer Security).

### Why is it called an SSL certificate if it is deprecated?

Most major certificate providers still refer to certificates as SSL certificates, which is why the naming convention persists.

### Why was SSL so important?

Originally, data on the web was transmitted in plaintext that anyone could read if they intercepted the message. SSL was created to correct this problem and protect user privacy. By encrypting any data that goes between the user and a web server, SSL also stops certain kinds of cyber attacks by preventing attackers from tampering with data in transit.

## TLS

Transport Layer Security, or TLS, is a widely adopted security protocol designed to facilitate privacy and data security for communications over the internet. TLS evolved from a previous encryption protocol called Secure Sockets Layer (SSL). A primary use case of TLS is encrypting the communication between web applications and servers.

There are three main components to what the TLS protocol accomplishes:

- **Encryption**: hides the data being transferred from third parties.
- **Authentication**: ensures that the parties exchanging information are who they claim to be.
- **Integrity**: verifies that the data has not been forged or tampered with.

## mTLS

Mutual TLS, or mTLS, is a method for mutual authentication. mTLS ensures that the parties at each end of a network connection are who they claim to be by verifying that they both have the correct private key. The information within their respective TLS certificates provides additional verification.

### Why use mTLS?

mTLS helps ensure that the traffic is secure and trusted in both directions between a client and server. This provides an additional layer of security for users who log in to an organization's network or applications. It also verifies connections with client devices that do not follow a login process, such as Internet of Things (IoT) devices.

Nowadays, mTLS is commonly used by microservices or distributed systems in a [zero trust security model](https://en.wikipedia.org/wiki/Zero_trust_security_model) to verify each other.

# System Design Interviews

System design is a very extensive topic and system design interviews are designed to evaluate your capability to produce technical solutions to abstract problems, as such, they're not designed for a specific answer. The unique aspect of system design interviews is the two-way nature between the candidate and the interviewer.

Expectations are quite different at different engineering levels as well. This is because someone with a lot of practical experience will approach it quite differently from someone who's new in the industry. As a result, it's hard to come up with a single strategy that will help us stay organized during the interview.

Let's look at some common strategies for system design interviews:

## Requirements clarifications

System design interview questions, by nature, are vague or abstract. Asking questions about the exact scope of the problem, and clarifying functional requirements early in the interview is essential. Usually, requirements are divided into three parts:

### Functional requirements

These are the requirements that the end user specifically demands as basic functionalities that the system should offer. All these functionalities need to be necessarily incorporated into the system as part of the contract.

For example:

- "What are the features that we need to design for this system?"
- "What are the edge cases we need to consider, if any, in our design?"

### Non-functional requirements

These are the quality constraints that the system must satisfy according to the project contract. The priority or extent to which these factors are implemented varies from one project to another. They are also called non-behavioral requirements. For example, portability, maintainability, reliability, scalability, security, etc.

For example:

- "Each request should be processed with the minimum latency"
- "System should be highly available"

### Extended requirements

These are basically "nice to have" requirements that might be out of the scope of the system.

For example:

- "Our system should record metrics and analytics"
- "Service health and performance monitoring?"

## Estimation and Constraints

Estimate the scale of the system we're going to design. It is important to ask questions such as:

- "What is the desired scale that this system will need to handle?"
- "What is the read/write ratio of our system?"
- "How many requests per second?"
- "How much storage will be needed?"

These questions will help us scale our design later.

## Data model design

Once we have the estimations, we can start with defining the database schema. Doing so in the early stages of the interview would help us to understand the data flow which is the core of every system. In this step, we basically define all the entities and relationships between them.

- "What are the different entities in the system?"
- "What are the relationships between these entities?"
- "How many tables do we need?"
- "Is NoSQL a better choice here?"

## API design

Next, we can start designing APIs for the system. These APIs will help us define the expectations from the system explicitly. We don't have to write any code, just a simple interface defining the API requirements such as parameters, functions, classes, types, entities, etc.

For example:

```tsx
createUser(name: string, email: string): User
```

It is advised to keep the interface as simple as possible and come back to it later when covering extended requirements.

## High-level component design

Now we have established our data model and API design, it's time to identify system components (such as Load Balancers, API Gateway, etc.) that are needed to solve our problem and draft the first design of our system.

- "Is it best to design a monolithic or a microservices architecture?"
- "What type of database should we use?"

Once we have a basic diagram, we can start discussing with the interviewer how the system will work from the client's perspective.

## Detailed design

Now it's time to go into detail about the major components of the system we designed. As always discuss with the interviewer which component may need further improvements.

Here is a good opportunity to demonstrate your experience in the areas of your expertise. Present different approaches, advantages, and disadvantages. Explain your design decisions, and back them up with examples. This is also a good time to discuss any additional features the system might be able to support, though this is optional.

- "How should we partition our data?"
- "What about load distribution?"
- "Should we use cache?"
- "How will we handle a sudden spike in traffic?"

Also, try not to be too opinionated about certain technologies, statements like "I believe that NoSQL databases are just better, SQL databases are not scalable" reflect poorly. As someone who has interviewed a lot of people over the years, my two cents here would be to be humble about what you know and what you do not. Use your existing knowledge with examples to navigate this part of the interview.

## Identify and resolve bottlenecks

Finally, it's time to discuss bottlenecks and approaches to mitigate them. Here are some important questions to ask:

- "Do we have enough database replicas?"
- "Is there any single point of failure?"
- "Is database sharding required?"
- "How can we make our system more robust?"
- "How to improve the availability of our cache?"

Make sure to read the engineering blog of the company you're interviewing with. This will help you get a sense of what technology stack they're using and which problems are important to them.

# URL Shortener

Let's design a URL shortener, similar to services like [Bitly](https://bitly.com), [TinyURL](https://tinyurl.com/app).

## What is a URL Shortener?

A URL shortener service creates an alias or a short URL for a long URL. Users are redirected to the original URL when they visit these short links.

For example, the following long URL can be changed to a shorter URL.

**Long URL**: [https://karanpratapsingh.com/courses/system-design/url-shortener](https://karanpratapsingh.com/courses/system-design/url-shortener)

**Short URL**: [https://bit.ly/3I71d3o](https://bit.ly/3I71d3o)

## Why do we need a URL shortener?

URL shortener saves space in general when we are sharing URLs. Users are also less likely to mistype shorter URLs. Moreover, we can also optimize links across devices, this allows us to track individual links.

## Requirements

Our URL shortening system should meet the following requirements:

### Functional requirements

- Given a URL, our service should generate a _shorter and unique_ alias for it.
- Users should be redirected to the original URL when they visit the short link.
- Links should expire after a default timespan.

### Non-functional requirements

- High availability with minimal latency.
- The system should be scalable and efficient.

### Extended requirements

- Prevent abuse of services.
- Record analytics and metrics for redirections.

## Estimation and Constraints

Let's start with the estimation and constraints.

_Note: Make sure to check any scale or traffic related assumptions with your interviewer._

### Traffic

This will be a read-heavy system, so let's assume a `100:1` read/write ratio with 100 million links generated per month.

**Reads/Writes Per month**

For reads per month:

$$
100 \times 100 \space million = 10 \space billion/month
$$

Similarly for writes:

$$
1 \times 100 \space million = 100 \space million/month
$$

**What would be Requests Per Second (RPS) for our system?**

100 million requests per month translate into 40 requests per second.

$$
\frac{100 \space million}{(30 \space days \times 24 \space hrs \times 3600 \space seconds)} = \sim 40 \space URLs/second
$$

And with a `100:1` read/write ratio, the number of redirections will be:

$$
100 \times 40 \space URLs/second = 4000 \space requests/second
$$

### Bandwidth

Since we expect about 40 URLs every second, and if we assume each request is of size 500 bytes then the total incoming data for write requests would be:

$$
40 \times 500 \space bytes = 20 \space KB/second
$$

Similarly, for the read requests, since we expect about 4K redirections, the total outgoing data would be:

$$
4000 \space URLs/second \times 500 \space bytes = \sim 2 \space MB/second
$$

### Storage

For storage, we will assume we store each link or record in our database for 10 years. Since we expect around 100M new requests every month, the total number of records we will need to store would be:

$$
100 \space million \times 10\space years \times 12 \space months = 12 \space billion
$$

Like earlier, if we assume each stored record will be approximately 500 bytes. We will need around 6TB of storage:

$$
12 \space billion \times 500 \space bytes = 6 \space TB
$$

### Cache

For caching, we will follow the classic [Pareto principle](https://en.wikipedia.org/wiki/Pareto_principle) also known as the 80/20 rule. This means that 80% of the requests are for 20% of the data, so we can cache around 20% of our requests.

Since we get around 4K read or redirection requests each second, this translates into 350M requests per day.

$$
4000 \space URLs/second \times 24 \space hours \times 3600 \space seconds = \sim 350 \space million \space requests/day
$$

Hence, we will need around 35GB of memory per day.

$$
20 \space percent \times 350 \space million \times 500 \space bytes = 35 \space GB/day
$$

### High-level estimate

Here is our high-level estimate:

| Type                 | Estimate   |
| -------------------- | ---------- |
| Writes (New URLs)    | 40/s       |
| Reads (Redirection)  | 4K/s       |
| Bandwidth (Incoming) | 20 KB/s    |
| Bandwidth (Outgoing) | 2 MB/s     |
| Storage (10 years)   | 6 TB       |
| Memory (Caching)     | ~35 GB/day |

## Data model design

Next, we will focus on the data model design. Here is our database schema:

![url-shortener-datamodel](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/url-shortener/url-shortener-datamodel.png)

Initially, we can get started with just two tables:

**users**

Stores user's details such as `name`, `email`, `createdAt`, etc.

**urls**

Contains the new short URL's properties such as `expiration`, `hash`, `originalURL`, and `userID` of the user who created the short URL. We can also use the `hash` column as an [index](https://karanpratapsingh.com/courses/system-design/indexes) to improve the query performance.

### What kind of database should we use?

Since the data is not strongly relational, NoSQL databases such as [Amazon DynamoDB](https://aws.amazon.com/dynamodb), [Apache Cassandra](https://cassandra.apache.org/_/index.html), or [MongoDB](https://www.mongodb.com) will be a better choice here, if we do decide to use an SQL database then we can use something like [Azure SQL Database](https://azure.microsoft.com/en-in/products/azure-sql/database) or [Amazon RDS](https://aws.amazon.com/rds).

_For more details, refer to [SQL vs NoSQL](https://karanpratapsingh.com/courses/system-design/sql-vs-nosql-databases)._

## API design

Let us do a basic API design for our services:

### Create URL

This API should create a new short URL in our system given an original URL.

```tsx
createURL(apiKey: string, originalURL: string, expiration?: Date): string
```

**Parameters**

API Key (`string`): API key provided by the user.

Original URL (`string`): Original URL to be shortened.

Expiration (`Date`): Expiration date of the new URL _(optional)_.

**Returns**

Short URL (`string`): New shortened URL.

### Get URL

This API should retrieve the original URL from a given short URL.

```tsx
getURL(apiKey: string, shortURL: string): string
```

**Parameters**

API Key (`string`): API key provided by the user.

Short URL (`string`): Short URL mapped to the original URL.

**Returns**

Original URL (`string`): Original URL to be retrieved.

### Delete URL

This API should delete a given shortURL from our system.

```tsx
deleteURL(apiKey: string, shortURL: string): boolean
```

**Parameters**

API Key (`string`): API key provided by the user.

Short URL (`string`): Short URL to be deleted.

**Returns**

Result (`boolean`): Represents whether the operation was successful or not.

### Why do we need an API key?

As you must've noticed, we're using an API key to prevent abuse of our services. Using this API key we can limit the users to a certain number of requests per second or minute. This is quite a standard practice for developer APIs and should cover our extended requirement.

## High-level design

Now let us do a high-level design of our system.

### URL Encoding

Our system's primary goal is to shorten a given URL, let's look at different approaches:

**Base62 Approach**

In this approach, we can encode the original URL using [Base62](https://en.wikipedia.org/wiki/Base62) which consists of the capital letters A-Z, the lower case letters a-z, and the numbers 0-9.

$$
Number \space of \space URLs = 62^N
$$

Where,

`N`: Number of characters in the generated URL.

So, if we want to generate a URL that is 7 characters long, we will generate ~3.5 trillion different URLs.

$$
\begin{gather*}
62^5 = \sim 916 \space million \space URLs \\
62^6 = \sim 56.8 \space billion \space URLs \\
62^7 = \sim 3.5 \space trillion \space URLs
\end{gather*}
$$

This is the simplest solution here, but it does not guarantee non-duplicate or collision-resistant keys.

**MD5 Approach**

The [MD5 message-digest algorithm](https://en.wikipedia.org/wiki/MD5) is a widely used hash function producing a 128-bit hash value (or 32 hexadecimal digits). We can use these 32 hexadecimal digits for generating 7 characters long URL.

$$
MD5(original\_url) \rightarrow base62encode \rightarrow hash
$$

However, this creates a new issue for us, which is duplication and collision. We can try to re-compute the hash until we find a unique one but that will increase the overhead of our systems. It's better to look for more scalable approaches.

**Counter Approach**

In this approach, we will start with a single server which will maintain the count of the keys generated. Once our service receives a request, it can reach out to the counter which returns a unique number and increments the counter. When the next request comes the counter again returns the unique number and this goes on.

$$
Counter(0-3.5 \space trillion) \rightarrow base62encode \rightarrow hash
$$

The problem with this approach is that it can quickly become a single point for failure. And if we run multiple instances of the counter we can have collision as it's essentially a distributed system.

To solve this issue we can use a distributed system manager such as [Zookeeper](https://zookeeper.apache.org) which can provide distributed synchronization. Zookeeper can maintain multiple ranges for our servers.

$$
\begin{align*}
& Range \space 1: \space 1 \rightarrow 1,000,000 \\
& Range \space 2: \space 1,000,001 \rightarrow 2,000,000 \\
& Range \space 3: \space 2,000,001 \rightarrow 3,000,000 \\
& ...
\end{align*}
$$

Once a server reaches its maximum range Zookeeper will assign an unused counter range to the new server. This approach can guarantee non-duplicate and collision-resistant URLs. Also, we can run multiple instances of Zookeeper to remove the single point of failure.

### Key Generation Service (KGS)

As we discussed, generating a unique key at scale without duplication and collisions can be a bit of a challenge. To solve this problem, we can create a standalone Key Generation Service (KGS) that generates a unique key ahead of time and stores it in a separate database for later use. This approach can make things simple for us.

**How to handle concurrent access?**

Once the key is used, we can mark it in the database to make sure we don't reuse it, however, if there are multiple server instances reading data concurrently, two or more servers might try to use the same key.

The easiest way to solve this would be to store keys in two tables. As soon as a key is used, we move it to a separate table with appropriate locking in place. Also, to improve reads, we can keep some of the keys in memory.

**KGS database estimations**

As per our discussion, we can generate up to ~56.8 billion unique 6 character long keys which will result in us having to store 300 GB of keys.

$$
6 \space characters \times 56.8 \space billion = \sim 390 \space GB
$$

While 390 GB seems like a lot for this simple use case, it is important to remember this is for the entirety of our service lifetime and the size of the keys database would not increase like our main database.

### Caching

Now, let's talk about [caching](https://karanpratapsingh.com/courses/system-design/caching). As per our estimations, we will require around ~35 GB of memory per day to cache 20% of the incoming requests to our services. For this use case, we can use [Redis](https://redis.io) or [Memcached](https://memcached.org) servers alongside our API server.

_For more details, refer to [caching](https://karanpratapsingh.com/courses/system-design/caching)._

### Design

Now that we have identified some core components, let's do the first draft of our system design.

![url-shortener-basic-design](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/url-shortener/url-shortener-basic-design.png)

Here's how it works:

**Creating a new URL**

1. When a user creates a new URL, our API server requests a new unique key from the Key Generation Service (KGS).
2. Key Generation Service provides a unique key to the API server and marks the key as used.
3. API server writes the new URL entry to the database and cache.
4. Our service returns an HTTP 201 (Created) response to the user.

**Accessing a URL**

1. When a client navigates to a certain short URL, the request is sent to the API servers.
2. The request first hits the cache, and if the entry is not found there then it is retrieved from the database and an HTTP 301 (Redirect) is issued to the original URL.
3. If the key is still not found in the database, an HTTP 404 (Not found) error is sent to the user.

## Detailed design

It's time to discuss the finer details of our design.

### Data Partitioning

To scale out our databases we will need to partition our data. Horizontal partitioning (aka [Sharding](https://karanpratapsingh.com/courses/system-design/sharding)) can be a good first step. We can use partitions schemes such as:

- Hash-Based Partitioning
- List-Based Partitioning
- Range Based Partitioning
- Composite Partitioning

The above approaches can still cause uneven data and load distribution, we can solve this using [Consistent hashing](https://karanpratapsingh.com/courses/system-design/consistent-hashing).

_For more details, refer to [Sharding](https://karanpratapsingh.com/courses/system-design/sharding) and [Consistent Hashing](https://karanpratapsingh.com/courses/system-design/consistent-hashing)._

### Database cleanup

This is more of a maintenance step for our services and depends on whether we keep the expired entries or remove them. If we do decide to remove expired entries, we can approach this in two different ways:

**Active cleanup**

In active cleanup, we will run a separate cleanup service which will periodically remove expired links from our storage and cache. This will be a very lightweight service like a [cron job](https://en.wikipedia.org/wiki/Cron).

**Passive cleanup**

For passive cleanup, we can remove the entry when a user tries to access an expired link. This can ensure a lazy cleanup of our database and cache.

### Cache

Now let us talk about [caching](https://karanpratapsingh.com/courses/system-design/caching).

**Which cache eviction policy to use?**

As we discussed before, we can use solutions like [Redis](https://redis.io) or [Memcached](https://memcached.org) and cache 20% of the daily traffic but what kind of cache eviction policy would best fit our needs?

[Least Recently Used (LRU)](<https://en.wikipedia.org/wiki/Cache_replacement_policies#Least_recently_used_(LRU)>) can be a good policy for our system. In this policy, we discard the least recently used key first.

**How to handle cache miss?**

Whenever there is a cache miss, our servers can hit the database directly and update the cache with the new entries.

### Metrics and Analytics

Recording analytics and metrics is one of our extended requirements. We can store and update metadata like visitor's country, platform, the number of views, etc alongside the URL entry in our database.

### Security

For security, we can introduce private URLs and authorization. A separate table can be used to store user ids that have permission to access a specific URL. If a user does not have proper permissions, we can return an HTTP 401 (Unauthorized) error.

We can also use an [API Gateway](https://karanpratapsingh.com/courses/system-design/api-gateway) as they can support capabilities like authorization, rate limiting, and load balancing out of the box.

## Identify and resolve bottlenecks

![url-shortener-advanced-design](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/url-shortener/url-shortener-advanced-design.png)

Let us identify and resolve bottlenecks such as single points of failure in our design:

- "What if the API service or Key Generation Service crashes?"
- "How will we distribute our traffic between our components?"
- "How can we reduce the load on our database?"
- "What if the key database used by KGS fails?"
- "How to improve the availability of our cache?"

To make our system more resilient we can do the following:

- Running multiple instances of our Servers and Key Generation Service.
- Introducing [load balancers](https://karanpratapsingh.com/courses/system-design/load-balancing) between clients, servers, databases, and cache servers.
- Using multiple read replicas for our database as it's a read-heavy system.
- Standby replica for our key database in case it fails.
- Multiple instances and replicas for our distributed cache.

# WhatsApp

Let's design a [WhatsApp](https://whatsapp.com) like instant messaging service, similar to services like [Facebook Messenger](https://www.messenger.com), and [WeChat](https://www.wechat.com).

## What is WhatsApp?

WhatsApp is a chat application that provides instant messaging services to its users. It is one of the most used mobile applications on the planet, connecting over 2 billion users in 180+ countries. WhatsApp is also available on the web.

## Requirements

Our system should meet the following requirements:

### Functional requirements

- Should support one-on-one chat.
- Group chats (max 100 people).
- Should support file sharing (image, video, etc.).

### Non-functional requirements

- High availability with minimal latency.
- The system should be scalable and efficient.

### Extended requirements

- Sent, Delivered, and Read receipts of the messages.
- Show the last seen time of users.
- Push notifications.

## Estimation and Constraints

Let's start with the estimation and constraints.

_Note: Make sure to check any scale or traffic-related assumptions with your interviewer._

### Traffic

Let us assume we have 50 million daily active users (DAU) and on average each user sends at least 10 messages to 4 different people every day. This gives us 2 billion messages per day.

$$
50 \space million \times 40 \space messages = 2 \space billion/day
$$

Messages can also contain media such as images, videos, or other files. We can assume that 5 percent of messages are media files shared by the users, which gives us additional 100 million files we would need to store.

$$
5 \space percent \times 2 \space billion = 100 \space million/day
$$

**What would be Requests Per Second (RPS) for our system?**

2 billion requests per day translate into 24K requests per second.

$$
\frac{2 \space billion}{(24 \space hrs \times 3600 \space seconds)} = \sim 24K \space requests/second
$$

### Storage

If we assume each message on average is 100 bytes, we will require about 200 GB of database storage every day.

$$
2 \space billion \times 100 \space bytes = \sim 200 \space GB/day
$$

As per our requirements, we also know that around 5 percent of our daily messages (100 million) are media files. If we assume each file is 100 KB on average, we will require 10 TB of storage every day.

$$
100 \space million \times 100 \space KB = 10 \space TB/day
$$

And for 10 years, we will require about 38 PB of storage.

$$
(10 \space TB + 0.2 \space TB) \times 10 \space years \times 365 \space days = \sim 38 \space PB
$$

### Bandwidth

As our system is handling 10.2 TB of ingress every day, we will require a minimum bandwidth of around 120 MB per second.

$$
\frac{10.2 \space TB}{(24 \space hrs \times 3600 \space seconds)} = \sim 120 \space MB/second
$$

### High-level estimate

Here is our high-level estimate:

| Type                      | Estimate   |
| ------------------------- | ---------- |
| Daily active users (DAU)  | 50 million |
| Requests per second (RPS) | 24K/s      |
| Storage (per day)         | ~10.2 TB   |
| Storage (10 years)        | ~38 PB     |
| Bandwidth                 | ~120 MB/s  |

## Data model design

This is the general data model which reflects our requirements.

![whatsapp-datamodel](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/whatsapp/whatsapp-datamodel.png)

We have the following tables:

**users**

This table will contain a user's information such as `name`, `phoneNumber`, and other details.

**messages**

As the name suggests, this table will store messages with properties such as `type` (text, image, video, etc.), `content`, and timestamps for message delivery. The message will also have a corresponding `chatID` or `groupID`.

**chats**

This table basically represents a private chat between two users and can contain multiple messages.

**users_chats**

This table maps users and chats as multiple users can have multiple chats (N:M relationship) and vice versa.

**groups**

This table represents a group made up of multiple users.

**users_groups**

This table maps users and groups as multiple users can be a part of multiple groups (N:M relationship) and vice versa.

### What kind of database should we use?

While our data model seems quite relational, we don't necessarily need to store everything in a single database, as this can limit our scalability and quickly become a bottleneck.

We will split the data between different services each having ownership over a particular table. Then we can use a relational database such as [PostgreSQL](https://www.postgresql.org) or a distributed NoSQL database such as [Apache Cassandra](https://cassandra.apache.org/_/index.html) for our use case.

## API design

Let us do a basic API design for our services:

### Get all chats or groups

This API will get all chats or groups for a given `userID`.

```tsx
getAll(userID: UUID): Chat[] | Group[]
```

**Parameters**

User ID (`UUID`): ID of the current user.

**Returns**

Result (`Chat[] | Group[]`): All the chats and groups the user is a part of.

### Get messages

Get all messages for a user given the `channelID` (chat or group id).

```tsx
getMessages(userID: UUID, channelID: UUID): Message[]
```

**Parameters**

User ID (`UUID`): ID of the current user.

Channel ID (`UUID`): ID of the channel (chat or group) from which messages need to be retrieved.

**Returns**

Messages (`Message[]`): All the messages in a given chat or group.

### Send message

Send a message from a user to a channel (chat or group).

```tsx
sendMessage(userID: UUID, channelID: UUID, message: Message): boolean
```

**Parameters**

User ID (`UUID`): ID of the current user.

Channel ID (`UUID`): ID of the channel (chat or group) user wants to send a message to.

Message (`Message`): The message (text, image, video, etc.) that the user wants to send.

**Returns**

Result (`boolean`): Represents whether the operation was successful or not.

### Join or leave a channel

Allows the user to join or leave a channel (chat or group).

```tsx
joinGroup(userID: UUID, channelID: UUID): boolean
leaveGroup(userID: UUID, channelID: UUID): boolean
```

**Parameters**

User ID (`UUID`): ID of the current user.

Channel ID (`UUID`): ID of the channel (chat or group) the user wants to join or leave.

**Returns**

Result (`boolean`): Represents whether the operation was successful or not.

## High-level design

Now let us do a high-level design of our system.

### Architecture

We will be using [microservices architecture](https://karanpratapsingh.com/courses/system-design/monoliths-microservices#microservices) since it will make it easier to horizontally scale and decouple our services. Each service will have ownership of its own data model. Let's try to divide our system into some core services.

**User Service**

This is an HTTP-based service that handles user-related concerns such as authentication and user information.

**Chat Service**

The chat service will use WebSockets to establish connections with the client to handle chat and group message-related functionality. We can also use cache to keep track of all the active connections, sort of like sessions which will help us determine if the user is online or not.

**Notification Service**

This service will simply send push notifications to the users. It will be discussed in detail separately.

**Presence Service**

The presence service will keep track of the _last seen_ status of all users. It will be discussed in detail separately.

**Media service**

This service will handle the media (images, videos, files, etc.) uploads. It will be discussed in detail separately.

**What about inter-service communication and service discovery?**

Since our architecture is microservices-based, services will be communicating with each other as well. Generally, REST or HTTP performs well but we can further improve the performance using [gRPC](https://karanpratapsingh.com/courses/system-design/rest-graphql-grpc#grpc) which is more lightweight and efficient.

[Service discovery](https://karanpratapsingh.com/courses/system-design/service-discovery) is another thing we will have to take into account. We can also use a service mesh that enables managed, observable, and secure communication between individual services.

_Note: Learn more about [REST, GraphQL, gRPC](https://karanpratapsingh.com/courses/system-design/rest-graphql-grpc) and how they compare with each other._

### Real-time messaging

How do we efficiently send and receive messages? We have two different options:

**Pull model**

The client can periodically send an HTTP request to servers to check if there are any new messages. This can be achieved via something like [Long polling](https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events#long-polling).

**Push model**

The client opens a long-lived connection with the server and once new data is available it will be pushed to the client. We can use [WebSockets](https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events#websockets) or [Server-Sent Events (SSE)](https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events#server-sent-events-sse) for this.

The pull model approach is not scalable as it will create unnecessary request overhead on our servers and most of the time the response will be empty, thus wasting our resources. To minimize latency, using the push model with [WebSockets](https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events#websockets) is a better choice because then we can push data to the client once it's available without any delay, given that the connection is open with the client. Also, WebSockets provide full-duplex communication, unlike [Server-Sent Events (SSE)](https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events#server-sent-events-sse) which are only unidirectional.

_Note: Learn more about [Long polling, WebSockets, Server-Sent Events (SSE)](https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events)._

### Last seen

To implement the last seen functionality, we can use a [heartbeat](<https://en.wikipedia.org/wiki/Heartbeat_(computing)>) mechanism, where the client can periodically ping the servers indicating its liveness. Since this needs to be as low overhead as possible, we can store the last active timestamp in the cache as follows:

| Key    | Value               |
| ------ | ------------------- |
| User A | 2022-07-01T14:32:50 |
| User B | 2022-07-05T05:10:35 |
| User C | 2022-07-10T04:33:25 |

This will give us the last time the user was active. This functionality will be handled by the presence service combined with [Redis](https://redis.io) or [Memcached](https://memcached.org) as our cache.

Another way to implement this is to track the latest action of the user, once the last activity crosses a certain threshold, such as _"user hasn't performed any action in the last 30 seconds"_, we can show the user as offline and last seen with the last recorded timestamp. This will be more of a lazy update approach and might benefit us over heartbeat mechanism in certain cases.

### Notifications

Once a message is sent in a chat or a group, we will first check if the recipient is active or not, we can get this information by taking the user's active connection and last seen into consideration.

If the recipient is not active, the chat service will add an event to a [message queue](https://karanpratapsingh.com/courses/system-design/message-queues) with additional metadata such as the client's device platform which will be used to route the notification to the correct platform later on.

The notification service will then consume the event from the message queue and forward the request to [Firebase Cloud Messaging (FCM)](https://firebase.google.com/docs/cloud-messaging) or [Apple Push Notification Service (APNS)](https://developer.apple.com/documentation/usernotifications) based on the client's device platform (Android, iOS, web, etc). We can also add support for email and SMS.

**Why are we using a message queue?**

Since most message queues provide best-effort ordering which ensures that messages are generally delivered in the same order as they're sent and that a message is delivered at least once which is an important part of our service functionality.

While this seems like a classic [publish-subscribe](https://karanpratapsingh.com/courses/system-design/publish-subscribe) use case, it is actually not as mobile devices and browsers each have their own way of handling push notifications. Usually, notifications are handled externally via Firebase Cloud Messaging (FCM) or Apple Push Notification Service (APNS) unlike message fan-out which we commonly see in backend services. We can use something like [Amazon SQS](https://aws.amazon.com/sqs) or [RabbitMQ](https://www.rabbitmq.com) to support this functionality.

### Read receipts

Handling read receipts can be tricky, for this use case we can wait for some sort of [Acknowledgment (ACK)](<https://en.wikipedia.org/wiki/Acknowledgement_(data_networks)>) from the client to determine if the message was delivered and update the corresponding `deliveredAt` field. Similarly, we will mark the message as seen once the user opens the chat and update the corresponding `seenAt` timestamp field.

### Design

Now that we have identified some core components, let's do the first draft of our system design.

![whatsapp-basic-design](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/whatsapp/whatsapp-basic-design.png)

## Detailed design

It's time to discuss our design decisions in detail.

### Data Partitioning

To scale out our databases we will need to partition our data. Horizontal partitioning (aka [Sharding](https://karanpratapsingh.com/courses/system-design/sharding)) can be a good first step. We can use partitions schemes such as:

- Hash-Based Partitioning
- List-Based Partitioning
- Range Based Partitioning
- Composite Partitioning

The above approaches can still cause uneven data and load distribution, we can solve this using [Consistent hashing](https://karanpratapsingh.com/courses/system-design/consistent-hashing).

_For more details, refer to [Sharding](https://karanpratapsingh.com/courses/system-design/sharding) and [Consistent Hashing](https://karanpratapsingh.com/courses/system-design/consistent-hashing)._

### Caching

In a messaging application, we have to be careful about using cache as our users expect the latest data, but many users will be requesting the same messages, especially in a group chat. So, to prevent usage spikes from our resources we can cache older messages.

Some group chats can have thousands of messages and sending that over the network will be really inefficient, to improve efficiency we can add pagination to our system APIs. This decision will be helpful for users with limited network bandwidth as they won't have to retrieve old messages unless requested.

**Which cache eviction policy to use?**

We can use solutions like [Redis](https://redis.io) or [Memcached](https://memcached.org) and cache 20% of the daily traffic but what kind of cache eviction policy would best fit our needs?

[Least Recently Used (LRU)](<https://en.wikipedia.org/wiki/Cache_replacement_policies#Least_recently_used_(LRU)>) can be a good policy for our system. In this policy, we discard the least recently used key first.

**How to handle cache miss?**

Whenever there is a cache miss, our servers can hit the database directly and update the cache with the new entries.

_For more details, refer to [Caching](https://karanpratapsingh.com/courses/system-design/caching)._

### Media access and storage

As we know, most of our storage space will be used for storing media files such as images, videos, or other files. Our media service will be handling both access and storage of the user media files.

But where can we store files at scale? Well, [object storage](https://karanpratapsingh.com/courses/system-design/storage#object-storage) is what we're looking for. Object stores break data files up into pieces called objects. It then stores those objects in a single repository, which can be spread out across multiple networked systems. We can also use distributed file storage such as [HDFS](https://karanpratapsingh.com/courses/system-design/storage#hdfs) or [GlusterFS](https://www.gluster.org).

_Fun fact: WhatsApp deletes media on its servers once it has been downloaded by the user._

We can use object stores like [Amazon S3](https://aws.amazon.com/s3), [Azure Blob Storage](https://azure.microsoft.com/en-in/services/storage/blobs), or [Google Cloud Storage](https://cloud.google.com/storage) for this use case.

### Content Delivery Network (CDN)

[Content Delivery Network (CDN)](https://karanpratapsingh.com/courses/system-design/content-delivery-network) increases content availability and redundancy while reducing bandwidth costs. Generally, static files such as images, and videos are served from CDN. We can use services like [Amazon CloudFront](https://aws.amazon.com/cloudfront) or [Cloudflare CDN](https://www.cloudflare.com/cdn) for this use case.

### API gateway

Since we will be using multiple protocols like HTTP, WebSocket, TCP/IP, deploying multiple L4 (transport layer) or L7 (application layer) type load balancers separately for each protocol will be expensive. Instead, we can use an [API Gateway](https://karanpratapsingh.com/courses/system-design/api-gateway) that supports multiple protocols without any issues.

API Gateway can also offer other features such as authentication, authorization, rate limiting, throttling, and API versioning which will improve the quality of our services.

We can use services like [Amazon API Gateway](https://aws.amazon.com/api-gateway) or [Azure API Gateway](https://azure.microsoft.com/en-in/services/api-management) for this use case.

## Identify and resolve bottlenecks

![whatsapp-advanced-design](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/whatsapp/whatsapp-advanced-design.png)

Let us identify and resolve bottlenecks such as single points of failure in our design:

- "What if one of our services crashes?"
- "How will we distribute our traffic between our components?"
- "How can we reduce the load on our database?"
- "How to improve the availability of our cache?"
- "Wouldn't API Gateway be a single point of failure?"
- "How can we make our notification system more robust?"
- "How can we reduce media storage costs"?
- "Does chat service has too much responsibility?"

To make our system more resilient we can do the following:

- Running multiple instances of each of our services.
- Introducing [load balancers](https://karanpratapsingh.com/courses/system-design/load-balancing) between clients, servers, databases, and cache servers.
- Using multiple read replicas for our databases.
- Multiple instances and replicas for our distributed cache.
- We can have a standby replica of our API Gateway.
- Exactly once delivery and message ordering is challenging in a distributed system, we can use a dedicated [message broker](https://karanpratapsingh.com/courses/system-design/message-brokers) such as [Apache Kafka](https://kafka.apache.org) or [NATS](https://nats.io) to make our notification system more robust.
- We can add media processing and compression capabilities to the media service to compress large files similar to WhatsApp which will save a lot of storage space and reduce cost.
- We can create a group service separate from the chat service to further decouple our services.

# Twitter

Let's design a [Twitter](https://twitter.com) like social media service, similar to services like [Facebook](https://facebook.com), [Instagram](https://instagram.com), etc.

## What is Twitter?

Twitter is a social media service where users can read or post short messages (up to 280 characters) called tweets. It is available on the web and mobile platforms such as Android and iOS.

## Requirements

Our system should meet the following requirements:

### Functional requirements

- Should be able to post new tweets (can be text, image, video, etc.).
- Should be able to follow other users.
- Should have a newsfeed feature consisting of tweets from the people the user is following.
- Should be able to search tweets.

### Non-Functional requirements

- High availability with minimal latency.
- The system should be scalable and efficient.

### Extended requirements

- Metrics and analytics.
- Retweet functionality.
- Favorite tweets.

## Estimation and Constraints

Let's start with the estimation and constraints.

_Note: Make sure to check any scale or traffic-related assumptions with your interviewer._

### Traffic

This will be a read-heavy system, let us assume we have 1 billion total users with 200 million daily active users (DAU), and on average each user tweets 5 times a day. This gives us 1 billion tweets per day.

$$
200 \space million \times 5 \space tweets = 1 \space billion/day
$$

Tweets can also contain media such as images, or videos. We can assume that 10 percent of tweets are media files shared by the users, which gives us additional 100 million files we would need to store.

$$
10 \space percent \times 1 \space billion = 100 \space million/day
$$

**What would be Requests Per Second (RPS) for our system?**

1 billion requests per day translate into 12K requests per second.

$$
\frac{1 \space billion}{(24 \space hrs \times 3600 \space seconds)} = \sim 12K \space requests/second
$$

### Storage

If we assume each message on average is 100 bytes, we will require about 100 GB of database storage every day.

$$
1 \space billion \times 100 \space bytes = \sim 100 \space GB/day
$$

We also know that around 10 percent of our daily messages (100 million) are media files per our requirements. If we assume each file is 50 KB on average, we will require 5 TB of storage every day.

$$
100 \space million \times 50 \space KB = 5 \space TB/day
$$

And for 10 years, we will require about 19 PB of storage.

$$
(5 \space TB + 0.1 \space TB) \times 365 \space days \times 10 \space years = \sim 19 \space PB
$$

### Bandwidth

As our system is handling 5.1 TB of ingress every day, we will require a minimum bandwidth of around 60 MB per second.

$$
\frac{5.1 \space TB}{(24 \space hrs \times 3600 \space seconds)} = \sim 60 \space MB/second
$$

### High-level estimate

Here is our high-level estimate:

| Type                      | Estimate    |
| ------------------------- | ----------- |
| Daily active users (DAU)  | 100 million |
| Requests per second (RPS) | 12K/s       |
| Storage (per day)         | ~5.1 TB     |
| Storage (10 years)        | ~19 PB      |
| Bandwidth                 | ~60 MB/s    |

## Data model design

This is the general data model which reflects our requirements.

![twitter-datamodel](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/twitter/twitter-datamodel.png)

We have the following tables:

**users**

This table will contain a user's information such as `name`, `email`, `dob`, and other details.

**tweets**

As the name suggests, this table will store tweets and their properties such as `type` (text, image, video, etc.), `content`, etc. We will also store the corresponding `userID`.

**favorites**

This table maps tweets with users for the favorite tweets functionality in our application.

**followers**

This table maps the followers and [followees](https://en.wiktionary.org/wiki/followee) as users can follow each other (N:M relationship).

**feeds**

This table stores feed properties with the corresponding `userID`.

**feeds_tweets**

This table maps tweets and feed (N:M relationship).

### What kind of database should we use?

While our data model seems quite relational, we don't necessarily need to store everything in a single database, as this can limit our scalability and quickly become a bottleneck.

We will split the data between different services each having ownership over a particular table. Then we can use a relational database such as [PostgreSQL](https://www.postgresql.org) or a distributed NoSQL database such as [Apache Cassandra](https://cassandra.apache.org/_/index.html) for our use case.

## API design

Let us do a basic API design for our services:

### Post a tweet

This API will allow the user to post a tweet on the platform.

```tsx
postTweet(userID: UUID, content: string, mediaURL?: string): boolean
```

**Parameters**

User ID (`UUID`): ID of the user.

Content (`string`): Contents of the tweet.

Media URL (`string`): URL of the attached media _(optional)_.

**Returns**

Result (`boolean`): Represents whether the operation was successful or not.

### Follow or unfollow a user

This API will allow the user to follow or unfollow another user.

```tsx
follow(followerID: UUID, followeeID: UUID): boolean
unfollow(followerID: UUID, followeeID: UUID): boolean
```

**Parameters**

Follower ID (`UUID`): ID of the current user.

Followee ID (`UUID`): ID of the user we want to follow or unfollow.

Media URL (`string`): URL of the attached media _(optional)_.

**Returns**

Result (`boolean`): Represents whether the operation was successful or not.

### Get newsfeed

This API will return all the tweets to be shown within a given newsfeed.

```tsx
getNewsfeed(userID: UUID): Tweet[]
```

**Parameters**

User ID (`UUID`): ID of the user.

**Returns**

Tweets (`Tweet[]`): All the tweets to be shown within a given newsfeed.

## High-level design

Now let us do a high-level design of our system.

### Architecture

We will be using [microservices architecture](https://karanpratapsingh.com/courses/system-design/monoliths-microservices#microservices) since it will make it easier to horizontally scale and decouple our services. Each service will have ownership of its own data model. Let's try to divide our system into some core services.

**User Service**

This service handles user-related concerns such as authentication and user information.

**Newsfeed Service**

This service will handle the generation and publishing of user newsfeeds. It will be discussed in detail separately.

**Tweet Service**

The tweet service will handle tweet-related use cases such as posting a tweet, favorites, etc.

**Search Service**

The service is responsible for handling search-related functionality. It will be discussed in detail separately.

**Media service**

This service will handle the media (images, videos, files, etc.) uploads. It will be discussed in detail separately.

**Notification Service**

This service will simply send push notifications to the users.

**Analytics Service**

This service will be used for metrics and analytics use cases.

**What about inter-service communication and service discovery?**

Since our architecture is microservices-based, services will be communicating with each other as well. Generally, REST or HTTP performs well but we can further improve the performance using [gRPC](https://karanpratapsingh.com/courses/system-design/rest-graphql-grpc#grpc) which is more lightweight and efficient.

[Service discovery](https://karanpratapsingh.com/courses/system-design/service-discovery) is another thing we will have to take into account. We can also use a service mesh that enables managed, observable, and secure communication between individual services.

_Note: Learn more about [REST, GraphQL, gRPC](https://karanpratapsingh.com/courses/system-design/rest-graphql-grpc) and how they compare with each other._

### Newsfeed

When it comes to the newsfeed, it seems easy enough to implement, but there are a lot of things that can make or break this feature. So, let's divide our problem into two parts:

**Generation**

Let's assume we want to generate the feed for user A, we will perform the following steps:

1. Retrieve the IDs of all the users and entities (hashtags, topics, etc.) user A follows.
2. Fetch the relevant tweets for each of the retrieved IDs.
3. Use a ranking algorithm to rank the tweets based on parameters such as relevance, time, engagement, etc.
4. Return the ranked tweets data to the client in a paginated manner.

Feed generation is an intensive process and can take quite a lot of time, especially for users following a lot of people. To improve the performance, the feed can be pre-generated and stored in the cache, then we can have a mechanism to periodically update the feed and apply our ranking algorithm to the new tweets.

**Publishing**

Publishing is the step where the feed data is pushed according to each specific user. This can be a quite heavy operation, as a user may have millions of friends or followers. To deal with this, we have three different approaches:

- Pull Model (or Fan-out on load)

![newsfeed-pull-model](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/twitter/newsfeed-pull-model.png)

When a user creates a tweet, and a follower reloads their newsfeed, the feed is created and stored in memory. The most recent feed is only loaded when the user requests it. This approach reduces the number of write operations on our database.

The downside of this approach is that the users will not be able to view recent feeds unless they "pull" the data from the server, which will increase the number of read operations on the server.

- Push Model (or Fan-out on write)

![newsfeed-push-model](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/twitter/newsfeed-push-model.png)

In this model, once a user creates a tweet, it is "pushed" to all the follower's feeds immediately. This prevents the system from having to go through a user's entire followers list to check for updates.

However, the downside of this approach is that it would increase the number of write operations on the database.

- Hybrid Model

A third approach is a hybrid model between the pull and push model. It combines the beneficial features of the above two models and tries to provide a balanced approach between the two.

The hybrid model allows only users with a lesser number of followers to use the push model. For users with a higher number of followers such as celebrities, the pull model is used.

### Ranking Algorithm

As we discussed, we will need a ranking algorithm to rank each tweet according to its relevance to each specific user.

For example, Facebook used to utilize an [EdgeRank](https://en.wikipedia.org/wiki/EdgeRank) algorithm. Here, the rank of each feed item is described by:

$$
Rank = Affinity \times Weight \times Decay
$$

Where,

`Affinity`: is the "closeness" of the user to the creator of the edge. If a user frequently likes, comments, or messages the edge creator, then the value of affinity will be higher, resulting in a higher rank for the post.

`Weight`: is the value assigned according to each edge. A comment can have a higher weightage than likes, and thus a post with more comments is more likely to get a higher rank.

`Decay`: is the measure of the creation of the edge. The older the edge, the lesser will be the value of decay and eventually the rank.

Nowadays, algorithms are much more complex and ranking is done using machine learning models which can take thousands of factors into consideration.

### Retweets

Retweets are one of our extended requirements. To implement this feature, we can simply create a new tweet with the user id of the user retweeting the original tweet and then modify the `type` enum and `content` property of the new tweet to link it with the original tweet.

For example, the `type` enum property can be of type tweet, similar to text, video, etc and `content` can be the id of the original tweet. Here the first row indicates the original tweet while the second row is how we can represent a retweet.

| id                  | userID              | type  | content                      | createdAt     |
| ------------------- | ------------------- | ----- | ---------------------------- | ------------- |
| ad34-291a-45f6-b36c | 7a2c-62c4-4dc8-b1bb | text  | Hey, this is my first tweet… | 1658905644054 |
| f064-49ad-9aa2-84a6 | 6aa2-2bc9-4331-879f | tweet | ad34-291a-45f6-b36c          | 1658906165427 |

This is a very basic implementation. To improve this we can create a separate table itself to store retweets.

### Search

Sometimes traditional DBMS are not performant enough, we need something which allows us to store, search, and analyze huge volumes of data quickly and in near real-time and give results within milliseconds. [Elasticsearch](https://www.elastic.co) can help us with this use case.

[Elasticsearch](https://www.elastic.co) is a distributed, free and open search and analytics engine for all types of data, including textual, numerical, geospatial, structured, and unstructured. It is built on top of [Apache Lucene](https://lucene.apache.org).

**How do we identify trending topics?**

Trending functionality will be based on top of the search functionality. We can cache the most frequently searched queries, hashtags, and topics in the last `N` seconds and update them every `M` seconds using some sort of batch job mechanism. Our ranking algorithm can also be applied to the trending topics to give them more weight and personalize them for the user.

### Notifications

Push notifications are an integral part of any social media platform. We can use a message queue or a message broker such as [Apache Kafka](https://kafka.apache.org) with the notification service to dispatch requests to [Firebase Cloud Messaging (FCM)](https://firebase.google.com/docs/cloud-messaging) or [Apple Push Notification Service (APNS)](https://developer.apple.com/documentation/usernotifications) which will handle the delivery of the push notifications to user devices.

_For more details, refer to the [WhatsApp](https://karanpratapsingh.com/courses/system-design/whatsapp#notifications) system design where we discuss push notifications in detail._

## Detailed design

It's time to discuss our design decisions in detail.

### Data Partitioning

To scale out our databases we will need to partition our data. Horizontal partitioning (aka [Sharding](https://karanpratapsingh.com/courses/system-design/sharding)) can be a good first step. We can use partitions schemes such as:

- Hash-Based Partitioning
- List-Based Partitioning
- Range Based Partitioning
- Composite Partitioning

The above approaches can still cause uneven data and load distribution, we can solve this using [Consistent hashing](https://karanpratapsingh.com/courses/system-design/consistent-hashing).

_For more details, refer to [Sharding](https://karanpratapsingh.com/courses/system-design/sharding) and [Consistent Hashing](https://karanpratapsingh.com/courses/system-design/consistent-hashing)._

### Mutual friends

For mutual friends, we can build a social graph for every user. Each node in the graph will represent a user and a directional edge will represent followers and followees. After that, we can traverse the followers of a user to find and suggest a mutual friend. This would require a graph database such as [Neo4j](https://neo4j.com) or [ArangoDB](https://www.arangodb.com).

This is a pretty simple algorithm, to improve our suggestion accuracy, we will need to incorporate a recommendation model which uses machine learning as part of our algorithm.

### Metrics and Analytics

Recording analytics and metrics is one of our extended requirements. As we will be using [Apache Kafka](https://kafka.apache.org) to publish all sorts of events, we can process these events and run analytics on the data using [Apache Spark](https://spark.apache.org) which is an open-source unified analytics engine for large-scale data processing.

### Caching

In a social media application, we have to be careful about using cache as our users expect the latest data. So, to prevent usage spikes from our resources we can cache the top 20% of the tweets.

To further improve efficiency we can add pagination to our system APIs. This decision will be helpful for users with limited network bandwidth as they won't have to retrieve old messages unless requested.

**Which cache eviction policy to use?**

We can use solutions like [Redis](https://redis.io) or [Memcached](https://memcached.org) and cache 20% of the daily traffic but what kind of cache eviction policy would best fit our needs?

[Least Recently Used (LRU)](<https://en.wikipedia.org/wiki/Cache_replacement_policies#Least_recently_used_(LRU)>) can be a good policy for our system. In this policy, we discard the least recently used key first.

**How to handle cache miss?**

Whenever there is a cache miss, our servers can hit the database directly and update the cache with the new entries.

_For more details, refer to [Caching](https://karanpratapsingh.com/courses/system-design/caching)._

### Media access and storage

As we know, most of our storage space will be used for storing media files such as images, videos, or other files. Our media service will be handling both access and storage of the user media files.

But where can we store files at scale? Well, [object storage](https://karanpratapsingh.com/courses/system-design/storage#object-storage) is what we're looking for. Object stores break data files up into pieces called objects. It then stores those objects in a single repository, which can be spread out across multiple networked systems. We can also use distributed file storage such as [HDFS](https://karanpratapsingh.com/courses/system-design/storage#hdfs) or [GlusterFS](https://www.gluster.org).

### Content Delivery Network (CDN)

[Content Delivery Network (CDN)](https://karanpratapsingh.com/courses/system-design/content-delivery-network) increases content availability and redundancy while reducing bandwidth costs. Generally, static files such as images, and videos are served from CDN. We can use services like [Amazon CloudFront](https://aws.amazon.com/cloudfront) or [Cloudflare CDN](https://www.cloudflare.com/cdn) for this use case.

## Identify and resolve bottlenecks

![twitter-advanced-design](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/twitter/twitter-advanced-design.png)

Let us identify and resolve bottlenecks such as single points of failure in our design:

- "What if one of our services crashes?"
- "How will we distribute our traffic between our components?"
- "How can we reduce the load on our database?"
- "How to improve the availability of our cache?"
- "How can we make our notification system more robust?"
- "How can we reduce media storage costs"?

To make our system more resilient we can do the following:

- Running multiple instances of each of our services.
- Introducing [load balancers](https://karanpratapsingh.com/courses/system-design/load-balancing) between clients, servers, databases, and cache servers.
- Using multiple read replicas for our databases.
- Multiple instances and replicas for our distributed cache.
- Exactly once delivery and message ordering is challenging in a distributed system, we can use a dedicated [message broker](https://karanpratapsingh.com/courses/system-design/message-brokers) such as [Apache Kafka](https://kafka.apache.org) or [NATS](https://nats.io) to make our notification system more robust.
- We can add media processing and compression capabilities to the media service to compress large files which will save a lot of storage space and reduce cost.

# Netflix

Let's design a [Netflix](https://netflix.com) like video streaming service, similar to services like [Amazon Prime Video](https://www.primevideo.com), [Disney Plus](https://www.disneyplus.com), [Hulu](https://www.hulu.com), [Youtube](https://youtube.com), [Vimeo](https://vimeo.com), etc.

## What is Netflix?

Netflix is a subscription-based streaming service that allows its members to watch TV shows and movies on an internet-connected device. It is available on platforms such as the Web, iOS, Android, TV, etc.

## Requirements

Our system should meet the following requirements:

### Functional requirements

- Users should be able to stream and share videos.
- The content team (or users in YouTube's case) should be able to upload new videos (movies, tv shows episodes, and other content).
- Users should be able to search for videos using titles or tags.
- Users should be able to comment on a video similar to YouTube.

### Non-Functional requirements

- High availability with minimal latency.
- High reliability, no uploads should be lost.
- The system should be scalable and efficient.

### Extended requirements

- Certain content should be [geo-blocked](https://en.wikipedia.org/wiki/Geo-blocking).
- Resume video playback from the point user left off.
- Record metrics and analytics of videos.

## Estimation and Constraints

Let's start with the estimation and constraints.

_Note: Make sure to check any scale or traffic-related assumptions with your interviewer._

### Traffic

This will be a read-heavy system, let us assume we have 1 billion total users with 200 million daily active users (DAU), and on average each user watches 5 videos a day. This gives us 1 billion videos watched per day.

$$
200 \space million \times 5 \space videos = 1 \space billion/day
$$

Assuming a `200:1` read/write ratio, about 5 million videos will be uploaded every day.

$$
\frac{1}{200} \times 1 \space billion = 5 \space million/day
$$

**What would be Requests Per Second (RPS) for our system?**

1 billion requests per day translate into 12K requests per second.

$$
\frac{1 \space billion}{(24 \space hrs \times 3600 \space seconds)} = \sim 12K \space requests/second
$$

### Storage

If we assume each video is 100 MB on average, we will require about 500 TB of storage every day.

$$
5 \space million \times 100 \space MB = 500 \space TB/day
$$

And for 10 years, we will require an astounding 1,825 PB of storage.

$$
500 \space TB \times 365 \space days \times 10 \space years = \sim 1,825 \space PB
$$

### Bandwidth

As our system is handling 500 TB of ingress every day, we will require a minimum bandwidth of around 5.8 GB per second.

$$
\frac{500 \space TB}{(24 \space hrs \times 3600 \space seconds)} = \sim 5.8 \space GB/second
$$

### High-level estimate

Here is our high-level estimate:

| Type                      | Estimate    |
| ------------------------- | ----------- |
| Daily active users (DAU)  | 200 million |
| Requests per second (RPS) | 12K/s       |
| Storage (per day)         | ~500 TB     |
| Storage (10 years)        | ~1,825 PB   |
| Bandwidth                 | ~5.8 GB/s   |

## Data model design

This is the general data model which reflects our requirements.

![netflix-datamodel](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/netflix/netflix-datamodel.png)

We have the following tables:

**users**

This table will contain a user's information such as `name`, `email`, `dob`, and other details.

**videos**

As the name suggests, this table will store videos and their properties such as `title`, `streamURL`, `tags`, etc. We will also store the corresponding `userID`.

**tags**

This table will simply store tags associated with a video.

**views**

This table helps us to store all the views received on a video.

**comments**

This table stores all the comments received on a video (like YouTube).

### What kind of database should we use?

While our data model seems quite relational, we don't necessarily need to store everything in a single database, as this can limit our scalability and quickly become a bottleneck.

We will split the data between different services each having ownership over a particular table. Then we can use a relational database such as [PostgreSQL](https://www.postgresql.org) or a distributed NoSQL database such as [Apache Cassandra](https://cassandra.apache.org/_/index.html) for our use case.

## API design

Let us do a basic API design for our services:

### Upload a video

Given a byte stream, this API enables video to be uploaded to our service.

```tsx
uploadVideo(title: string, description: string, data: Stream<byte>, tags?: string[]): boolean
```

**Parameters**

Title (`string`): Title of the new video.

Description (`string`): Description of the new video.

Data (`byte[]`): Byte stream of the video data.

Tags (`string[]`): Tags for the video _(optional)_.

**Returns**

Result (`boolean`): Represents whether the operation was successful or not.

### Streaming a video

This API allows our users to stream a video with the preferred codec and resolution.

```tsx
streamVideo(videoID: UUID, codec: Enum<string>, resolution: Tuple<int>, offset?: int): VideoStream
```

**Parameters**

Video ID (`UUID`): ID of the video that needs to be streamed.

Codec (`Enum<string>`): Required [codec](https://en.wikipedia.org/wiki/Video_codec) of the requested video, such as `h.265`, `h.264`, `VP9`, etc.

Resolution (`Tuple<int>`): [Resolution](https://en.wikipedia.org/wiki/Display_resolution) of the requested video.

Offset (`int`): Offset of the video stream in seconds to stream data from any point in the video _(optional)_.

**Returns**

Stream (`VideoStream`): Data stream of the requested video.

### Search for a video

This API will enable our users to search for a video based on its title or tags.

```tsx
searchVideo(query: string, nextPage?: string): Video[]
```

**Parameters**

Query (`string`): Search query from the user.

Next Page (`string`): Token for the next page, this can be used for pagination _(optional)_.

**Returns**

Videos (`Video[]`): All the videos available for a particular search query.

### Add a comment

This API will allow our users to post a comment on a video (like YouTube).

```tsx
comment(videoID: UUID, comment: string): boolean
```

**Parameters**

VideoID (`UUID`): ID of the video user wants to comment on.

Comment (`string`): The text content of the comment.

**Returns**

Result (`boolean`): Represents whether the operation was successful or not.

## High-level design

Now let us do a high-level design of our system.

### Architecture

We will be using [microservices architecture](https://karanpratapsingh.com/courses/system-design/monoliths-microservices#microservices) since it will make it easier to horizontally scale and decouple our services. Each service will have ownership of its own data model. Let's try to divide our system into some core services.

**User Service**

This service handles user-related concerns such as authentication and user information.

**Stream Service**

The stream service will handle video streaming-related functionality.

**Search Service**

The service is responsible for handling search-related functionality. It will be discussed in detail separately.

**Media service**

This service will handle the video uploads and processing. It will be discussed in detail separately.

**Analytics Service**

This service will be used for metrics and analytics use cases.

**What about inter-service communication and service discovery?**

Since our architecture is microservices-based, services will be communicating with each other as well. Generally, REST or HTTP performs well but we can further improve the performance using [gRPC](https://karanpratapsingh.com/courses/system-design/rest-graphql-grpc#grpc) which is more lightweight and efficient.

[Service discovery](https://karanpratapsingh.com/courses/system-design/service-discovery) is another thing we will have to take into account. We can also use a service mesh that enables managed, observable, and secure communication between individual services.

_Note: Learn more about [REST, GraphQL, gRPC](https://karanpratapsingh.com/courses/system-design/rest-graphql-grpc) and how they compare with each other._

### Video processing

![video-processing-pipeline](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/netflix/video-processing-pipeline.png)

There are so many variables in play when it comes to processing a video. For example, an average data size of two-hour raw 8K footage from a high-end camera can easily be up to 4 TB, thus we need to have some kind of processing to reduce both storage and delivery costs.

Here's how we can process videos once they're uploaded by the content team (or users in YouTube's case) and are queued for processing in our [message queue](https://karanpratapsingh.com/courses/system-design/message-queues).

Let's discuss how this works:

- **File Chunker**

![file-chunking](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/netflix/file-chunking.png)

This is the first step of our processing pipeline. File chunking is the process of splitting a file into smaller pieces called chunks. It can help us eliminate duplicate copies of repeating data on storage, and reduces the amount of data sent over the network by only selecting changed chunks.

Usually, a video file can be split into equal size chunks based on timestamps but Netflix instead splits chunks based on scenes. This slight variation becomes a huge factor for a better user experience since whenever the client requests a chunk from the server, there is a lower chance of interruption as a complete scene will be retrieved.

- **Content Filter**

This step checks if the video adheres to the content policy of the platform. This can be pre-approved as in the case of Netflix according to [content rating](https://en.wikipedia.org/wiki/Motion_picture_content_rating_system) of the media or can be strictly enforced like by YouTube.

This entire process is done by a machine learning model which performs copyright, piracy, and NSFW checks. If issues are found, we can push the task to a [dead-letter queue (DLQ)](https://karanpratapsingh.com/courses/system-design/message-queues#dead-letter-queues) and someone from the moderation team can do further inspection.

- **Transcoder**

[Transcoding](https://en.wikipedia.org/wiki/Transcoding) is a process in which the original data is decoded to an intermediate uncompressed format, which is then encoded into the target format. This process uses different [codecs](https://en.wikipedia.org/wiki/Video_codec) to perform bitrate adjustment, image downsampling, or re-encoding the media.

This results in a smaller size file and a much more optimized format for the target devices. Standalone solutions such as [FFmpeg](https://ffmpeg.org) or cloud-based solutions like [AWS Elemental MediaConvert](https://aws.amazon.com/mediaconvert) can be used to implement this step of the pipeline.

- **Quality Conversion**

This is the last step of the processing pipeline and as the name suggests, this step handles the conversion of the transcoded media from the previous step into different resolutions such as 4K, 1440p, 1080p, 720p, etc.

It allows us to fetch the desired quality of the video as per the user's request, and once the media file finishes processing, it gets uploaded to a distributed file storage such as [HDFS](https://karanpratapsingh.com/courses/system-design/storage#hdfs), [GlusterFS](https://www.gluster.org), or an [object storage](https://karanpratapsingh.com/courses/system-design/storage#object-storage) such as [Amazon S3](https://aws.amazon.com/s3) for later retrieval during streaming.

_Note: We can add additional steps such as subtitles and thumbnails generation as part of our pipeline._

**Why are we using a message queue?**

Processing videos as a long-running task and using a [message queue](https://karanpratapsingh.com/courses/system-design/message-queues) makes much more sense. It also decouples our video processing pipeline from the upload functionality. We can use something like [Amazon SQS](https://aws.amazon.com/sqs) or [RabbitMQ](https://www.rabbitmq.com) to support this.

### Video streaming

Video streaming is a challenging task from both the client and server perspectives. Moreover, internet connection speeds vary quite a lot between different users. To make sure users don't re-fetch the same content, we can use a [Content Delivery Network (CDN)](https://karanpratapsingh.com/courses/system-design/content-delivery-network).

Netflix takes this a step further with its [Open Connect](https://openconnect.netflix.com) program. In this approach, they partner with thousands of Internet Service Providers (ISPs) to localize their traffic and deliver their content more efficiently.

**What is the difference between Netflix's Open Connect and a traditional Content Delivery Network (CDN)?**

Netflix Open Connect is a purpose-built [Content Delivery Network (CDN)](https://karanpratapsingh.com/courses/system-design/content-delivery-network) responsible for serving Netflix's video traffic. Around 95% of the traffic globally is delivered via direct connections between Open Connect and the ISPs their customers use to access the internet.

Currently, they have Open Connect Appliances (OCAs) in over 1000 separate locations around the world. In case of issues, Open Connect Appliances (OCAs) can failover, and the traffic can be re-routed to Netflix servers.

Additionally, we can use [Adaptive bitrate streaming](https://en.wikipedia.org/wiki/Adaptive_bitrate_streaming) protocols such as [HTTP Live Streaming (HLS)](https://en.wikipedia.org/wiki/HTTP_Live_Streaming) which is designed for reliability and it dynamically adapts to network conditions by optimizing playback for the available speed of the connections.

Lastly, for playing the video from where the user left off (part of our extended requirements), we can simply use the `offset` property we stored in the `views` table to retrieve the scene chunk at that particular timestamp and resume the playback for the user.

### Searching

Sometimes traditional DBMS are not performant enough, we need something which allows us to store, search, and analyze huge volumes of data quickly and in near real-time and give results within milliseconds. [Elasticsearch](https://www.elastic.co) can help us with this use case.

[Elasticsearch](https://www.elastic.co) is a distributed, free and open search and analytics engine for all types of data, including textual, numerical, geospatial, structured, and unstructured. It is built on top of [Apache Lucene](https://lucene.apache.org).

**How do we identify trending content?**

Trending functionality will be based on top of the search functionality. We can cache the most frequently searched queries in the last `N` seconds and update them every `M` seconds using some sort of batch job mechanism.

### Sharing

Sharing content is an important part of any platform, for this, we can have some sort of URL shortener service in place that can generate short URLs for the users to share.

_For more details, refer to the [URL Shortener](https://karanpratapsingh.com/courses/system-design/url-shortener) system design._

## Detailed design

It's time to discuss our design decisions in detail.

### Data Partitioning

To scale out our databases we will need to partition our data. Horizontal partitioning (aka [Sharding](https://karanpratapsingh.com/courses/system-design/sharding)) can be a good first step. We can use partitions schemes such as:

- Hash-Based Partitioning
- List-Based Partitioning
- Range Based Partitioning
- Composite Partitioning

The above approaches can still cause uneven data and load distribution, we can solve this using [Consistent hashing](https://karanpratapsingh.com/courses/system-design/consistent-hashing).

_For more details, refer to [Sharding](https://karanpratapsingh.com/courses/system-design/sharding) and [Consistent Hashing](https://karanpratapsingh.com/courses/system-design/consistent-hashing)._

### Geo-blocking

Platforms like Netflix and YouTube use [Geo-blocking](https://en.wikipedia.org/wiki/Geo-blocking) to restrict content in certain geographical areas or countries. This is primarily done due to legal distribution laws that Netflix has to adhere to when they make a deal with the production and distribution companies. In the case of YouTube, this will be controlled by the user during the publishing of the content.

We can determine the user's location either using their [IP](https://karanpratapsingh.com/courses/system-design/ip) or region settings in their profile then use services like [Amazon CloudFront](https://aws.amazon.com/cloudfront) which supports a geographic restrictions feature or a [geolocation routing policy](https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy-geo.html) with [Amazon Route53](https://aws.amazon.com/route53) to restrict the content and re-route the user to an error page if the content is not available in that particular region or country.

### Recommendations

Netflix uses a machine learning model which uses the user's viewing history to predict what the user might like to watch next, an algorithm like [Collaborative Filtering](https://en.wikipedia.org/wiki/Collaborative_filtering) can be used.

However, Netflix (like YouTube) uses its own algorithm called Netflix Recommendation Engine which can track several data points such as:

- User profile information like age, gender, and location.
- Browsing and scrolling behavior of the user.
- Time and date a user watched a title.
- The device which was used to stream the content.
- The number of searches and what terms were searched.

_For more detail, refer to [Netflix recommendation research](https://research.netflix.com/research-area/recommendations)._

### Metrics and Analytics

Recording analytics and metrics is one of our extended requirements. We can capture the data from different services and run analytics on the data using [Apache Spark](https://spark.apache.org) which is an open-source unified analytics engine for large-scale data processing. Additionally, we can store critical metadata in the views table to increase data points within our data.

### Caching

In a streaming platform, caching is important. We have to be able to cache as much static media content as possible to improve user experience. We can use solutions like [Redis](https://redis.io) or [Memcached](https://memcached.org) but what kind of cache eviction policy would best fit our needs?

**Which cache eviction policy to use?**

[Least Recently Used (LRU)](<https://en.wikipedia.org/wiki/Cache_replacement_policies#Least_recently_used_(LRU)>) can be a good policy for our system. In this policy, we discard the least recently used key first.

**How to handle cache miss?**

Whenever there is a cache miss, our servers can hit the database directly and update the cache with the new entries.

_For more details, refer to [Caching](https://karanpratapsingh.com/courses/system-design/caching)._

### Media streaming and storage

As most of our storage space will be used for storing media files such as thumbnails and videos. Per our discussion earlier, the media service will be handling both the upload and processing of media files.

We will use distributed file storage such as [HDFS](https://karanpratapsingh.com/courses/system-design/storage#hdfs), [GlusterFS](https://www.gluster.org), or an [object storage](https://karanpratapsingh.com/courses/system-design/storage#object-storage) such as [Amazon S3](https://aws.amazon.com/s3) for storage and streaming of the content.

### Content Delivery Network (CDN)

[Content Delivery Network (CDN)](https://karanpratapsingh.com/courses/system-design/content-delivery-network) increases content availability and redundancy while reducing bandwidth costs. Generally, static files such as images, and videos are served from CDN. We can use services like [Amazon CloudFront](https://aws.amazon.com/cloudfront) or [Cloudflare CDN](https://www.cloudflare.com/cdn) for this use case.

## Identify and resolve bottlenecks

![netflix-advanced-design](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/netflix/netflix-advanced-design.png)

Let us identify and resolve bottlenecks such as single points of failure in our design:

- "What if one of our services crashes?"
- "How will we distribute our traffic between our components?"
- "How can we reduce the load on our database?"
- "How to improve the availability of our cache?"

To make our system more resilient we can do the following:

- Running multiple instances of each of our services.
- Introducing [load balancers](https://karanpratapsingh.com/courses/system-design/load-balancing) between clients, servers, databases, and cache servers.
- Using multiple read replicas for our databases.
- Multiple instances and replicas for our distributed cache.

# Uber

Let's design an [Uber](https://uber.com) like ride-hailing service, similar to services like [Lyft](https://www.lyft.com), [OLA Cabs](https://www.olacabs.com), etc.

## What is Uber?

Uber is a mobility service provider, allowing users to book rides and a driver to transport them in a way similar to a taxi. It is available on the web and mobile platforms such as Android and iOS.

## Requirements

Our system should meet the following requirements:

### Functional requirements

We will design our system for two types of users: Customers and Drivers.

**Customers**

- Customers should be able to see all the cabs in the vicinity with an ETA and pricing information.
- Customers should be able to book a cab to a destination.
- Customers should be able to see the location of the driver.

**Drivers**

- Drivers should be able to accept or deny the customer-requested ride.
- Once a driver accepts the ride, they should see the pickup location of the customer.
- Drivers should be able to mark the trip as complete on reaching the destination.

### Non-Functional requirements

- High reliability.
- High availability with minimal latency.
- The system should be scalable and efficient.

### Extended requirements

- Customers can rate the trip after it's completed.
- Payment processing.
- Metrics and analytics.

## Estimation and Constraints

Let's start with the estimation and constraints.

_Note: Make sure to check any scale or traffic-related assumptions with your interviewer._

### Traffic

Let us assume we have 100 million daily active users (DAU) with 1 million drivers and on average our platform enables 10 million rides daily.

If on average each user performs 10 actions (such as request a check available rides, fares, book rides, etc.) we will have to handle 1 billion requests daily.

$$
100 \space million \times 10 \space actions = 1 \space billion/day
$$

**What would be Requests Per Second (RPS) for our system?**

1 billion requests per day translate into 12K requests per second.

$$
\frac{1 \space billion}{(24 \space hrs \times 3600 \space seconds)} = \sim 12K \space requests/second
$$

### Storage

If we assume each message on average is 400 bytes, we will require about 400 GB of database storage every day.

$$
1 \space billion \times 400 \space bytes = \sim 400 \space GB/day
$$

And for 10 years, we will require about 1.4 PB of storage.

$$
400 \space GB \times 10 \space years \times 365 \space days = \sim 1.4 \space PB
$$

### Bandwidth

As our system is handling 400 GB of ingress every day, we will require a minimum bandwidth of around 5 MB per second.

$$
\frac{400 \space GB}{(24 \space hrs \times 3600 \space seconds)} = \sim 5 \space MB/second
$$

### High-level estimate

Here is our high-level estimate:

| Type                      | Estimate    |
| ------------------------- | ----------- |
| Daily active users (DAU)  | 100 million |
| Requests per second (RPS) | 12K/s       |
| Storage (per day)         | ~400 GB     |
| Storage (10 years)        | ~1.4 PB     |
| Bandwidth                 | ~5 MB/s     |

## Data model design

This is the general data model which reflects our requirements.

![uber-datamodel](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/uber/uber-datamodel.png)

We have the following tables:

**customers**

This table will contain a customer's information such as `name`, `email`, and other details.

**drivers**

This table will contain a driver's information such as `name`, `email`, `dob` and other details.

**trips**

This table represents the trip taken by the customer and stores data such as `source`, `destination`, and `status` of the trip.

**cabs**

This table stores data such as the registration number, and type (like Uber Go, Uber XL, etc.) of the cab that the driver will be driving.

**ratings**

As the name suggests, this table stores the `rating` and `feedback` for the trip.

**payments**

The payments table contains the payment-related data with the corresponding `tripID`.

### What kind of database should we use?

While our data model seems quite relational, we don't necessarily need to store everything in a single database, as this can limit our scalability and quickly become a bottleneck.

We will split the data between different services each having ownership over a particular table. Then we can use a relational database such as [PostgreSQL](https://www.postgresql.org) or a distributed NoSQL database such as [Apache Cassandra](https://cassandra.apache.org/_/index.html) for our use case.

## API design

Let us do a basic API design for our services:

### Request a Ride

Through this API, customers will be able to request a ride.

```tsx
requestRide(customerID: UUID, source: Tuple<float>, destination: Tuple<float>, cabType: Enum<string>, paymentMethod: Enum<string>): Ride
```

**Parameters**

Customer ID (`UUID`): ID of the customer.

Source (`Tuple<float>`): Tuple containing the latitude and longitude of the trip's starting location.

Destination (`Tuple<float>`): Tuple containing the latitude and longitude of the trip's destination.

**Returns**

Result (`Ride`): Associated ride information of the trip.

### Cancel the Ride

This API will allow customers to cancel the ride.

```tsx
cancelRide(customerID: UUID, reason?: string): boolean
```

**Parameters**

Customer ID (`UUID`): ID of the customer.

Reason (`UUID`): Reason for canceling the ride _(optional)_.

**Returns**

Result (`boolean`): Represents whether the operation was successful or not.

### Accept or Deny the Ride

This API will allow the driver to accept or deny the trip.

```tsx
acceptRide(driverID: UUID, rideID: UUID): boolean
denyRide(driverID: UUID, rideID: UUID): boolean
```

**Parameters**

Driver ID (`UUID`): ID of the driver.

Ride ID (`UUID`): ID of the customer requested ride.

**Returns**

Result (`boolean`): Represents whether the operation was successful or not.

### Start or End the Trip

Using this API, a driver will be able to start and end the trip.

```tsx
startTrip(driverID: UUID, tripID: UUID): boolean
endTrip(driverID: UUID, tripID: UUID): boolean
```

**Parameters**

Driver ID (`UUID`): ID of the driver.

Trip ID (`UUID`): ID of the requested trip.

**Returns**

Result (`boolean`): Represents whether the operation was successful or not.

### Rate the Trip

This API will enable customers to rate the trip.

```tsx
rateTrip(customerID: UUID, tripID: UUID, rating: int, feedback?: string): boolean
```

**Parameters**

Customer ID (`UUID`): ID of the customer.

Trip ID (`UUID`): ID of the completed trip.

Rating (`int`): Rating of the trip.

Feedback (`string`): Feedback about the trip by the customer _(optional)_.

**Returns**

Result (`boolean`): Represents whether the operation was successful or not.

## High-level design

Now let us do a high-level design of our system.

### Architecture

We will be using [microservices architecture](https://karanpratapsingh.com/courses/system-design/monoliths-microservices#microservices) since it will make it easier to horizontally scale and decouple our services. Each service will have ownership of its own data model. Let's try to divide our system into some core services.

**Customer Service**

This service handles customer-related concerns such as authentication and customer information.

**Driver Service**

This service handles driver-related concerns such as authentication and driver information.

**Ride Service**

This service will be responsible for ride matching and quadtree aggregation. It will be discussed in detail separately.

**Trip Service**

This service handles trip-related functionality in our system.

**Payment Service**

This service will be responsible for handling payments in our system.

**Notification Service**

This service will simply send push notifications to the users. It will be discussed in detail separately.

**Analytics Service**

This service will be used for metrics and analytics use cases.

**What about inter-service communication and service discovery?**

Since our architecture is microservices-based, services will be communicating with each other as well. Generally, REST or HTTP performs well but we can further improve the performance using [gRPC](https://karanpratapsingh.com/courses/system-design/rest-graphql-grpc#grpc) which is more lightweight and efficient.

[Service discovery](https://karanpratapsingh.com/courses/system-design/service-discovery) is another thing we will have to take into account. We can also use a service mesh that enables managed, observable, and secure communication between individual services.

_Note: Learn more about [REST, GraphQL, gRPC](https://karanpratapsingh.com/courses/system-design/rest-graphql-grpc) and how they compare with each other._

### How is the service expected to work?

Here's how our service is expected to work:

![uber-working](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/uber/uber-working.png)

1. Customer requests a ride by specifying the source, destination, cab type, payment method, etc.
2. Ride service registers this request, finds nearby drivers, and calculates the estimated time of arrival (ETA).
3. The request is then broadcasted to the nearby drivers for them to accept or deny.
4. If the driver accepts, the customer is notified about the live location of the driver with the estimated time of arrival (ETA) while they wait for pickup.
5. The customer is picked up and the driver can start the trip.
6. Once the destination is reached, the driver will mark the ride as complete and collect payment.
7. After the payment is complete, the customer can leave a rating and feedback for the trip if they like.

### Location Tracking

How do we efficiently send and receive live location data from the client (customers and drivers) to our backend? We have two different options:

**Pull model**

The client can periodically send an HTTP request to servers to report its current location and receive ETA and pricing information. This can be achieved via something like [Long polling](https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events#long-polling).

**Push model**

The client opens a long-lived connection with the server and once new data is available it will be pushed to the client. We can use [WebSockets](https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events#websockets) or [Server-Sent Events (SSE)](https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events#server-sent-events-sse) for this.

The pull model approach is not scalable as it will create unnecessary request overhead on our servers and most of the time the response will be empty, thus wasting our resources. To minimize latency, using the push model with [WebSockets](https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events#websockets) is a better choice because then we can push data to the client once it's available without any delay, given that the connection is open with the client. Also, WebSockets provide full-duplex communication, unlike [Server-Sent Events (SSE)](https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events#server-sent-events-sse) which are only unidirectional.

Additionally, the client application should have some sort of background job mechanism to ping GPS location while the application is in the background.

_Note: Learn more about [Long polling, WebSockets, Server-Sent Events (SSE)](https://karanpratapsingh.com/courses/system-design/long-polling-websockets-server-sent-events)._

### Ride Matching

We need a way to efficiently store and query nearby drivers. Let's explore different solutions we can incorporate into our design.

**SQL**

We already have access to the latitude and longitude of our customers, and with databases like [PostgreSQL](https://www.postgresql.org) and [MySQL](https://www.mysql.com) we can perform a query to find nearby driver locations given a latitude and longitude (X, Y) within a radius (R).

```sql
SELECT * FROM locations WHERE lat BETWEEN X-R AND X+R AND long BETWEEN Y-R AND Y+R
```

However, this is not scalable, and performing this query on large datasets will be quite slow.

**Geohashing**

[Geohashing](https://karanpratapsingh.com/courses/system-design/geohashing-and-quadtrees#geohashing) is a [geocoding](https://en.wikipedia.org/wiki/Address_geocoding) method used to encode geographic coordinates such as latitude and longitude into short alphanumeric strings. It was created by [Gustavo Niemeyer](https://twitter.com/gniemeyer) in 2008.

Geohash is a hierarchical spatial index that uses Base-32 alphabet encoding, the first character in a geohash identifies the initial location as one of the 32 cells. This cell will also contain 32 cells. This means that to represent a point, the world is recursively divided into smaller and smaller cells with each additional bit until the desired precision is attained. The precision factor also determines the size of the cell.

![geohashing](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/geohashing-and-quadtrees/geohashing.png)

For example, San Francisco with coordinates `37.7564, -122.4016` can be represented in geohash as `9q8yy9mf`.

Now, using the customer's geohash we can determine the nearest available driver by simply comparing it with the driver's geohash. For better performance, we will index and store the geohash of the driver in memory for faster retrieval.

**Quadtrees**

A [Quadtree](https://karanpratapsingh.com/courses/system-design/geohashing-and-quadtrees#quadtrees) is a tree data structure in which each internal node has exactly four children. They are often used to partition a two-dimensional space by recursively subdividing it into four quadrants or regions. Each child or leaf node stores spatial information. Quadtrees are the two-dimensional analog of [Octrees](https://en.wikipedia.org/wiki/Octree) which are used to partition three-dimensional space.

![quadtree](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/geohashing-and-quadtrees/quadtree.png)

Quadtrees enable us to search points within a two-dimensional range efficiently, where those points are defined as latitude/longitude coordinates or as cartesian (x, y) coordinates.

We can save further computation by only subdividing a node after a certain threshold.

![quadtree-subdivision](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-IV/geohashing-and-quadtrees/quadtree-subdivision.png)

[Quadtree](https://karanpratapsingh.com/courses/system-design/geohashing-and-quadtrees#quadtrees) seems perfect for our use case, we can update the Quadtree every time we receive a new location update from the driver. To reduce the load on the quadtree servers we can use an in-memory datastore such as [Redis](https://redis.io) to cache the latest updates. And with the application of mapping algorithms such as the [Hilbert curve](https://en.wikipedia.org/wiki/Hilbert_curve), we can perform efficient range queries to find nearby drivers for the customer.

**What about race conditions?**

Race conditions can easily occur when a large number of customers will be requesting rides simultaneously. To avoid this, we can wrap our ride matching logic in a [Mutex](<https://en.wikipedia.org/wiki/Lock_(computer_science)>) to avoid any race conditions. Furthermore, every action should be transactional in nature.

_For more details, refer to [Transactions](https://karanpratapsingh.com/courses/system-design/transactions) and [Distributed Transactions](https://karanpratapsingh.com/courses/system-design/distributed-transactions)._

**How to find the best drivers nearby?**

Once we have a list of nearby drivers from the Quadtree servers, we can perform some sort of ranking based on parameters like average ratings, relevance, past customer feedback, etc. This will allow us to broadcast notifications to the best available drivers first.

**Dealing with high demand**

In cases of high demand, we can use the concept of Surge Pricing. Surge pricing is a dynamic pricing method where prices are temporarily increased as a reaction to increased demand and mostly limited supply. This surge price can be added to the base price of the trip.

_For more details, learn how [surge pricing works](https://www.uber.com/us/en/drive/driver-app/how-surge-works) with Uber._

### Payments

Handling payments at scale is challenging, to simplify our system we can use a third-party payment processor like [Stripe](https://stripe.com) or [PayPal](https://www.paypal.com). Once the payment is complete, the payment processor will redirect the user back to our application and we can set up a [webhook](https://en.wikipedia.org/wiki/Webhook) to capture all the payment-related data.

### Notifications

Push notifications will be an integral part of our platform. We can use a message queue or a message broker such as [Apache Kafka](https://kafka.apache.org) with the notification service to dispatch requests to [Firebase Cloud Messaging (FCM)](https://firebase.google.com/docs/cloud-messaging) or [Apple Push Notification Service (APNS)](https://developer.apple.com/documentation/usernotifications) which will handle the delivery of the push notifications to user devices.

_For more details, refer to the [WhatsApp](https://karanpratapsingh.com/courses/system-design/whatsapp#notifications) system design where we discuss push notifications in detail._

## Detailed design

It's time to discuss our design decisions in detail.

### Data Partitioning

To scale out our databases we will need to partition our data. Horizontal partitioning (aka [Sharding](https://karanpratapsingh.com/courses/system-design/sharding)) can be a good first step. We can shard our database either based on existing [partition schemes](https://karanpratapsingh.com/courses/system-design/sharding#partitioning-criteria) or regions. If we divide the locations into regions using let's say zip codes, we can effectively store all the data in a given region on a fixed node. But this can still cause uneven data and load distribution, we can solve this using [Consistent hashing](https://karanpratapsingh.com/courses/system-design/consistent-hashing).

_For more details, refer to [Sharding](https://karanpratapsingh.com/courses/system-design/sharding) and [Consistent Hashing](https://karanpratapsingh.com/courses/system-design/consistent-hashing)._

### Metrics and Analytics

Recording analytics and metrics is one of our extended requirements. We can capture the data from different services and run analytics on the data using [Apache Spark](https://spark.apache.org) which is an open-source unified analytics engine for large-scale data processing. Additionally, we can store critical metadata in the views table to increase data points within our data.

### Caching

In a location services-based platform, caching is important. We have to be able to cache the recent locations of the customers and drivers for fast retrieval. We can use solutions like [Redis](https://redis.io) or [Memcached](https://memcached.org) but what kind of cache eviction policy would best fit our needs?

**Which cache eviction policy to use?**

[Least Recently Used (LRU)](<https://en.wikipedia.org/wiki/Cache_replacement_policies#Least_recently_used_(LRU)>) can be a good policy for our system. In this policy, we discard the least recently used key first.

**How to handle cache miss?**

Whenever there is a cache miss, our servers can hit the database directly and update the cache with the new entries.

_For more details, refer to [Caching](https://karanpratapsingh.com/courses/system-design/caching)._

## Identify and resolve bottlenecks

![uber-advanced-design](https://raw.githubusercontent.com/karanpratapsingh/portfolio/master/public/static/courses/system-design/chapter-V/uber/uber-advanced-design.png)

Let us identify and resolve bottlenecks such as single points of failure in our design:

- "What if one of our services crashes?"
- "How will we distribute our traffic between our components?"
- "How can we reduce the load on our database?"
- "How to improve the availability of our cache?"
- "How can we make our notification system more robust?"

To make our system more resilient we can do the following:

- Running multiple instances of each of our services.
- Introducing [load balancers](https://karanpratapsingh.com/courses/system-design/load-balancing) between clients, servers, databases, and cache servers.
- Using multiple read replicas for our databases.
- Multiple instances and replicas for our distributed cache.
- Exactly once delivery and message ordering is challenging in a distributed system, we can use a dedicated [message broker](https://karanpratapsingh.com/courses/system-design/message-brokers) such as [Apache Kafka](https://kafka.apache.org) or [NATS](https://nats.io) to make our notification system more robust.

# Next Steps

Congratulations, you've finished the course!

Now that you know the fundamentals of System Design, here are some additional resources:

- [Distributed Systems](https://www.youtube.com/watch?v=UEAMfLPZZhE&list=PLeKd45zvjcDFUEv_ohr_HdUFe97RItdiB) (by Dr. Martin Kleppmann)
- [System Design Interview: An Insider's Guide](https://www.amazon.in/System-Design-Interview-insiders-Second/dp/B08CMF2CQF)
- [Microservices](https://microservices.io) (by Chris Richardson)
- [Serverless computing](https://en.wikipedia.org/wiki/Serverless_computing)
- [Kubernetes](https://kubernetes.io)

It is also recommended to actively follow engineering blogs of companies putting what we learned in the course into practice at scale:

- [Microsoft Engineering](https://engineering.microsoft.com)
- [Google Research Blog](http://googleresearch.blogspot.com)
- [Netflix Tech Blog](http://techblog.netflix.com)
- [AWS Blog](https://aws.amazon.com/blogs/aws)
- [Facebook Engineering](https://www.facebook.com/Engineering)
- [Uber Engineering Blog](http://eng.uber.com)
- [Airbnb Engineering](http://nerds.airbnb.com)
- [GitHub Engineering Blog](https://github.blog/category/engineering)
- [Intel Software Blog](https://software.intel.com/en-us/blogs)
- [LinkedIn Engineering](http://engineering.linkedin.com/blog)
- [Paypal Developer Blog](https://medium.com/paypal-engineering)
- [Twitter Engineering](https://blog.twitter.com/engineering)

Last but not least, volunteer for new projects at your company, and learn from senior engineers and architects to further improve your system design skills.

I hope this course was a great learning experience. I would love to hear feedback from you.

Wishing you all the best for further learning!

# References

Here are the resources that were referenced while creating this course.

- [Cloudflare learning center](https://www.cloudflare.com/learning)
- [IBM Blogs](https://www.ibm.com/blogs)
- [Fastly Blogs](https://www.fastly.com/blog)
- [NS1 Blogs](https://ns1.com/blog)
- [Grokking the System Design Interview](https://www.designgurus.io/course/grokking-the-system-design-interview)
- [Grokking Microservices Design Patterns](https://www.designgurus.io/course/grokking-microservices-design-patterns)
- [System Design Primer](https://github.com/donnemartin/system-design-primer)
- [AWS Blogs](https://aws.amazon.com/blogs)
- [Architecture Patterns by Microsoft](https://learn.microsoft.com/en-us/azure/architecture/patterns)
- [Martin Fowler](https://martinfowler.com)
- [PagerDuty resources](https://www.pagerduty.com/resources)
- [VMWare Blogs](https://blogs.vmware.com/learning)

_All the diagrams were made using [Excalidraw](https://excalidraw.com) and are available [here](https://github.com/karanpratapsingh/system-design/tree/main/diagrams)._
